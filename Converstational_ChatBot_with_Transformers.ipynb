{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Converstational ChatBot with Transformers.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hYGRGGelg7zJ",
        "uzdcCDVciGyR",
        "4g4fXGjplapO",
        "Bj5NlAsml7if",
        "OLyoB2vrmB3j"
      ],
      "authorship_tag": "ABX9TyN3eKJuRGY5JMZNfXVWwt6G",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashe/NLP/blob/main/Converstational_ChatBot_with_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6SOVSxoTqAL"
      },
      "source": [
        "In this notebook, we will train a converstational agent(Chatbot) using [Cornell Movie-Dialogs Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html) using the Transformer mentioned in the [Attention is all you Need](https://arxiv.org/pdf/1706.03762.pdf) paper.\n",
        "\n",
        "This notebook dervies heavily from:\n",
        "\n",
        "1. [Pytorch Chatbot Tutorial](https://pytorch.org/tutorials/beginner/chatbot_tutorial.html) but instead of RNN Seq2Seq model we will use Transformers.\n",
        "2. [Attention is all you Need notebook](https://github.com/akashe/NLP/blob/main/Attention_is_all_you_need.ipynb) we wrote previosuly.\n",
        "\n",
        "\n",
        "The Pytorch tutorial uses MAX_LENGHT of 10 and removes any conversation pairs with <unk> token and achieves a train NLLloss of 2.4606 after 4000 train steps.\n",
        "\n",
        "Objective:\n",
        "To get NLLloss less that 2.4606 in 4000 iterations using Transformers.\n",
        "\n",
        "Things left:\n",
        "\n",
        "1. reducing qa pairs with max_length and unk token\n",
        "1. restricting to 4000 iterations with random batches\n",
        "2. final qa interface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiLz47bYU6h0"
      },
      "source": [
        "### Importing libs and setting device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spjd5q4uTety"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import torch\n",
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "from io import open\n",
        "import itertools\n",
        "import math\n",
        "import spacy\n",
        "from torchtext.data import Field,Dataset, Example,BucketIterator\n",
        "import time\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdGn4VPXjmTN"
      },
      "source": [
        "SEED = 1007\n",
        "\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3U2MaxWVF7j"
      },
      "source": [
        "### Downloading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7WdjQmMVIjT",
        "outputId": "194d1a08-f4a1-40a2-fd62-7ac7a81b3600"
      },
      "source": [
        "!wget -c http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-07 20:53:48--  http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_UdDmZqVZF-",
        "outputId": "17d33724-135d-4704-c8e2-7ef4275653fc"
      },
      "source": [
        "!unzip -n /content/cornell_movie_dialogs_corpus.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/cornell_movie_dialogs_corpus.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phkyxej4Vr5d",
        "outputId": "60316e42-0060-4e4c-d491-0483d777ee8d"
      },
      "source": [
        "!head -10 /content/cornell\\ movie-dialogs\\ corpus/movie_lines.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
            "L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\n",
            "L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\n",
            "L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\n",
            "L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\n",
            "L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\n",
            "L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\n",
            "L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\n",
            "L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I'm kidding.  You know how sometimes you just become this \"persona\"?  And you don't know how to quit?\n",
            "L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut0VJNNLXVIp",
        "outputId": "03b900c5-af42-4848-c317-e571cb6860b9"
      },
      "source": [
        "!head -10 /content/cornell\\ movie-dialogs\\ corpus/movie_conversations.txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']\n",
            "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEX6UdMKV1oy"
      },
      "source": [
        "### Processing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeMXR2QrdoVe"
      },
      "source": [
        "In the pytorch tutorial there are seperate function for:\n",
        "\n",
        "1. Removing unicode character.\n",
        "2. Giving spaces between fullstop and question mark. i.e. Akash? -> Akash ?\n",
        "3. removing redundant spaces\n",
        "\n",
        "Luckily spacy takes care of all of the above while tokenizing. We do have to take care of keeping the text in lower case.\n",
        "\n",
        "Also, since we will be using bucketiterator, we need not worry about setting a max_len for the sentences. Add it to the fact that Transformers dont have an upper limit of src_len or trg_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XllAPZhmg45g"
      },
      "source": [
        "### Loading qa-pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c6HjXOzhCky"
      },
      "source": [
        "def loadLines(fileName, fields):\n",
        "    lines = {}\n",
        "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
        "        for line in f:\n",
        "            values = line.split(\" +++$+++ \")\n",
        "            # Extract fields\n",
        "            lineObj = {}\n",
        "            for i, field in enumerate(fields):\n",
        "                lineObj[field] = values[i]\n",
        "            lines[lineObj['lineID']] = lineObj\n",
        "    return lines\n",
        "\n",
        "\n",
        "# Groups fields of lines from `loadLines` into conversations based on *movie_conversations.txt*\n",
        "def loadConversations(fileName, lines, fields):\n",
        "    conversations = []\n",
        "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
        "        for line in f:\n",
        "            values = line.split(\" +++$+++ \")\n",
        "            # Extract fields\n",
        "            convObj = {}\n",
        "            for i, field in enumerate(fields):\n",
        "                convObj[field] = values[i]\n",
        "            # Convert string to list (convObj[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\n",
        "            utterance_id_pattern = re.compile('L[0-9]+')\n",
        "            lineIds = utterance_id_pattern.findall(convObj[\"utteranceIDs\"])\n",
        "            # Reassemble lines\n",
        "            convObj[\"lines\"] = []\n",
        "            for lineId in lineIds:\n",
        "                convObj[\"lines\"].append(lines[lineId])\n",
        "            conversations.append(convObj)\n",
        "    return conversations\n",
        "\n",
        "\n",
        "# Extracts pairs of sentences from conversations\n",
        "def extractSentencePairs(conversations):\n",
        "    qa_pairs = []\n",
        "    for conversation in conversations:\n",
        "        # Iterate over all the lines of the conversation\n",
        "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
        "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
        "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
        "            # Filter wrong samples (if one of the lists is empty)\n",
        "            if inputLine and targetLine:\n",
        "                qa_pairs.append([inputLine, targetLine])\n",
        "    return qa_pairs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBUrwmSDhLST",
        "outputId": "5f9d1378-1797-4b86-9ed0-e11ce543cb4e"
      },
      "source": [
        "corpus = \"/content/cornell movie-dialogs corpus/\"\n",
        "\n",
        "lines = {}\n",
        "conversations = []\n",
        "MOVIE_LINES_FIELDS = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\n",
        "MOVIE_CONVERSATIONS_FIELDS = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\n",
        "\n",
        "# Load lines and process conversations\n",
        "print(\"\\nProcessing corpus...\")\n",
        "lines = loadLines(os.path.join(corpus, \"movie_lines.txt\"), MOVIE_LINES_FIELDS)\n",
        "print(\"\\nLoading conversations...\")\n",
        "conversations = loadConversations(os.path.join(corpus, \"movie_conversations.txt\"),\n",
        "                                  lines, MOVIE_CONVERSATIONS_FIELDS)\n",
        "\n",
        "qa_pairs = extractSentencePairs(conversations)\n",
        "print(f'Total number of qa pairs = {len(qa_pairs)}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Processing corpus...\n",
            "\n",
            "Loading conversations...\n",
            "Total number of qa pairs = 221282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPLeyMmohRIC"
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "# Reducing number of examples by setting max_len = 10\n",
        "length_mask = [len(i[0].split(\" \"))<MAX_LENGTH and len(i[1].split(\" \"))<MAX_LENGTH for i in qa_pairs]\n",
        "\n",
        "qa_pairs = [pair for i,pair in enumerate(qa_pairs) if length_mask[i]]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYGRGGelg7zJ"
      },
      "source": [
        "### Setting up preprocessing necesseties"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjMnOqGeV4Mz",
        "outputId": "cb614015-a03b-4674-a315-a879ccc2889c"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (53.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcvRdD2LcNX0"
      },
      "source": [
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVy4DXHhcaUH",
        "outputId": "1445bf7f-36e9-4b66-aed8-999d4efc28b7"
      },
      "source": [
        "print([i.text.lower() for i in spacy_en.tokenizer('What!!! No?? \\u1F600')])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what', '!', '!', '!', 'no', '?', '?', 'ὠ0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84DdufQ0gTQr"
      },
      "source": [
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzdcCDVciGyR"
      },
      "source": [
        "### Setting up Fields, Vocabs, Datasets and Iterators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZQx1GeVgkqa"
      },
      "source": [
        "# Defining a single field to keep the vocab same for encoder and decoder\n",
        "\n",
        "SRC_TRG = Field(tokenize = tokenize_en, \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXrjjzstiKqZ"
      },
      "source": [
        "fields = [('src',SRC_TRG),('trg',SRC_TRG)]\n",
        "\n",
        "chat_examples = [Example.fromlist([pair[0],pair[1]],fields) for pair in qa_pairs]\n",
        "chat_dataset = Dataset(chat_examples,fields)\n",
        "\n",
        "train_data, valid_data = chat_dataset.split(split_ratio=[0.85,0.15],random_state = random.seed(SEED))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1_UOahVlm6O",
        "outputId": "f82157e9-9b20-42aa-8dc7-902cebd6dd8c"
      },
      "source": [
        "print(vars(train_data[0]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'src': ['he', 'tapped', 'that', '.'], 'trg': ['naw', '!']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9KY45U-lDIr"
      },
      "source": [
        "SRC_TRG.build_vocab(train_data, max_size = 7823,min_freq = 3)\n",
        "# TRG.build_vocab(train_data, max_size = 5000,min_freq = 3)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HuYvjfRnhoN",
        "outputId": "2eacec86-ccbe-40ef-a22b-b36f0d6393d5"
      },
      "source": [
        "# There is no need for the this step. Ideally model should be able to handle unk tokens.\n",
        "# Since we are trying to compare results with the pytorch tutorial,\n",
        "# we are removing pairs with unk token in them\n",
        "pruned_Examples = []\n",
        "for i in train_data.examples:\n",
        "  flag_ = True\n",
        "  for j in i.src:\n",
        "    if j not in SRC_TRG.vocab.stoi:\n",
        "      flag_ = False\n",
        "  for j in i.trg:\n",
        "    if j not in SRC_TRG.vocab.stoi:\n",
        "      flag_ = False\n",
        "  if flag_:\n",
        "    pruned_Examples.append(i)\n",
        "  \n",
        "print(f\"Total number of train_examples after pruning pairs with unk tokens {len(pruned_Examples)}\")\n",
        "train_data.examples = pruned_Examples"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of train_examples after pruning pairs with unk tokens 57320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv2EDAw4j3Fy"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, valid_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort_key = lambda x: len(x.src),\n",
        "     device = device)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLKiWwrPkFMO"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCKkJLYFkLDi"
      },
      "source": [
        "class PositionalEncodingComponent(nn.Module):\n",
        "  '''\n",
        "  Class to encode positional information to tokens.\n",
        "  \n",
        "\n",
        "  '''\n",
        "  def __init__(self,hid_dim,device,dropout=0.2,max_len=5000):\n",
        "    super().__init__()\n",
        "\n",
        "    assert hid_dim%2==0 # If not, it will result error in allocation to positional_encodings[:,1::2] later\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.positional_encodings = torch.zeros(max_len,hid_dim)\n",
        "\n",
        "    pos = torch.arange(0,max_len).unsqueeze(1) # pos : [max_len,1]\n",
        "    div_term  = torch.exp(-torch.arange(0,hid_dim,2)*math.log(10000.0)/hid_dim) # Calculating value of 1/(10000^(2i/hid_dim)) in log space and then exponentiating it\n",
        "    # div_term: [hid_dim//2]\n",
        "\n",
        "    self.positional_encodings[:,0::2] = torch.sin(pos*div_term) # pos*div_term [max_len,hid_dim//2]\n",
        "    self.positional_encodings[:,1::2] = torch.cos(pos*div_term) \n",
        "\n",
        "    self.positional_encodings = self.positional_encodings.unsqueeze(0) # To account for batch_size in inputs\n",
        "    # positional_encodings : [1,max_len,hid_dim]\n",
        "    \n",
        "    self.device = device\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x + self.positional_encodings[:,:x.size(1)].detach().to(self.device)\n",
        "    return self.dropout(x)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPxIbk8QkaGo"
      },
      "source": [
        "class FeedForwardComponent(nn.Module):\n",
        "  '''\n",
        "  Class for pointwise feed forward connections\n",
        "  '''\n",
        "  def __init__(self,hid_dim,pf_dim,dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.fc1 = nn.Linear(hid_dim,pf_dim)\n",
        "    self.fc2 = nn.Linear(pf_dim,hid_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    # x : [batch_size,seq_len,hid_dim]\n",
        "    x = self.dropout(torch.relu(self.fc1(x)))\n",
        "\n",
        "    # x : [batch_size,seq_len,pf_dim]\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    # x : [batch_size,seq_len,hid_dim]\n",
        "    return x"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFLRDzXxkbzC"
      },
      "source": [
        "class MultiHeadedAttentionComponent(nn.Module):\n",
        "  '''\n",
        "  Multiheaded attention Component. This implementation also supports mask. \n",
        "  The reason for mask that in Decoder, we don't want attention mechanism to get\n",
        "  important information from future tokens.\n",
        "  '''\n",
        "  def __init__(self,hid_dim, n_heads, dropout, device):\n",
        "    super().__init__()\n",
        "\n",
        "    assert hid_dim % n_heads == 0 # Since we split hid_dims into n_heads\n",
        "\n",
        "    self.hid_dim = hid_dim\n",
        "    self.n_heads = n_heads # no of heads in 'multiheaded' attention\n",
        "    self.head_dim = hid_dim//n_heads # dims of each head\n",
        "\n",
        "    # Transformation from source vector to query vector\n",
        "    self.fc_q = nn.Linear(hid_dim,hid_dim)\n",
        "\n",
        "    # Transformation from source vector to key vector\n",
        "    self.fc_k = nn.Linear(hid_dim,hid_dim)\n",
        "\n",
        "    # Transformation from source vector to value vector\n",
        "    self.fc_v = nn.Linear(hid_dim,hid_dim)\n",
        "\n",
        "    self.fc_o = nn.Linear(hid_dim,hid_dim)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # Used in self attention for smoother gradients\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "\n",
        "  def forward(self,query,key,value,mask=None):\n",
        "\n",
        "    #query : [batch_size, query_len, hid_dim]\n",
        "    #key : [batch_size, key_len, hid_dim]\n",
        "    #value : [batch_size, value_len, hid_dim]\n",
        "\n",
        "    batch_size = query.shape[0]\n",
        "\n",
        "    # Transforming quey,key,values\n",
        "    Q = self.fc_q(query)\n",
        "    K = self.fc_k(key)\n",
        "    V = self.fc_v(value)\n",
        "\n",
        "    #Q : [batch_size, query_len, hid_dim]\n",
        "    #K : [batch_size, key_len, hid_dim]\n",
        "    #V : [batch_size, value_len,hid_dim]\n",
        "\n",
        "    # Changing shapes to acocmadate n_heads information\n",
        "    Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "    K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "    V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "    #Q : [batch_size, n_heads, query_len, head_dim]\n",
        "    #K : [batch_size, n_heads, key_len, head_dim]\n",
        "    #V : [batch_size, n_heads, value_len, head_dim]\n",
        "\n",
        "    # Calculating alpha\n",
        "    score = torch.matmul(Q,K.permute(0,1,3,2))/self.scale\n",
        "    # score : [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "    if mask is not None:\n",
        "      score = score.masked_fill(mask==0,-1e10)\n",
        "\n",
        "    alpha = torch.softmax(score,dim=-1)\n",
        "    # alpha : [batch_size, n_heads, query_len, key_len]\n",
        "\n",
        "    # Get the final self-attention  vector\n",
        "    x = torch.matmul(self.dropout(alpha),V)\n",
        "    # x : [batch_size, n_heads, query_len, head_dim]\n",
        "\n",
        "    # Reshaping self attention vector to concatenate\n",
        "    x = x.permute(0,2,1,3).contiguous()\n",
        "    # x : [batch_size, query_len, n_heads, head_dim]\n",
        "\n",
        "    x = x.view(batch_size,-1,self.hid_dim)\n",
        "    # x: [batch_size, query_len, hid_dim]\n",
        "\n",
        "    # Transforming concatenated outputs \n",
        "    x = self.fc_o(x)\n",
        "    #x : [batch_size, query_len, hid_dim] \n",
        "\n",
        "    return x, alpha"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwAaA_SXkcWr"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "  '''\n",
        "  Operations of a single layer in an Encoder. An Encoder employs multiple such layers. Each layer contains:\n",
        "  1) multihead attention, folllowed by\n",
        "  2) LayerNorm of addition of multihead attention output and input to the layer, followed by\n",
        "  3) FeedForward connections, followed by\n",
        "  4) LayerNorm of addition of FeedForward outputs and output of previous layerNorm.\n",
        "  '''\n",
        "  def __init__(self, hid_dim,n_heads,pf_dim,dropout,device):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.self_attn_layer_norm = nn. LayerNorm(hid_dim) #Layer norm after self-attention\n",
        "    self.ff_layer_norm = nn.LayerNorm(hid_dim) # Layer norm after FeedForward component\n",
        "\n",
        "    self.self_attention = MultiHeadedAttentionComponent(hid_dim,n_heads,dropout,device)\n",
        "    self.feed_forward = FeedForwardComponent(hid_dim,pf_dim,dropout)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "  def forward(self,src,src_mask):\n",
        "    \n",
        "    # src : [batch_size, src_len, hid_dim]\n",
        "    # src_mask : [batch_size, 1, 1, src_len]\n",
        "\n",
        "    # get self-attention\n",
        "    _src, _ = self.self_attention(src,src,src,src_mask)\n",
        "\n",
        "    # LayerNorm after dropout\n",
        "    src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "    # src : [batch_size, src_len, hid_dim]\n",
        "\n",
        "    # FeedForward\n",
        "    _src = self.feed_forward(src)\n",
        "\n",
        "    # layerNorm after dropout\n",
        "    src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "    # src: [batch_size, src_len, hid_dim]\n",
        "\n",
        "    return src\n",
        "    "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWqnW-tWkdHb"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "  '''\n",
        "  Operations of a single layer in an Decoder. An Decoder employs multiple such layers. Each layer contains:\n",
        "  1) masked decoder self attention, followed by\n",
        "  2) LayerNorm of addition of previous attention output and input to the layer,, followed by\n",
        "  3) encoder self attention, followed by\n",
        "  4) LayerNorm of addition of result of encoder self attention and its input, followed by\n",
        "  5) FeedForward connections, followed by\n",
        "  6) LayerNorm of addition of Feedforward results and its input.\n",
        "  '''\n",
        "  def __init__(self,hid_dim,n_heads,pf_dim,dropout,device):\n",
        "    super().__init__()\n",
        "\n",
        "    self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "    self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "    self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "\n",
        "    # decoder self attention\n",
        "    self.self_attention = MultiHeadedAttentionComponent(hid_dim,n_heads,dropout,device)\n",
        "\n",
        "    # encoder attention\n",
        "    self.encoder_attention = MultiHeadedAttentionComponent(hid_dim,n_heads,dropout,device)\n",
        "\n",
        "    # FeedForward\n",
        "    self.feed_forward = FeedForwardComponent(hid_dim,pf_dim,dropout)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self,trg, enc_src,trg_mask,src_mask):\n",
        "\n",
        "    #trg : [batch_size, trg_len, hid_dim]\n",
        "    #enc_src : [batch_size, src_len, hid_dim]\n",
        "    #trg_mask : [batch_size, 1, trg_len, trg_len]\n",
        "    #src_mask : [batch_size, 1, 1, src_len]\n",
        "\n",
        "    '''\n",
        "    Decoder self-attention\n",
        "    trg_mask is to force decoder to look only into past tokens and not get information from future tokens.\n",
        "    Since we apply mask before doing softmax, the final self attention vector gets no information from future tokens.\n",
        "    '''\n",
        "    _trg, _ = self.self_attention(trg,trg,trg,trg_mask)\n",
        "\n",
        "    # LayerNorm and dropout with resdiual connection\n",
        "    trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "    # trg : [batch_size, trg_len, hid_dim]\n",
        "\n",
        "    '''\n",
        "    Encoder attention:\n",
        "    Query: trg\n",
        "    key: enc_src\n",
        "    Value : enc_src\n",
        "    Why? \n",
        "    the idea here is to extract information from encoder outputs. So we use decoder self-attention as a query to find important values from enc_src\n",
        "    and that is why we use src_mask, to avoid getting information from enc_src positions where it is equal to pad-id\n",
        "    After we get necessary infromation from encoder outputs we add them back to decoder self-attention.\n",
        "    '''\n",
        "    _trg, encoder_attn_alpha = self.encoder_attention(trg,enc_src,enc_src,src_mask)\n",
        "\n",
        "    # LayerNorm , residual connection and dropout\n",
        "    trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "    # trg : [ batch_size, trg_len, hid_dim]\n",
        "\n",
        "    # Feed Forward\n",
        "    _trg = self.feed_forward(trg)\n",
        "\n",
        "    # LayerNorm, residual connection and dropout\n",
        "    trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "    return trg, encoder_attn_alpha\n",
        "    "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byffMNI8kfKe"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  '''\n",
        "  An encoder, creates token embeddings and position embeddings and passes them through multiple encoder layers\n",
        "  This is a bidirectional encoder. So we will reverse the input, add appropriate padding and positional embeddings and\n",
        "  concat it with the forward input.\n",
        "  '''\n",
        "  def __init__(self,input_dim,hid_dim,n_layers,n_heads,pf_dim,dropout,device,max_length = 5000):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "\n",
        "    self.tok_embedding = nn.Embedding(input_dim,hid_dim)\n",
        "    self.pos_embedding = PositionalEncodingComponent(hid_dim,device,dropout,max_length)\n",
        "\n",
        "    # encoder layers\n",
        "    self.layers = nn.ModuleList([EncoderLayer(2*hid_dim,n_heads,pf_dim,dropout,device) for _ in range(n_layers)])\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "    self.hid_dim = hid_dim\n",
        "\n",
        "  def reverse_src(self,src,src_mask):\n",
        "    # src : [batch_size, src_len]\n",
        "    # src_mask : [batch_size,1,1,src_len]\n",
        "\n",
        "    total_non_padded_values = src_mask.sum(dim=-1).squeeze(1)\n",
        "    # total_non_padded_values : [batch_size,1]\n",
        "\n",
        "    reversed_src = torch.ones(src.shape,dtype=torch.int64)\n",
        "    # reversed_src : [batch_size,src_len]\n",
        "\n",
        "    # flip the src :[10,9,8] -> [8,9,10]\n",
        "    src = torch.flip(src,dims=[-1])\n",
        "    # src : [batch_size, src_len]\n",
        "    \n",
        "    for pos,(i,j) in enumerate(zip(src,total_non_padded_values)):\n",
        "      j = int(j.item())\n",
        "      reversed_src[pos] = torch.cat([i[-j:],i[:-j]],dim=-1)\n",
        "\n",
        "    return reversed_src\n",
        "  \n",
        "  def forward(self,src,src_mask):\n",
        "\n",
        "    # src : [batch_size, src_len]\n",
        "    # src_mask : [batch_size,1,1,src_len]\n",
        "\n",
        "    batch_size = src.shape[0]\n",
        "    src_len = src.shape[1]\n",
        "\n",
        "    # reversed source\n",
        "    reversed_src = self.reverse_src(src,src_mask).to(device)\n",
        "    # reversed_src : [batch_size,src_len]\n",
        "\n",
        "    tok_embeddings = self.tok_embedding(src)*self.scale\n",
        "    reversed_tok_embeddings = self.tok_embedding(reversed_src)*self.scale\n",
        "\n",
        "    # token plus position embeddings\n",
        "    src  = self.pos_embedding(tok_embeddings)\n",
        "    reversed_src = self.pos_embedding(reversed_tok_embeddings)\n",
        "\n",
        "    concatenated_src = torch.ones([batch_size,src_len,self.hid_dim*2]).to(device)\n",
        "    # Interleaving concatenated source such that f1,b1,f2,b2....\n",
        "    concatenated_src[:,:,0::2] = src\n",
        "    concatenated_src[:,:,1::2] = reversed_src\n",
        "\n",
        "    src = concatenated_src\n",
        "\n",
        "    for layer in self.layers:\n",
        "      src = layer(src,src_mask)\n",
        "    # src : [batch_size, src_len, 2*hid_dim]\n",
        "\n",
        "    return src"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8fn9uHrkhKF"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  '''\n",
        "  An decoder, creates token embeddings and position embeddings and passes them through multiple decoder layers\n",
        "  '''\n",
        "  def __init__(self,output_dim,hid_dim,n_layers,n_heads,pf_dim,dropout,device,max_length= 5000):\n",
        "    super().__init__()\n",
        "\n",
        "    self.device = device\n",
        "\n",
        "    self.tok_embedding = nn.Embedding(output_dim,hid_dim)\n",
        "    self.pos_embedding = PositionalEncodingComponent(hid_dim,device,dropout,max_length)\n",
        "\n",
        "    # decoder layers\n",
        "    self.layers = nn.ModuleList([DecoderLayer(hid_dim,n_heads,pf_dim,dropout,device) for _ in range(n_layers)])\n",
        "\n",
        "    # convert decoder outputs to real outputs\n",
        "    self.fc_out = nn.Linear(hid_dim,output_dim)\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "\n",
        "  def forward(self, trg, enc_src,trg_mask,src_mask):\n",
        "    \n",
        "    #trg : [batch_size, trg_len]\n",
        "    #enc_src : [batch_size, src_len, hid_dim]\n",
        "    #trg_mask : [batch_size, 1, trg_len, trg_len]\n",
        "    #src_mask : [batch_size, 1, 1, src_len]\n",
        "\n",
        "    batch_size = trg.shape[0]\n",
        "    trg_len = trg.shape[1]\n",
        "\n",
        "    tok_embeddings = self.tok_embedding(trg)*self.scale\n",
        "\n",
        "    # token plus pos embeddings\n",
        "    trg = self.pos_embedding(tok_embeddings)\n",
        "    # trg : [batch_size, trg_len, hid_dim]\n",
        "\n",
        "    # Pass trg thorugh decoder layers\n",
        "    for layer in self.layers:\n",
        "      trg, encoder_attention = layer(trg,enc_src,trg_mask,src_mask)\n",
        "    \n",
        "    # trg : [batch_size,trg_len,hid_dim]\n",
        "    # encoder_attention :  [batch_size, n_head,trg_len, src_len]\n",
        "\n",
        "    # Convert to outputs\n",
        "    output = self.fc_out(trg)\n",
        "    # output : [batch_size, trg_len, output_dim]\n",
        "    \n",
        "    return output, encoder_attention"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dBBnH83kiSI"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_pad_idx = src_pad_idx\n",
        "    self.trg_pad_idx = trg_pad_idx\n",
        "    self.device = device\n",
        "\n",
        "  def make_src_mask(self,src):\n",
        "    # src : [batch_size, src_len]\n",
        "\n",
        "    # Masking pad values\n",
        "    src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    # src_mask : [batch_size,1,1,src_len]\n",
        "\n",
        "    return src_mask\n",
        "\n",
        "  def make_trg_mask(self,trg):\n",
        "    # trg : [batch_size, trg_len]\n",
        "\n",
        "    # Masking pad values\n",
        "    trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "    # trg_pad_mask : [batch_size,1,1, trg_len]\n",
        "\n",
        "    # Masking future values\n",
        "    trg_len = trg.shape[1]\n",
        "    trg_sub_mask = torch.tril(torch.ones((trg_len,trg_len),device= self.device)).bool()\n",
        "    # trg_sub_mask : [trg_len, trg_len]\n",
        "\n",
        "    # combine both masks\n",
        "    trg_mask = trg_pad_mask & trg_sub_mask\n",
        "    # trg_mask = [batch_size,1,trg_len,trg_len]\n",
        "\n",
        "    return trg_mask\n",
        "\n",
        "  def forward(self,src,trg):\n",
        "\n",
        "    # src : [batch_size, src_len]\n",
        "    # trg : [batch_size, trg_len]\n",
        "\n",
        "    src_mask = self.make_src_mask(src)\n",
        "    trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "    # src_mask : [ batch_size, 1,1,src_len]\n",
        "    # trg_mask : [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "    enc_src = self.encoder(src,src_mask)\n",
        "    #enc_src : [batch_size, src_len, hid_dim]\n",
        "\n",
        "    output, encoder_decoder_attention = self.decoder(trg,enc_src,trg_mask,src_mask)\n",
        "    # output : [batch_size, trg_len, output_dim]\n",
        "    # encoder_decoder_attention : [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "    return output, encoder_decoder_attention"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_YLil4tkwAD"
      },
      "source": [
        "### Initializing Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O9NyH8EkzlI"
      },
      "source": [
        "INPUT_DIM = len(SRC_TRG.vocab)\n",
        "OUTPUT_DIM = len(SRC_TRG.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 1\n",
        "DEC_LAYERS = 1\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, \n",
        "              2*HID_DIM, \n",
        "              DEC_LAYERS, \n",
        "              DEC_HEADS, \n",
        "              DEC_PF_DIM, \n",
        "              DEC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "SRC_PAD_IDX = SRC_TRG.vocab.stoi[SRC_TRG.pad_token]\n",
        "TRG_PAD_IDX = SRC_TRG.vocab.stoi[SRC_TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g4fXGjplapO"
      },
      "source": [
        "### Initialize weights and total model params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7_9p1j3lhdi"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(initialize_weights);"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ba45ySktlito",
        "outputId": "0a2972e2-281a-413c-e357-8b1482072f5b"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 14,234,003 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj5NlAsml7if"
      },
      "source": [
        "### Learning rate, criterion and optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dk5WtaZWmABj",
        "outputId": "5de848db-ac77-41d8-97cf-c7c84c0de6ec"
      },
      "source": [
        "LEARNING_RATE = 0.0001\n",
        "decoder_learning_ratio = 5\n",
        "\n",
        "encoder_optimizer = torch.optim.Adam(model.encoder.parameters(), lr = LEARNING_RATE)\n",
        "decoder_optimizer = torch.optim.Adam(model.decoder.parameters(),lr= decoder_learning_ratio*LEARNING_RATE)\n",
        "\n",
        "optimizer = (encoder_optimizer,decoder_optimizer)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX,size_average= True) # size average = True calculates mean loss only of non pad idx values"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLyoB2vrmB3j"
      },
      "source": [
        "### Train and Eval Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzY5PQalmEud"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip,iters):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "\n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer[0].zero_grad()\n",
        "        optimizer[1].zero_grad()\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "\n",
        "        if iters <= 4000:\n",
        "          print(f'Train loss at {iters} iteration is {loss.item()} ')\n",
        "          \n",
        "        if iters >=4000:\n",
        "          break\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer[0].step()\n",
        "        optimizer[1].step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "        iters += 1\n",
        "\n",
        "    return epoch_loss / len(iterator), iters"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnVaJt5AmGGt"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z9AObu6mJyn"
      },
      "source": [
        "### Runner Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTWRwHhgmMco"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiffzngEmNwX",
        "outputId": "4118d700-4a99-47ef-d893-97fa71eea793"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "iters = 0\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss,iters = train(model, train_iterator, optimizer, criterion, CLIP ,iters)\n",
        "    # valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    # if valid_loss < best_valid_loss:\n",
        "    #     best_valid_loss = valid_loss\n",
        "    #     torch.save(model.state_dict(), 'chat_bot_model.pt')\n",
        "    \n",
        "    # print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    # print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    # print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train loss at 0 iteration is 9.00206470489502 \n",
            "Train loss at 1 iteration is 8.232087135314941 \n",
            "Train loss at 2 iteration is 7.64331579208374 \n",
            "Train loss at 3 iteration is 7.442013263702393 \n",
            "Train loss at 4 iteration is 7.192834854125977 \n",
            "Train loss at 5 iteration is 6.757341384887695 \n",
            "Train loss at 6 iteration is 6.532083988189697 \n",
            "Train loss at 7 iteration is 6.337754726409912 \n",
            "Train loss at 8 iteration is 6.048821926116943 \n",
            "Train loss at 9 iteration is 5.9464240074157715 \n",
            "Train loss at 10 iteration is 5.775899410247803 \n",
            "Train loss at 11 iteration is 5.612894535064697 \n",
            "Train loss at 12 iteration is 5.5215582847595215 \n",
            "Train loss at 13 iteration is 5.067715167999268 \n",
            "Train loss at 14 iteration is 5.517705917358398 \n",
            "Train loss at 15 iteration is 5.209707260131836 \n",
            "Train loss at 16 iteration is 5.2359209060668945 \n",
            "Train loss at 17 iteration is 5.240084648132324 \n",
            "Train loss at 18 iteration is 5.263883590698242 \n",
            "Train loss at 19 iteration is 4.915689945220947 \n",
            "Train loss at 20 iteration is 4.748227119445801 \n",
            "Train loss at 21 iteration is 4.880546569824219 \n",
            "Train loss at 22 iteration is 4.8232598304748535 \n",
            "Train loss at 23 iteration is 4.743680477142334 \n",
            "Train loss at 24 iteration is 4.7644853591918945 \n",
            "Train loss at 25 iteration is 4.8494133949279785 \n",
            "Train loss at 26 iteration is 4.8962602615356445 \n",
            "Train loss at 27 iteration is 4.890727996826172 \n",
            "Train loss at 28 iteration is 4.6957316398620605 \n",
            "Train loss at 29 iteration is 4.930588722229004 \n",
            "Train loss at 30 iteration is 4.729191780090332 \n",
            "Train loss at 31 iteration is 4.5251784324646 \n",
            "Train loss at 32 iteration is 4.873714447021484 \n",
            "Train loss at 33 iteration is 4.849546432495117 \n",
            "Train loss at 34 iteration is 4.7589430809021 \n",
            "Train loss at 35 iteration is 4.673919677734375 \n",
            "Train loss at 36 iteration is 4.92152738571167 \n",
            "Train loss at 37 iteration is 4.627656936645508 \n",
            "Train loss at 38 iteration is 4.65924072265625 \n",
            "Train loss at 39 iteration is 4.490877151489258 \n",
            "Train loss at 40 iteration is 4.698270320892334 \n",
            "Train loss at 41 iteration is 4.653232574462891 \n",
            "Train loss at 42 iteration is 4.687974452972412 \n",
            "Train loss at 43 iteration is 4.713193893432617 \n",
            "Train loss at 44 iteration is 4.579954147338867 \n",
            "Train loss at 45 iteration is 4.605476379394531 \n",
            "Train loss at 46 iteration is 4.551007270812988 \n",
            "Train loss at 47 iteration is 4.665126323699951 \n",
            "Train loss at 48 iteration is 4.502760887145996 \n",
            "Train loss at 49 iteration is 4.322944164276123 \n",
            "Train loss at 50 iteration is 4.268119812011719 \n",
            "Train loss at 51 iteration is 4.382160186767578 \n",
            "Train loss at 52 iteration is 4.617456912994385 \n",
            "Train loss at 53 iteration is 4.277542591094971 \n",
            "Train loss at 54 iteration is 4.445728302001953 \n",
            "Train loss at 55 iteration is 4.636062145233154 \n",
            "Train loss at 56 iteration is 4.542477607727051 \n",
            "Train loss at 57 iteration is 4.399479866027832 \n",
            "Train loss at 58 iteration is 4.378587245941162 \n",
            "Train loss at 59 iteration is 4.244024276733398 \n",
            "Train loss at 60 iteration is 4.406909465789795 \n",
            "Train loss at 61 iteration is 4.242892265319824 \n",
            "Train loss at 62 iteration is 4.320335865020752 \n",
            "Train loss at 63 iteration is 4.21012544631958 \n",
            "Train loss at 64 iteration is 4.431499004364014 \n",
            "Train loss at 65 iteration is 4.451794147491455 \n",
            "Train loss at 66 iteration is 4.104654788970947 \n",
            "Train loss at 67 iteration is 4.656632900238037 \n",
            "Train loss at 68 iteration is 4.500220775604248 \n",
            "Train loss at 69 iteration is 4.209906578063965 \n",
            "Train loss at 70 iteration is 4.428216457366943 \n",
            "Train loss at 71 iteration is 4.163647651672363 \n",
            "Train loss at 72 iteration is 4.316720008850098 \n",
            "Train loss at 73 iteration is 4.160279273986816 \n",
            "Train loss at 74 iteration is 4.413688659667969 \n",
            "Train loss at 75 iteration is 4.323720932006836 \n",
            "Train loss at 76 iteration is 4.06596040725708 \n",
            "Train loss at 77 iteration is 4.520818710327148 \n",
            "Train loss at 78 iteration is 4.196110725402832 \n",
            "Train loss at 79 iteration is 4.494864463806152 \n",
            "Train loss at 80 iteration is 4.087577819824219 \n",
            "Train loss at 81 iteration is 4.2225446701049805 \n",
            "Train loss at 82 iteration is 4.220174789428711 \n",
            "Train loss at 83 iteration is 4.450039386749268 \n",
            "Train loss at 84 iteration is 4.1349616050720215 \n",
            "Train loss at 85 iteration is 4.226473331451416 \n",
            "Train loss at 86 iteration is 4.213825702667236 \n",
            "Train loss at 87 iteration is 4.2245588302612305 \n",
            "Train loss at 88 iteration is 4.213358402252197 \n",
            "Train loss at 89 iteration is 4.420165061950684 \n",
            "Train loss at 90 iteration is 4.014405727386475 \n",
            "Train loss at 91 iteration is 4.156848430633545 \n",
            "Train loss at 92 iteration is 4.17204475402832 \n",
            "Train loss at 93 iteration is 4.414983749389648 \n",
            "Train loss at 94 iteration is 4.168880939483643 \n",
            "Train loss at 95 iteration is 4.227125644683838 \n",
            "Train loss at 96 iteration is 4.3117876052856445 \n",
            "Train loss at 97 iteration is 4.1072845458984375 \n",
            "Train loss at 98 iteration is 4.103378772735596 \n",
            "Train loss at 99 iteration is 4.284683704376221 \n",
            "Train loss at 100 iteration is 4.120580196380615 \n",
            "Train loss at 101 iteration is 4.1596903800964355 \n",
            "Train loss at 102 iteration is 4.274476528167725 \n",
            "Train loss at 103 iteration is 4.154401779174805 \n",
            "Train loss at 104 iteration is 4.168111324310303 \n",
            "Train loss at 105 iteration is 4.128445625305176 \n",
            "Train loss at 106 iteration is 3.9527647495269775 \n",
            "Train loss at 107 iteration is 4.047464370727539 \n",
            "Train loss at 108 iteration is 4.078756332397461 \n",
            "Train loss at 109 iteration is 4.097705364227295 \n",
            "Train loss at 110 iteration is 4.204868793487549 \n",
            "Train loss at 111 iteration is 4.1791911125183105 \n",
            "Train loss at 112 iteration is 4.096020221710205 \n",
            "Train loss at 113 iteration is 3.8710381984710693 \n",
            "Train loss at 114 iteration is 3.9295260906219482 \n",
            "Train loss at 115 iteration is 4.163265228271484 \n",
            "Train loss at 116 iteration is 4.194601058959961 \n",
            "Train loss at 117 iteration is 4.307529449462891 \n",
            "Train loss at 118 iteration is 4.0534257888793945 \n",
            "Train loss at 119 iteration is 3.896353244781494 \n",
            "Train loss at 120 iteration is 4.079404830932617 \n",
            "Train loss at 121 iteration is 4.112234592437744 \n",
            "Train loss at 122 iteration is 3.9286532402038574 \n",
            "Train loss at 123 iteration is 4.193528175354004 \n",
            "Train loss at 124 iteration is 3.947857618331909 \n",
            "Train loss at 125 iteration is 4.1218390464782715 \n",
            "Train loss at 126 iteration is 4.020204067230225 \n",
            "Train loss at 127 iteration is 4.173242092132568 \n",
            "Train loss at 128 iteration is 3.988650321960449 \n",
            "Train loss at 129 iteration is 4.25076961517334 \n",
            "Train loss at 130 iteration is 3.925352096557617 \n",
            "Train loss at 131 iteration is 4.035431861877441 \n",
            "Train loss at 132 iteration is 4.104599952697754 \n",
            "Train loss at 133 iteration is 3.8809115886688232 \n",
            "Train loss at 134 iteration is 4.0470967292785645 \n",
            "Train loss at 135 iteration is 3.8251736164093018 \n",
            "Train loss at 136 iteration is 4.1599507331848145 \n",
            "Train loss at 137 iteration is 3.792182207107544 \n",
            "Train loss at 138 iteration is 4.201622009277344 \n",
            "Train loss at 139 iteration is 3.8415560722351074 \n",
            "Train loss at 140 iteration is 4.134312629699707 \n",
            "Train loss at 141 iteration is 3.9202723503112793 \n",
            "Train loss at 142 iteration is 4.1464996337890625 \n",
            "Train loss at 143 iteration is 4.110147476196289 \n",
            "Train loss at 144 iteration is 3.8355581760406494 \n",
            "Train loss at 145 iteration is 3.941284656524658 \n",
            "Train loss at 146 iteration is 4.195489883422852 \n",
            "Train loss at 147 iteration is 4.260040283203125 \n",
            "Train loss at 148 iteration is 4.076961040496826 \n",
            "Train loss at 149 iteration is 3.9047136306762695 \n",
            "Train loss at 150 iteration is 4.218648433685303 \n",
            "Train loss at 151 iteration is 3.9765772819519043 \n",
            "Train loss at 152 iteration is 4.153437614440918 \n",
            "Train loss at 153 iteration is 4.260140419006348 \n",
            "Train loss at 154 iteration is 4.036903381347656 \n",
            "Train loss at 155 iteration is 4.2342305183410645 \n",
            "Train loss at 156 iteration is 4.072629451751709 \n",
            "Train loss at 157 iteration is 4.2174272537231445 \n",
            "Train loss at 158 iteration is 3.998751401901245 \n",
            "Train loss at 159 iteration is 3.9831314086914062 \n",
            "Train loss at 160 iteration is 3.897458553314209 \n",
            "Train loss at 161 iteration is 4.025823593139648 \n",
            "Train loss at 162 iteration is 3.8670108318328857 \n",
            "Train loss at 163 iteration is 4.189509868621826 \n",
            "Train loss at 164 iteration is 3.8655123710632324 \n",
            "Train loss at 165 iteration is 3.860502004623413 \n",
            "Train loss at 166 iteration is 4.099945068359375 \n",
            "Train loss at 167 iteration is 4.001171588897705 \n",
            "Train loss at 168 iteration is 4.038181304931641 \n",
            "Train loss at 169 iteration is 4.032297611236572 \n",
            "Train loss at 170 iteration is 3.7570455074310303 \n",
            "Train loss at 171 iteration is 3.853492498397827 \n",
            "Train loss at 172 iteration is 4.016375541687012 \n",
            "Train loss at 173 iteration is 4.138450622558594 \n",
            "Train loss at 174 iteration is 4.156718730926514 \n",
            "Train loss at 175 iteration is 3.8804268836975098 \n",
            "Train loss at 176 iteration is 4.1145172119140625 \n",
            "Train loss at 177 iteration is 4.175775051116943 \n",
            "Train loss at 178 iteration is 3.945838451385498 \n",
            "Train loss at 179 iteration is 3.7348077297210693 \n",
            "Train loss at 180 iteration is 3.946019411087036 \n",
            "Train loss at 181 iteration is 3.81300687789917 \n",
            "Train loss at 182 iteration is 3.7297723293304443 \n",
            "Train loss at 183 iteration is 3.8715920448303223 \n",
            "Train loss at 184 iteration is 4.008072853088379 \n",
            "Train loss at 185 iteration is 3.9477949142456055 \n",
            "Train loss at 186 iteration is 3.8150761127471924 \n",
            "Train loss at 187 iteration is 4.035542011260986 \n",
            "Train loss at 188 iteration is 3.8944268226623535 \n",
            "Train loss at 189 iteration is 3.814107656478882 \n",
            "Train loss at 190 iteration is 3.9678027629852295 \n",
            "Train loss at 191 iteration is 4.0263895988464355 \n",
            "Train loss at 192 iteration is 3.8427157402038574 \n",
            "Train loss at 193 iteration is 4.15444278717041 \n",
            "Train loss at 194 iteration is 3.8708229064941406 \n",
            "Train loss at 195 iteration is 4.232429027557373 \n",
            "Train loss at 196 iteration is 3.8386683464050293 \n",
            "Train loss at 197 iteration is 4.023683071136475 \n",
            "Train loss at 198 iteration is 3.7937469482421875 \n",
            "Train loss at 199 iteration is 3.856508731842041 \n",
            "Train loss at 200 iteration is 4.015544891357422 \n",
            "Train loss at 201 iteration is 4.089932441711426 \n",
            "Train loss at 202 iteration is 4.019519329071045 \n",
            "Train loss at 203 iteration is 4.058467388153076 \n",
            "Train loss at 204 iteration is 4.022115707397461 \n",
            "Train loss at 205 iteration is 3.6968913078308105 \n",
            "Train loss at 206 iteration is 3.8888206481933594 \n",
            "Train loss at 207 iteration is 4.004024982452393 \n",
            "Train loss at 208 iteration is 3.6908926963806152 \n",
            "Train loss at 209 iteration is 3.841639280319214 \n",
            "Train loss at 210 iteration is 3.9420180320739746 \n",
            "Train loss at 211 iteration is 3.8558990955352783 \n",
            "Train loss at 212 iteration is 3.9194798469543457 \n",
            "Train loss at 213 iteration is 3.7083899974823 \n",
            "Train loss at 214 iteration is 3.884450674057007 \n",
            "Train loss at 215 iteration is 3.988600254058838 \n",
            "Train loss at 216 iteration is 4.10826301574707 \n",
            "Train loss at 217 iteration is 4.05153751373291 \n",
            "Train loss at 218 iteration is 3.916229248046875 \n",
            "Train loss at 219 iteration is 4.241456985473633 \n",
            "Train loss at 220 iteration is 3.9189980030059814 \n",
            "Train loss at 221 iteration is 3.9214813709259033 \n",
            "Train loss at 222 iteration is 3.943183422088623 \n",
            "Train loss at 223 iteration is 3.7860543727874756 \n",
            "Train loss at 224 iteration is 3.776334047317505 \n",
            "Train loss at 225 iteration is 3.832211494445801 \n",
            "Train loss at 226 iteration is 3.8928728103637695 \n",
            "Train loss at 227 iteration is 3.946843385696411 \n",
            "Train loss at 228 iteration is 4.082452297210693 \n",
            "Train loss at 229 iteration is 3.978149652481079 \n",
            "Train loss at 230 iteration is 3.7887816429138184 \n",
            "Train loss at 231 iteration is 3.8987345695495605 \n",
            "Train loss at 232 iteration is 3.8019611835479736 \n",
            "Train loss at 233 iteration is 3.8497085571289062 \n",
            "Train loss at 234 iteration is 4.064339637756348 \n",
            "Train loss at 235 iteration is 3.8547074794769287 \n",
            "Train loss at 236 iteration is 3.7024099826812744 \n",
            "Train loss at 237 iteration is 3.8641183376312256 \n",
            "Train loss at 238 iteration is 3.8481013774871826 \n",
            "Train loss at 239 iteration is 3.890953779220581 \n",
            "Train loss at 240 iteration is 3.891101598739624 \n",
            "Train loss at 241 iteration is 4.036125183105469 \n",
            "Train loss at 242 iteration is 3.986964225769043 \n",
            "Train loss at 243 iteration is 3.634045124053955 \n",
            "Train loss at 244 iteration is 3.8136844635009766 \n",
            "Train loss at 245 iteration is 3.6125848293304443 \n",
            "Train loss at 246 iteration is 3.712604284286499 \n",
            "Train loss at 247 iteration is 4.03853178024292 \n",
            "Train loss at 248 iteration is 3.6949334144592285 \n",
            "Train loss at 249 iteration is 3.9426474571228027 \n",
            "Train loss at 250 iteration is 4.120255470275879 \n",
            "Train loss at 251 iteration is 4.005338668823242 \n",
            "Train loss at 252 iteration is 3.853320837020874 \n",
            "Train loss at 253 iteration is 3.982396125793457 \n",
            "Train loss at 254 iteration is 3.849748373031616 \n",
            "Train loss at 255 iteration is 3.6365692615509033 \n",
            "Train loss at 256 iteration is 3.902071952819824 \n",
            "Train loss at 257 iteration is 3.7810165882110596 \n",
            "Train loss at 258 iteration is 3.6826322078704834 \n",
            "Train loss at 259 iteration is 3.977537155151367 \n",
            "Train loss at 260 iteration is 3.9491755962371826 \n",
            "Train loss at 261 iteration is 3.6476821899414062 \n",
            "Train loss at 262 iteration is 3.7577884197235107 \n",
            "Train loss at 263 iteration is 4.013469219207764 \n",
            "Train loss at 264 iteration is 3.721865653991699 \n",
            "Train loss at 265 iteration is 3.7029592990875244 \n",
            "Train loss at 266 iteration is 3.7827675342559814 \n",
            "Train loss at 267 iteration is 3.8349075317382812 \n",
            "Train loss at 268 iteration is 3.8680777549743652 \n",
            "Train loss at 269 iteration is 4.013910293579102 \n",
            "Train loss at 270 iteration is 3.8045437335968018 \n",
            "Train loss at 271 iteration is 3.896559953689575 \n",
            "Train loss at 272 iteration is 3.4089317321777344 \n",
            "Train loss at 273 iteration is 3.87534761428833 \n",
            "Train loss at 274 iteration is 3.957900285720825 \n",
            "Train loss at 275 iteration is 3.7709290981292725 \n",
            "Train loss at 276 iteration is 3.9571757316589355 \n",
            "Train loss at 277 iteration is 3.964083671569824 \n",
            "Train loss at 278 iteration is 3.785465717315674 \n",
            "Train loss at 279 iteration is 3.7791290283203125 \n",
            "Train loss at 280 iteration is 3.7979612350463867 \n",
            "Train loss at 281 iteration is 3.8366949558258057 \n",
            "Train loss at 282 iteration is 3.7435696125030518 \n",
            "Train loss at 283 iteration is 4.012558937072754 \n",
            "Train loss at 284 iteration is 4.02881383895874 \n",
            "Train loss at 285 iteration is 3.6223602294921875 \n",
            "Train loss at 286 iteration is 3.775233030319214 \n",
            "Train loss at 287 iteration is 4.220215797424316 \n",
            "Train loss at 288 iteration is 3.6226799488067627 \n",
            "Train loss at 289 iteration is 3.632253408432007 \n",
            "Train loss at 290 iteration is 3.526848793029785 \n",
            "Train loss at 291 iteration is 3.7744011878967285 \n",
            "Train loss at 292 iteration is 3.832130193710327 \n",
            "Train loss at 293 iteration is 3.7043445110321045 \n",
            "Train loss at 294 iteration is 3.7345621585845947 \n",
            "Train loss at 295 iteration is 3.8003790378570557 \n",
            "Train loss at 296 iteration is 3.4981958866119385 \n",
            "Train loss at 297 iteration is 3.625927209854126 \n",
            "Train loss at 298 iteration is 3.8038864135742188 \n",
            "Train loss at 299 iteration is 3.880542516708374 \n",
            "Train loss at 300 iteration is 3.776156425476074 \n",
            "Train loss at 301 iteration is 4.100126266479492 \n",
            "Train loss at 302 iteration is 3.827967405319214 \n",
            "Train loss at 303 iteration is 3.8664228916168213 \n",
            "Train loss at 304 iteration is 4.239683151245117 \n",
            "Train loss at 305 iteration is 3.631527900695801 \n",
            "Train loss at 306 iteration is 3.704633951187134 \n",
            "Train loss at 307 iteration is 3.6377453804016113 \n",
            "Train loss at 308 iteration is 3.7996177673339844 \n",
            "Train loss at 309 iteration is 3.8272101879119873 \n",
            "Train loss at 310 iteration is 3.840195417404175 \n",
            "Train loss at 311 iteration is 3.8186564445495605 \n",
            "Train loss at 312 iteration is 3.7031805515289307 \n",
            "Train loss at 313 iteration is 3.7972896099090576 \n",
            "Train loss at 314 iteration is 3.782902240753174 \n",
            "Train loss at 315 iteration is 3.6357603073120117 \n",
            "Train loss at 316 iteration is 3.875563859939575 \n",
            "Train loss at 317 iteration is 3.800811529159546 \n",
            "Train loss at 318 iteration is 3.778728723526001 \n",
            "Train loss at 319 iteration is 3.6248936653137207 \n",
            "Train loss at 320 iteration is 3.7622456550598145 \n",
            "Train loss at 321 iteration is 3.6057074069976807 \n",
            "Train loss at 322 iteration is 3.7250471115112305 \n",
            "Train loss at 323 iteration is 3.846484899520874 \n",
            "Train loss at 324 iteration is 3.819424629211426 \n",
            "Train loss at 325 iteration is 3.73457407951355 \n",
            "Train loss at 326 iteration is 3.817660331726074 \n",
            "Train loss at 327 iteration is 3.9206037521362305 \n",
            "Train loss at 328 iteration is 3.7811946868896484 \n",
            "Train loss at 329 iteration is 3.9323244094848633 \n",
            "Train loss at 330 iteration is 3.676783561706543 \n",
            "Train loss at 331 iteration is 3.545412063598633 \n",
            "Train loss at 332 iteration is 3.84837007522583 \n",
            "Train loss at 333 iteration is 3.848252534866333 \n",
            "Train loss at 334 iteration is 3.819017171859741 \n",
            "Train loss at 335 iteration is 3.7457175254821777 \n",
            "Train loss at 336 iteration is 3.821270227432251 \n",
            "Train loss at 337 iteration is 3.629772186279297 \n",
            "Train loss at 338 iteration is 3.8656177520751953 \n",
            "Train loss at 339 iteration is 3.8379805088043213 \n",
            "Train loss at 340 iteration is 3.898573160171509 \n",
            "Train loss at 341 iteration is 3.948063611984253 \n",
            "Train loss at 342 iteration is 3.7547767162323 \n",
            "Train loss at 343 iteration is 3.8526456356048584 \n",
            "Train loss at 344 iteration is 3.8292391300201416 \n",
            "Train loss at 345 iteration is 3.715672016143799 \n",
            "Train loss at 346 iteration is 3.7771973609924316 \n",
            "Train loss at 347 iteration is 3.8610596656799316 \n",
            "Train loss at 348 iteration is 3.666836738586426 \n",
            "Train loss at 349 iteration is 3.700132131576538 \n",
            "Train loss at 350 iteration is 3.7487235069274902 \n",
            "Train loss at 351 iteration is 3.7186622619628906 \n",
            "Train loss at 352 iteration is 3.939716339111328 \n",
            "Train loss at 353 iteration is 3.826474666595459 \n",
            "Train loss at 354 iteration is 3.829167604446411 \n",
            "Train loss at 355 iteration is 3.8813929557800293 \n",
            "Train loss at 356 iteration is 3.837877035140991 \n",
            "Train loss at 357 iteration is 4.005179405212402 \n",
            "Train loss at 358 iteration is 4.0034308433532715 \n",
            "Train loss at 359 iteration is 3.6557414531707764 \n",
            "Train loss at 360 iteration is 3.701634645462036 \n",
            "Train loss at 361 iteration is 3.924414873123169 \n",
            "Train loss at 362 iteration is 3.7193338871002197 \n",
            "Train loss at 363 iteration is 3.8633129596710205 \n",
            "Train loss at 364 iteration is 3.9127864837646484 \n",
            "Train loss at 365 iteration is 3.983340263366699 \n",
            "Train loss at 366 iteration is 3.886262893676758 \n",
            "Train loss at 367 iteration is 3.781435251235962 \n",
            "Train loss at 368 iteration is 3.882868528366089 \n",
            "Train loss at 369 iteration is 3.794215202331543 \n",
            "Train loss at 370 iteration is 3.4902570247650146 \n",
            "Train loss at 371 iteration is 3.600644111633301 \n",
            "Train loss at 372 iteration is 3.835582971572876 \n",
            "Train loss at 373 iteration is 3.720890522003174 \n",
            "Train loss at 374 iteration is 3.7757651805877686 \n",
            "Train loss at 375 iteration is 3.738135814666748 \n",
            "Train loss at 376 iteration is 3.758277177810669 \n",
            "Train loss at 377 iteration is 3.8299241065979004 \n",
            "Train loss at 378 iteration is 3.5780270099639893 \n",
            "Train loss at 379 iteration is 3.766739845275879 \n",
            "Train loss at 380 iteration is 3.8314497470855713 \n",
            "Train loss at 381 iteration is 3.6301074028015137 \n",
            "Train loss at 382 iteration is 3.937122344970703 \n",
            "Train loss at 383 iteration is 3.7737433910369873 \n",
            "Train loss at 384 iteration is 4.064655780792236 \n",
            "Train loss at 385 iteration is 3.798410177230835 \n",
            "Train loss at 386 iteration is 3.723172664642334 \n",
            "Train loss at 387 iteration is 3.7082390785217285 \n",
            "Train loss at 388 iteration is 3.5689592361450195 \n",
            "Train loss at 389 iteration is 3.7811827659606934 \n",
            "Train loss at 390 iteration is 3.756643533706665 \n",
            "Train loss at 391 iteration is 3.966459035873413 \n",
            "Train loss at 392 iteration is 3.8660635948181152 \n",
            "Train loss at 393 iteration is 3.851328134536743 \n",
            "Train loss at 394 iteration is 3.578312397003174 \n",
            "Train loss at 395 iteration is 3.595346450805664 \n",
            "Train loss at 396 iteration is 3.846121072769165 \n",
            "Train loss at 397 iteration is 3.6292340755462646 \n",
            "Train loss at 398 iteration is 3.807077169418335 \n",
            "Train loss at 399 iteration is 3.6726112365722656 \n",
            "Train loss at 400 iteration is 3.782498359680176 \n",
            "Train loss at 401 iteration is 3.944507122039795 \n",
            "Train loss at 402 iteration is 3.9327640533447266 \n",
            "Train loss at 403 iteration is 3.6637048721313477 \n",
            "Train loss at 404 iteration is 3.6734988689422607 \n",
            "Train loss at 405 iteration is 3.7869508266448975 \n",
            "Train loss at 406 iteration is 3.8140671253204346 \n",
            "Train loss at 407 iteration is 3.4221320152282715 \n",
            "Train loss at 408 iteration is 3.8185880184173584 \n",
            "Train loss at 409 iteration is 3.77358341217041 \n",
            "Train loss at 410 iteration is 3.6826486587524414 \n",
            "Train loss at 411 iteration is 3.6540300846099854 \n",
            "Train loss at 412 iteration is 3.617387533187866 \n",
            "Train loss at 413 iteration is 3.642408847808838 \n",
            "Train loss at 414 iteration is 3.8483901023864746 \n",
            "Train loss at 415 iteration is 3.6422014236450195 \n",
            "Train loss at 416 iteration is 3.7836949825286865 \n",
            "Train loss at 417 iteration is 3.737525224685669 \n",
            "Train loss at 418 iteration is 3.9760048389434814 \n",
            "Train loss at 419 iteration is 3.6772024631500244 \n",
            "Train loss at 420 iteration is 3.744633674621582 \n",
            "Train loss at 421 iteration is 3.7660226821899414 \n",
            "Train loss at 422 iteration is 3.628737449645996 \n",
            "Train loss at 423 iteration is 3.7045695781707764 \n",
            "Train loss at 424 iteration is 3.7646517753601074 \n",
            "Train loss at 425 iteration is 3.9134364128112793 \n",
            "Train loss at 426 iteration is 3.9052834510803223 \n",
            "Train loss at 427 iteration is 3.477581739425659 \n",
            "Train loss at 428 iteration is 3.537665367126465 \n",
            "Train loss at 429 iteration is 3.791388750076294 \n",
            "Train loss at 430 iteration is 3.6179072856903076 \n",
            "Train loss at 431 iteration is 3.686183452606201 \n",
            "Train loss at 432 iteration is 3.51835560798645 \n",
            "Train loss at 433 iteration is 3.5278027057647705 \n",
            "Train loss at 434 iteration is 3.8444507122039795 \n",
            "Train loss at 435 iteration is 3.764740467071533 \n",
            "Train loss at 436 iteration is 3.410172939300537 \n",
            "Train loss at 437 iteration is 3.9383115768432617 \n",
            "Train loss at 438 iteration is 3.7028753757476807 \n",
            "Train loss at 439 iteration is 3.917086362838745 \n",
            "Train loss at 440 iteration is 3.6124088764190674 \n",
            "Train loss at 441 iteration is 3.715794563293457 \n",
            "Train loss at 442 iteration is 3.7367637157440186 \n",
            "Train loss at 443 iteration is 3.8698740005493164 \n",
            "Train loss at 444 iteration is 3.9357175827026367 \n",
            "Train loss at 445 iteration is 3.4718027114868164 \n",
            "Train loss at 446 iteration is 3.835695505142212 \n",
            "Train loss at 447 iteration is 3.6453347206115723 \n",
            "Train loss at 448 iteration is 3.735718011856079 \n",
            "Train loss at 449 iteration is 3.547760009765625 \n",
            "Train loss at 450 iteration is 3.689981460571289 \n",
            "Train loss at 451 iteration is 3.9085841178894043 \n",
            "Train loss at 452 iteration is 3.8554301261901855 \n",
            "Train loss at 453 iteration is 3.5202109813690186 \n",
            "Train loss at 454 iteration is 3.6264889240264893 \n",
            "Train loss at 455 iteration is 3.7795968055725098 \n",
            "Train loss at 456 iteration is 3.4675190448760986 \n",
            "Train loss at 457 iteration is 3.8970048427581787 \n",
            "Train loss at 458 iteration is 3.6709649562835693 \n",
            "Train loss at 459 iteration is 3.653205633163452 \n",
            "Train loss at 460 iteration is 3.8532493114471436 \n",
            "Train loss at 461 iteration is 3.5967986583709717 \n",
            "Train loss at 462 iteration is 3.9292690753936768 \n",
            "Train loss at 463 iteration is 3.516719341278076 \n",
            "Train loss at 464 iteration is 3.674750566482544 \n",
            "Train loss at 465 iteration is 3.5527312755584717 \n",
            "Train loss at 466 iteration is 3.8374202251434326 \n",
            "Train loss at 467 iteration is 3.7433927059173584 \n",
            "Train loss at 468 iteration is 3.8447275161743164 \n",
            "Train loss at 469 iteration is 3.5434820652008057 \n",
            "Train loss at 470 iteration is 3.731314182281494 \n",
            "Train loss at 471 iteration is 3.8482797145843506 \n",
            "Train loss at 472 iteration is 3.7890822887420654 \n",
            "Train loss at 473 iteration is 3.5373969078063965 \n",
            "Train loss at 474 iteration is 3.5171303749084473 \n",
            "Train loss at 475 iteration is 3.5525660514831543 \n",
            "Train loss at 476 iteration is 3.5344769954681396 \n",
            "Train loss at 477 iteration is 3.682011842727661 \n",
            "Train loss at 478 iteration is 3.6816651821136475 \n",
            "Train loss at 479 iteration is 3.611069917678833 \n",
            "Train loss at 480 iteration is 3.7068943977355957 \n",
            "Train loss at 481 iteration is 3.850240707397461 \n",
            "Train loss at 482 iteration is 4.100834846496582 \n",
            "Train loss at 483 iteration is 3.7372045516967773 \n",
            "Train loss at 484 iteration is 3.753007650375366 \n",
            "Train loss at 485 iteration is 3.8105921745300293 \n",
            "Train loss at 486 iteration is 3.7469043731689453 \n",
            "Train loss at 487 iteration is 3.677943706512451 \n",
            "Train loss at 488 iteration is 3.428961992263794 \n",
            "Train loss at 489 iteration is 3.722029685974121 \n",
            "Train loss at 490 iteration is 3.7221360206604004 \n",
            "Train loss at 491 iteration is 3.87532377243042 \n",
            "Train loss at 492 iteration is 3.711913824081421 \n",
            "Train loss at 493 iteration is 3.7479348182678223 \n",
            "Train loss at 494 iteration is 3.7872889041900635 \n",
            "Train loss at 495 iteration is 3.6844162940979004 \n",
            "Train loss at 496 iteration is 3.6203060150146484 \n",
            "Train loss at 497 iteration is 3.9399302005767822 \n",
            "Train loss at 498 iteration is 3.66780424118042 \n",
            "Train loss at 499 iteration is 3.5235466957092285 \n",
            "Train loss at 500 iteration is 3.5257673263549805 \n",
            "Train loss at 501 iteration is 3.5550129413604736 \n",
            "Train loss at 502 iteration is 3.5951740741729736 \n",
            "Train loss at 503 iteration is 3.710293769836426 \n",
            "Train loss at 504 iteration is 3.598932981491089 \n",
            "Train loss at 505 iteration is 3.7311747074127197 \n",
            "Train loss at 506 iteration is 3.591858148574829 \n",
            "Train loss at 507 iteration is 3.690119743347168 \n",
            "Train loss at 508 iteration is 3.7593588829040527 \n",
            "Train loss at 509 iteration is 3.8164241313934326 \n",
            "Train loss at 510 iteration is 3.8667619228363037 \n",
            "Train loss at 511 iteration is 3.6785194873809814 \n",
            "Train loss at 512 iteration is 3.7866835594177246 \n",
            "Train loss at 513 iteration is 3.866180896759033 \n",
            "Train loss at 514 iteration is 3.8760640621185303 \n",
            "Train loss at 515 iteration is 4.069925785064697 \n",
            "Train loss at 516 iteration is 3.631870746612549 \n",
            "Train loss at 517 iteration is 3.761404514312744 \n",
            "Train loss at 518 iteration is 3.673733949661255 \n",
            "Train loss at 519 iteration is 3.7910311222076416 \n",
            "Train loss at 520 iteration is 3.546950101852417 \n",
            "Train loss at 521 iteration is 3.769876003265381 \n",
            "Train loss at 522 iteration is 3.492692232131958 \n",
            "Train loss at 523 iteration is 3.726060628890991 \n",
            "Train loss at 524 iteration is 3.5802857875823975 \n",
            "Train loss at 525 iteration is 3.8346776962280273 \n",
            "Train loss at 526 iteration is 3.6727328300476074 \n",
            "Train loss at 527 iteration is 3.8097426891326904 \n",
            "Train loss at 528 iteration is 3.99875545501709 \n",
            "Train loss at 529 iteration is 3.7916274070739746 \n",
            "Train loss at 530 iteration is 3.6807949542999268 \n",
            "Train loss at 531 iteration is 3.4503986835479736 \n",
            "Train loss at 532 iteration is 3.859264612197876 \n",
            "Train loss at 533 iteration is 3.7168779373168945 \n",
            "Train loss at 534 iteration is 3.4919075965881348 \n",
            "Train loss at 535 iteration is 3.705460786819458 \n",
            "Train loss at 536 iteration is 3.718690872192383 \n",
            "Train loss at 537 iteration is 3.685494899749756 \n",
            "Train loss at 538 iteration is 4.113306045532227 \n",
            "Train loss at 539 iteration is 3.5669569969177246 \n",
            "Train loss at 540 iteration is 3.7112746238708496 \n",
            "Train loss at 541 iteration is 3.515791654586792 \n",
            "Train loss at 542 iteration is 3.6678481101989746 \n",
            "Train loss at 543 iteration is 3.7090349197387695 \n",
            "Train loss at 544 iteration is 3.841738700866699 \n",
            "Train loss at 545 iteration is 3.6504039764404297 \n",
            "Train loss at 546 iteration is 3.791750907897949 \n",
            "Train loss at 547 iteration is 3.6669561862945557 \n",
            "Train loss at 548 iteration is 3.980236530303955 \n",
            "Train loss at 549 iteration is 3.7803943157196045 \n",
            "Train loss at 550 iteration is 3.6281981468200684 \n",
            "Train loss at 551 iteration is 3.7352781295776367 \n",
            "Train loss at 552 iteration is 3.6463489532470703 \n",
            "Train loss at 553 iteration is 3.697286605834961 \n",
            "Train loss at 554 iteration is 3.6200523376464844 \n",
            "Train loss at 555 iteration is 3.6321921348571777 \n",
            "Train loss at 556 iteration is 3.628221035003662 \n",
            "Train loss at 557 iteration is 3.5346364974975586 \n",
            "Train loss at 558 iteration is 3.6351664066314697 \n",
            "Train loss at 559 iteration is 3.5601022243499756 \n",
            "Train loss at 560 iteration is 3.532712936401367 \n",
            "Train loss at 561 iteration is 3.7656469345092773 \n",
            "Train loss at 562 iteration is 3.738663673400879 \n",
            "Train loss at 563 iteration is 3.828320264816284 \n",
            "Train loss at 564 iteration is 3.5696840286254883 \n",
            "Train loss at 565 iteration is 3.7410826683044434 \n",
            "Train loss at 566 iteration is 3.718055009841919 \n",
            "Train loss at 567 iteration is 3.801426410675049 \n",
            "Train loss at 568 iteration is 3.810720205307007 \n",
            "Train loss at 569 iteration is 3.802121639251709 \n",
            "Train loss at 570 iteration is 3.7332096099853516 \n",
            "Train loss at 571 iteration is 3.79034161567688 \n",
            "Train loss at 572 iteration is 3.5225956439971924 \n",
            "Train loss at 573 iteration is 3.738949775695801 \n",
            "Train loss at 574 iteration is 3.5445709228515625 \n",
            "Train loss at 575 iteration is 3.4787023067474365 \n",
            "Train loss at 576 iteration is 3.621570587158203 \n",
            "Train loss at 577 iteration is 3.753249406814575 \n",
            "Train loss at 578 iteration is 3.782799243927002 \n",
            "Train loss at 579 iteration is 3.8497352600097656 \n",
            "Train loss at 580 iteration is 3.8013288974761963 \n",
            "Train loss at 581 iteration is 3.7272462844848633 \n",
            "Train loss at 582 iteration is 3.786566734313965 \n",
            "Train loss at 583 iteration is 3.640331506729126 \n",
            "Train loss at 584 iteration is 3.5189976692199707 \n",
            "Train loss at 585 iteration is 3.8749141693115234 \n",
            "Train loss at 586 iteration is 3.8050639629364014 \n",
            "Train loss at 587 iteration is 3.6370084285736084 \n",
            "Train loss at 588 iteration is 3.6167185306549072 \n",
            "Train loss at 589 iteration is 3.733888626098633 \n",
            "Train loss at 590 iteration is 3.52091646194458 \n",
            "Train loss at 591 iteration is 3.4540112018585205 \n",
            "Train loss at 592 iteration is 3.717742681503296 \n",
            "Train loss at 593 iteration is 3.609867811203003 \n",
            "Train loss at 594 iteration is 3.7795674800872803 \n",
            "Train loss at 595 iteration is 3.571294069290161 \n",
            "Train loss at 596 iteration is 3.702291965484619 \n",
            "Train loss at 597 iteration is 3.6524598598480225 \n",
            "Train loss at 598 iteration is 3.5657498836517334 \n",
            "Train loss at 599 iteration is 3.757695436477661 \n",
            "Train loss at 600 iteration is 3.7345235347747803 \n",
            "Train loss at 601 iteration is 3.6516222953796387 \n",
            "Train loss at 602 iteration is 3.6207714080810547 \n",
            "Train loss at 603 iteration is 3.699266195297241 \n",
            "Train loss at 604 iteration is 3.724714994430542 \n",
            "Train loss at 605 iteration is 3.488070011138916 \n",
            "Train loss at 606 iteration is 3.5360403060913086 \n",
            "Train loss at 607 iteration is 4.051273822784424 \n",
            "Train loss at 608 iteration is 3.6405322551727295 \n",
            "Train loss at 609 iteration is 3.5577783584594727 \n",
            "Train loss at 610 iteration is 3.940453290939331 \n",
            "Train loss at 611 iteration is 3.674372911453247 \n",
            "Train loss at 612 iteration is 3.589524745941162 \n",
            "Train loss at 613 iteration is 3.704589366912842 \n",
            "Train loss at 614 iteration is 3.665175199508667 \n",
            "Train loss at 615 iteration is 3.8047969341278076 \n",
            "Train loss at 616 iteration is 3.8147425651550293 \n",
            "Train loss at 617 iteration is 3.7663285732269287 \n",
            "Train loss at 618 iteration is 3.8043668270111084 \n",
            "Train loss at 619 iteration is 3.660576343536377 \n",
            "Train loss at 620 iteration is 3.53896164894104 \n",
            "Train loss at 621 iteration is 3.6870193481445312 \n",
            "Train loss at 622 iteration is 3.8832223415374756 \n",
            "Train loss at 623 iteration is 3.7448527812957764 \n",
            "Train loss at 624 iteration is 3.6482977867126465 \n",
            "Train loss at 625 iteration is 3.527738571166992 \n",
            "Train loss at 626 iteration is 3.6562745571136475 \n",
            "Train loss at 627 iteration is 3.6488711833953857 \n",
            "Train loss at 628 iteration is 3.629269599914551 \n",
            "Train loss at 629 iteration is 3.727729082107544 \n",
            "Train loss at 630 iteration is 3.5553348064422607 \n",
            "Train loss at 631 iteration is 3.7457425594329834 \n",
            "Train loss at 632 iteration is 3.8121159076690674 \n",
            "Train loss at 633 iteration is 3.714404821395874 \n",
            "Train loss at 634 iteration is 3.4435415267944336 \n",
            "Train loss at 635 iteration is 3.720755100250244 \n",
            "Train loss at 636 iteration is 3.5407192707061768 \n",
            "Train loss at 637 iteration is 3.537166118621826 \n",
            "Train loss at 638 iteration is 3.743166208267212 \n",
            "Train loss at 639 iteration is 3.7792420387268066 \n",
            "Train loss at 640 iteration is 3.5722968578338623 \n",
            "Train loss at 641 iteration is 3.4370577335357666 \n",
            "Train loss at 642 iteration is 3.6669201850891113 \n",
            "Train loss at 643 iteration is 3.66239333152771 \n",
            "Train loss at 644 iteration is 3.94999623298645 \n",
            "Train loss at 645 iteration is 3.873997449874878 \n",
            "Train loss at 646 iteration is 3.753084182739258 \n",
            "Train loss at 647 iteration is 3.7276101112365723 \n",
            "Train loss at 648 iteration is 3.6010773181915283 \n",
            "Train loss at 649 iteration is 3.684828042984009 \n",
            "Train loss at 650 iteration is 3.5341053009033203 \n",
            "Train loss at 651 iteration is 3.6623644828796387 \n",
            "Train loss at 652 iteration is 3.75465726852417 \n",
            "Train loss at 653 iteration is 3.6565120220184326 \n",
            "Train loss at 654 iteration is 3.636542797088623 \n",
            "Train loss at 655 iteration is 3.585162878036499 \n",
            "Train loss at 656 iteration is 3.6810314655303955 \n",
            "Train loss at 657 iteration is 3.3955023288726807 \n",
            "Train loss at 658 iteration is 3.692220449447632 \n",
            "Train loss at 659 iteration is 3.7663774490356445 \n",
            "Train loss at 660 iteration is 3.594625234603882 \n",
            "Train loss at 661 iteration is 3.417100429534912 \n",
            "Train loss at 662 iteration is 3.413607597351074 \n",
            "Train loss at 663 iteration is 3.6732542514801025 \n",
            "Train loss at 664 iteration is 3.547527313232422 \n",
            "Train loss at 665 iteration is 3.659029960632324 \n",
            "Train loss at 666 iteration is 3.8649520874023438 \n",
            "Train loss at 667 iteration is 3.5959041118621826 \n",
            "Train loss at 668 iteration is 3.639512538909912 \n",
            "Train loss at 669 iteration is 3.709871768951416 \n",
            "Train loss at 670 iteration is 3.8707175254821777 \n",
            "Train loss at 671 iteration is 3.3740222454071045 \n",
            "Train loss at 672 iteration is 3.635512351989746 \n",
            "Train loss at 673 iteration is 3.680915355682373 \n",
            "Train loss at 674 iteration is 3.5667216777801514 \n",
            "Train loss at 675 iteration is 3.5531554222106934 \n",
            "Train loss at 676 iteration is 3.9511735439300537 \n",
            "Train loss at 677 iteration is 3.8588955402374268 \n",
            "Train loss at 678 iteration is 3.556143283843994 \n",
            "Train loss at 679 iteration is 3.921560287475586 \n",
            "Train loss at 680 iteration is 3.616929531097412 \n",
            "Train loss at 681 iteration is 3.8883862495422363 \n",
            "Train loss at 682 iteration is 3.7100555896759033 \n",
            "Train loss at 683 iteration is 3.617619276046753 \n",
            "Train loss at 684 iteration is 3.763615369796753 \n",
            "Train loss at 685 iteration is 3.676712989807129 \n",
            "Train loss at 686 iteration is 3.8107151985168457 \n",
            "Train loss at 687 iteration is 3.543910264968872 \n",
            "Train loss at 688 iteration is 3.789889335632324 \n",
            "Train loss at 689 iteration is 3.772972345352173 \n",
            "Train loss at 690 iteration is 3.680149555206299 \n",
            "Train loss at 691 iteration is 3.5889852046966553 \n",
            "Train loss at 692 iteration is 3.5688014030456543 \n",
            "Train loss at 693 iteration is 3.460045576095581 \n",
            "Train loss at 694 iteration is 3.5079216957092285 \n",
            "Train loss at 695 iteration is 3.433561325073242 \n",
            "Train loss at 696 iteration is 3.6057000160217285 \n",
            "Train loss at 697 iteration is 3.6921844482421875 \n",
            "Train loss at 698 iteration is 3.5879578590393066 \n",
            "Train loss at 699 iteration is 3.5756561756134033 \n",
            "Train loss at 700 iteration is 3.693567991256714 \n",
            "Train loss at 701 iteration is 3.674758195877075 \n",
            "Train loss at 702 iteration is 3.4874539375305176 \n",
            "Train loss at 703 iteration is 3.6734182834625244 \n",
            "Train loss at 704 iteration is 3.6440470218658447 \n",
            "Train loss at 705 iteration is 3.8299567699432373 \n",
            "Train loss at 706 iteration is 3.5790297985076904 \n",
            "Train loss at 707 iteration is 3.7277729511260986 \n",
            "Train loss at 708 iteration is 3.4509973526000977 \n",
            "Train loss at 709 iteration is 3.3684747219085693 \n",
            "Train loss at 710 iteration is 3.4921486377716064 \n",
            "Train loss at 711 iteration is 3.800708770751953 \n",
            "Train loss at 712 iteration is 3.5876963138580322 \n",
            "Train loss at 713 iteration is 3.499631643295288 \n",
            "Train loss at 714 iteration is 3.497816324234009 \n",
            "Train loss at 715 iteration is 3.7542576789855957 \n",
            "Train loss at 716 iteration is 3.7154369354248047 \n",
            "Train loss at 717 iteration is 3.6805601119995117 \n",
            "Train loss at 718 iteration is 3.5081253051757812 \n",
            "Train loss at 719 iteration is 3.650709390640259 \n",
            "Train loss at 720 iteration is 3.656548023223877 \n",
            "Train loss at 721 iteration is 3.750465154647827 \n",
            "Train loss at 722 iteration is 3.726836681365967 \n",
            "Train loss at 723 iteration is 3.718761920928955 \n",
            "Train loss at 724 iteration is 3.4865455627441406 \n",
            "Train loss at 725 iteration is 3.6576809883117676 \n",
            "Train loss at 726 iteration is 3.8059139251708984 \n",
            "Train loss at 727 iteration is 3.648512363433838 \n",
            "Train loss at 728 iteration is 3.622983694076538 \n",
            "Train loss at 729 iteration is 3.5319600105285645 \n",
            "Train loss at 730 iteration is 3.7221853733062744 \n",
            "Train loss at 731 iteration is 3.337583065032959 \n",
            "Train loss at 732 iteration is 3.712040901184082 \n",
            "Train loss at 733 iteration is 3.660093069076538 \n",
            "Train loss at 734 iteration is 3.546416759490967 \n",
            "Train loss at 735 iteration is 3.484936475753784 \n",
            "Train loss at 736 iteration is 3.567978858947754 \n",
            "Train loss at 737 iteration is 3.642801523208618 \n",
            "Train loss at 738 iteration is 3.5327744483947754 \n",
            "Train loss at 739 iteration is 3.5390706062316895 \n",
            "Train loss at 740 iteration is 3.867196559906006 \n",
            "Train loss at 741 iteration is 3.5604231357574463 \n",
            "Train loss at 742 iteration is 3.7751386165618896 \n",
            "Train loss at 743 iteration is 3.9283809661865234 \n",
            "Train loss at 744 iteration is 3.4598355293273926 \n",
            "Train loss at 745 iteration is 3.6057116985321045 \n",
            "Train loss at 746 iteration is 3.679534673690796 \n",
            "Train loss at 747 iteration is 3.550463914871216 \n",
            "Train loss at 748 iteration is 3.572610378265381 \n",
            "Train loss at 749 iteration is 3.689462423324585 \n",
            "Train loss at 750 iteration is 3.6633286476135254 \n",
            "Train loss at 751 iteration is 3.623539924621582 \n",
            "Train loss at 752 iteration is 3.7212564945220947 \n",
            "Train loss at 753 iteration is 3.6715667247772217 \n",
            "Train loss at 754 iteration is 3.6554176807403564 \n",
            "Train loss at 755 iteration is 3.895258665084839 \n",
            "Train loss at 756 iteration is 3.6266396045684814 \n",
            "Train loss at 757 iteration is 3.7052369117736816 \n",
            "Train loss at 758 iteration is 3.753455877304077 \n",
            "Train loss at 759 iteration is 3.641068935394287 \n",
            "Train loss at 760 iteration is 3.61314058303833 \n",
            "Train loss at 761 iteration is 3.6839888095855713 \n",
            "Train loss at 762 iteration is 3.7040610313415527 \n",
            "Train loss at 763 iteration is 3.6647870540618896 \n",
            "Train loss at 764 iteration is 3.622152805328369 \n",
            "Train loss at 765 iteration is 3.841387987136841 \n",
            "Train loss at 766 iteration is 3.5212607383728027 \n",
            "Train loss at 767 iteration is 3.699916124343872 \n",
            "Train loss at 768 iteration is 3.5622012615203857 \n",
            "Train loss at 769 iteration is 3.7023136615753174 \n",
            "Train loss at 770 iteration is 3.6460678577423096 \n",
            "Train loss at 771 iteration is 3.813762903213501 \n",
            "Train loss at 772 iteration is 3.6861026287078857 \n",
            "Train loss at 773 iteration is 3.577174186706543 \n",
            "Train loss at 774 iteration is 3.6136040687561035 \n",
            "Train loss at 775 iteration is 3.3552534580230713 \n",
            "Train loss at 776 iteration is 3.6612422466278076 \n",
            "Train loss at 777 iteration is 3.7517800331115723 \n",
            "Train loss at 778 iteration is 3.5603408813476562 \n",
            "Train loss at 779 iteration is 3.7036471366882324 \n",
            "Train loss at 780 iteration is 3.6041719913482666 \n",
            "Train loss at 781 iteration is 3.7761592864990234 \n",
            "Train loss at 782 iteration is 3.708385467529297 \n",
            "Train loss at 783 iteration is 3.8499088287353516 \n",
            "Train loss at 784 iteration is 3.5387628078460693 \n",
            "Train loss at 785 iteration is 3.7516286373138428 \n",
            "Train loss at 786 iteration is 3.6517794132232666 \n",
            "Train loss at 787 iteration is 3.6082165241241455 \n",
            "Train loss at 788 iteration is 3.6499524116516113 \n",
            "Train loss at 789 iteration is 3.4293861389160156 \n",
            "Train loss at 790 iteration is 3.606386184692383 \n",
            "Train loss at 791 iteration is 3.4696033000946045 \n",
            "Train loss at 792 iteration is 3.683143377304077 \n",
            "Train loss at 793 iteration is 3.7137057781219482 \n",
            "Train loss at 794 iteration is 3.6626570224761963 \n",
            "Train loss at 795 iteration is 3.714188814163208 \n",
            "Train loss at 796 iteration is 3.7459020614624023 \n",
            "Train loss at 797 iteration is 3.4898722171783447 \n",
            "Train loss at 798 iteration is 3.4981131553649902 \n",
            "Train loss at 799 iteration is 3.444173574447632 \n",
            "Train loss at 800 iteration is 3.4809811115264893 \n",
            "Train loss at 801 iteration is 3.6241633892059326 \n",
            "Train loss at 802 iteration is 3.6220767498016357 \n",
            "Train loss at 803 iteration is 3.8370048999786377 \n",
            "Train loss at 804 iteration is 3.485074758529663 \n",
            "Train loss at 805 iteration is 3.78444766998291 \n",
            "Train loss at 806 iteration is 3.500481367111206 \n",
            "Train loss at 807 iteration is 3.60980486869812 \n",
            "Train loss at 808 iteration is 3.5658323764801025 \n",
            "Train loss at 809 iteration is 3.60180401802063 \n",
            "Train loss at 810 iteration is 3.792741060256958 \n",
            "Train loss at 811 iteration is 3.447263240814209 \n",
            "Train loss at 812 iteration is 3.7231476306915283 \n",
            "Train loss at 813 iteration is 3.658555269241333 \n",
            "Train loss at 814 iteration is 3.4691271781921387 \n",
            "Train loss at 815 iteration is 3.7340476512908936 \n",
            "Train loss at 816 iteration is 3.47938871383667 \n",
            "Train loss at 817 iteration is 3.5678794384002686 \n",
            "Train loss at 818 iteration is 3.4384748935699463 \n",
            "Train loss at 819 iteration is 3.8032124042510986 \n",
            "Train loss at 820 iteration is 3.6917548179626465 \n",
            "Train loss at 821 iteration is 3.6812925338745117 \n",
            "Train loss at 822 iteration is 3.7152445316314697 \n",
            "Train loss at 823 iteration is 3.69467830657959 \n",
            "Train loss at 824 iteration is 3.812268018722534 \n",
            "Train loss at 825 iteration is 3.734588384628296 \n",
            "Train loss at 826 iteration is 3.580500364303589 \n",
            "Train loss at 827 iteration is 3.629236936569214 \n",
            "Train loss at 828 iteration is 3.658607006072998 \n",
            "Train loss at 829 iteration is 3.4542250633239746 \n",
            "Train loss at 830 iteration is 3.786726474761963 \n",
            "Train loss at 831 iteration is 3.265178680419922 \n",
            "Train loss at 832 iteration is 3.6352832317352295 \n",
            "Train loss at 833 iteration is 3.4654979705810547 \n",
            "Train loss at 834 iteration is 3.7094807624816895 \n",
            "Train loss at 835 iteration is 3.769049882888794 \n",
            "Train loss at 836 iteration is 3.547764539718628 \n",
            "Train loss at 837 iteration is 3.749244451522827 \n",
            "Train loss at 838 iteration is 3.473768949508667 \n",
            "Train loss at 839 iteration is 3.497494697570801 \n",
            "Train loss at 840 iteration is 3.8131179809570312 \n",
            "Train loss at 841 iteration is 3.519472599029541 \n",
            "Train loss at 842 iteration is 3.520495653152466 \n",
            "Train loss at 843 iteration is 3.44454288482666 \n",
            "Train loss at 844 iteration is 3.672025442123413 \n",
            "Train loss at 845 iteration is 3.541142225265503 \n",
            "Train loss at 846 iteration is 3.639251947402954 \n",
            "Train loss at 847 iteration is 3.480966329574585 \n",
            "Train loss at 848 iteration is 3.9003570079803467 \n",
            "Train loss at 849 iteration is 3.5354788303375244 \n",
            "Train loss at 850 iteration is 3.548628330230713 \n",
            "Train loss at 851 iteration is 3.5585837364196777 \n",
            "Train loss at 852 iteration is 3.695119619369507 \n",
            "Train loss at 853 iteration is 3.540053367614746 \n",
            "Train loss at 854 iteration is 3.773345708847046 \n",
            "Train loss at 855 iteration is 3.4510440826416016 \n",
            "Train loss at 856 iteration is 3.6259753704071045 \n",
            "Train loss at 857 iteration is 3.6924777030944824 \n",
            "Train loss at 858 iteration is 3.4116148948669434 \n",
            "Train loss at 859 iteration is 3.5316667556762695 \n",
            "Train loss at 860 iteration is 3.582169532775879 \n",
            "Train loss at 861 iteration is 3.488483190536499 \n",
            "Train loss at 862 iteration is 3.6029632091522217 \n",
            "Train loss at 863 iteration is 3.5075392723083496 \n",
            "Train loss at 864 iteration is 3.7450613975524902 \n",
            "Train loss at 865 iteration is 3.416285753250122 \n",
            "Train loss at 866 iteration is 3.4588723182678223 \n",
            "Train loss at 867 iteration is 3.7016663551330566 \n",
            "Train loss at 868 iteration is 3.29805850982666 \n",
            "Train loss at 869 iteration is 3.732598066329956 \n",
            "Train loss at 870 iteration is 3.4845919609069824 \n",
            "Train loss at 871 iteration is 3.179105281829834 \n",
            "Train loss at 872 iteration is 3.5072810649871826 \n",
            "Train loss at 873 iteration is 3.720186471939087 \n",
            "Train loss at 874 iteration is 3.567077398300171 \n",
            "Train loss at 875 iteration is 3.519338846206665 \n",
            "Train loss at 876 iteration is 3.92645525932312 \n",
            "Train loss at 877 iteration is 3.9083690643310547 \n",
            "Train loss at 878 iteration is 4.004805088043213 \n",
            "Train loss at 879 iteration is 3.5357112884521484 \n",
            "Train loss at 880 iteration is 3.883209466934204 \n",
            "Train loss at 881 iteration is 3.406363010406494 \n",
            "Train loss at 882 iteration is 3.8360307216644287 \n",
            "Train loss at 883 iteration is 3.7156741619110107 \n",
            "Train loss at 884 iteration is 3.7833523750305176 \n",
            "Train loss at 885 iteration is 3.4043824672698975 \n",
            "Train loss at 886 iteration is 3.8190102577209473 \n",
            "Train loss at 887 iteration is 3.611778736114502 \n",
            "Train loss at 888 iteration is 3.4721872806549072 \n",
            "Train loss at 889 iteration is 3.495814800262451 \n",
            "Train loss at 890 iteration is 3.726311206817627 \n",
            "Train loss at 891 iteration is 3.69022274017334 \n",
            "Train loss at 892 iteration is 3.360217571258545 \n",
            "Train loss at 893 iteration is 3.730649709701538 \n",
            "Train loss at 894 iteration is 3.585347890853882 \n",
            "Train loss at 895 iteration is 3.6436562538146973 \n",
            "Train loss at 896 iteration is 3.2072877883911133 \n",
            "Train loss at 897 iteration is 3.209120273590088 \n",
            "Train loss at 898 iteration is 3.5730271339416504 \n",
            "Train loss at 899 iteration is 3.2728400230407715 \n",
            "Train loss at 900 iteration is 3.5401816368103027 \n",
            "Train loss at 901 iteration is 3.348519802093506 \n",
            "Train loss at 902 iteration is 3.5782012939453125 \n",
            "Train loss at 903 iteration is 3.3827812671661377 \n",
            "Train loss at 904 iteration is 3.336920976638794 \n",
            "Train loss at 905 iteration is 3.3217997550964355 \n",
            "Train loss at 906 iteration is 3.4300689697265625 \n",
            "Train loss at 907 iteration is 3.4416496753692627 \n",
            "Train loss at 908 iteration is 3.3527417182922363 \n",
            "Train loss at 909 iteration is 3.507620334625244 \n",
            "Train loss at 910 iteration is 3.298276424407959 \n",
            "Train loss at 911 iteration is 3.5539443492889404 \n",
            "Train loss at 912 iteration is 3.342672109603882 \n",
            "Train loss at 913 iteration is 3.3464248180389404 \n",
            "Train loss at 914 iteration is 3.3060171604156494 \n",
            "Train loss at 915 iteration is 3.1787352561950684 \n",
            "Train loss at 916 iteration is 3.2907960414886475 \n",
            "Train loss at 917 iteration is 3.587472915649414 \n",
            "Train loss at 918 iteration is 3.358236074447632 \n",
            "Train loss at 919 iteration is 3.2188546657562256 \n",
            "Train loss at 920 iteration is 3.450916051864624 \n",
            "Train loss at 921 iteration is 3.4913346767425537 \n",
            "Train loss at 922 iteration is 3.3346340656280518 \n",
            "Train loss at 923 iteration is 3.5172829627990723 \n",
            "Train loss at 924 iteration is 3.473677635192871 \n",
            "Train loss at 925 iteration is 3.7089734077453613 \n",
            "Train loss at 926 iteration is 3.2324399948120117 \n",
            "Train loss at 927 iteration is 3.237271785736084 \n",
            "Train loss at 928 iteration is 3.3344430923461914 \n",
            "Train loss at 929 iteration is 3.5930745601654053 \n",
            "Train loss at 930 iteration is 3.2784931659698486 \n",
            "Train loss at 931 iteration is 3.418379545211792 \n",
            "Train loss at 932 iteration is 3.3355603218078613 \n",
            "Train loss at 933 iteration is 3.2689456939697266 \n",
            "Train loss at 934 iteration is 3.3334271907806396 \n",
            "Train loss at 935 iteration is 3.3082780838012695 \n",
            "Train loss at 936 iteration is 3.166754961013794 \n",
            "Train loss at 937 iteration is 3.246715784072876 \n",
            "Train loss at 938 iteration is 3.231184482574463 \n",
            "Train loss at 939 iteration is 3.273141384124756 \n",
            "Train loss at 940 iteration is 3.3989179134368896 \n",
            "Train loss at 941 iteration is 3.650624990463257 \n",
            "Train loss at 942 iteration is 3.156484603881836 \n",
            "Train loss at 943 iteration is 3.4907195568084717 \n",
            "Train loss at 944 iteration is 3.21136212348938 \n",
            "Train loss at 945 iteration is 3.4375994205474854 \n",
            "Train loss at 946 iteration is 3.1417343616485596 \n",
            "Train loss at 947 iteration is 3.2927966117858887 \n",
            "Train loss at 948 iteration is 3.4425435066223145 \n",
            "Train loss at 949 iteration is 3.428342819213867 \n",
            "Train loss at 950 iteration is 3.423234701156616 \n",
            "Train loss at 951 iteration is 3.5936498641967773 \n",
            "Train loss at 952 iteration is 3.5947670936584473 \n",
            "Train loss at 953 iteration is 3.4389936923980713 \n",
            "Train loss at 954 iteration is 3.252988338470459 \n",
            "Train loss at 955 iteration is 3.5290145874023438 \n",
            "Train loss at 956 iteration is 3.4437341690063477 \n",
            "Train loss at 957 iteration is 3.7453577518463135 \n",
            "Train loss at 958 iteration is 3.566986083984375 \n",
            "Train loss at 959 iteration is 3.630681037902832 \n",
            "Train loss at 960 iteration is 3.1279137134552 \n",
            "Train loss at 961 iteration is 3.3382625579833984 \n",
            "Train loss at 962 iteration is 3.5362777709960938 \n",
            "Train loss at 963 iteration is 3.2753801345825195 \n",
            "Train loss at 964 iteration is 3.6644527912139893 \n",
            "Train loss at 965 iteration is 3.4917118549346924 \n",
            "Train loss at 966 iteration is 3.528761386871338 \n",
            "Train loss at 967 iteration is 3.565551519393921 \n",
            "Train loss at 968 iteration is 3.2671802043914795 \n",
            "Train loss at 969 iteration is 3.506845235824585 \n",
            "Train loss at 970 iteration is 3.209245443344116 \n",
            "Train loss at 971 iteration is 3.3873488903045654 \n",
            "Train loss at 972 iteration is 3.338304281234741 \n",
            "Train loss at 973 iteration is 3.346334218978882 \n",
            "Train loss at 974 iteration is 3.4653968811035156 \n",
            "Train loss at 975 iteration is 3.6168296337127686 \n",
            "Train loss at 976 iteration is 3.537991523742676 \n",
            "Train loss at 977 iteration is 3.4002456665039062 \n",
            "Train loss at 978 iteration is 3.3352901935577393 \n",
            "Train loss at 979 iteration is 3.2995755672454834 \n",
            "Train loss at 980 iteration is 3.5817949771881104 \n",
            "Train loss at 981 iteration is 3.4332802295684814 \n",
            "Train loss at 982 iteration is 3.4907655715942383 \n",
            "Train loss at 983 iteration is 3.3789939880371094 \n",
            "Train loss at 984 iteration is 3.353564739227295 \n",
            "Train loss at 985 iteration is 3.5888469219207764 \n",
            "Train loss at 986 iteration is 3.436964273452759 \n",
            "Train loss at 987 iteration is 3.4700927734375 \n",
            "Train loss at 988 iteration is 3.4310319423675537 \n",
            "Train loss at 989 iteration is 3.5352628231048584 \n",
            "Train loss at 990 iteration is 3.296015501022339 \n",
            "Train loss at 991 iteration is 3.518325090408325 \n",
            "Train loss at 992 iteration is 3.392971992492676 \n",
            "Train loss at 993 iteration is 3.4833004474639893 \n",
            "Train loss at 994 iteration is 3.2890024185180664 \n",
            "Train loss at 995 iteration is 3.4280552864074707 \n",
            "Train loss at 996 iteration is 3.235705852508545 \n",
            "Train loss at 997 iteration is 3.4392220973968506 \n",
            "Train loss at 998 iteration is 3.342931032180786 \n",
            "Train loss at 999 iteration is 3.4954769611358643 \n",
            "Train loss at 1000 iteration is 3.3837125301361084 \n",
            "Train loss at 1001 iteration is 3.4224085807800293 \n",
            "Train loss at 1002 iteration is 3.400629997253418 \n",
            "Train loss at 1003 iteration is 3.463162660598755 \n",
            "Train loss at 1004 iteration is 3.573826551437378 \n",
            "Train loss at 1005 iteration is 3.646528482437134 \n",
            "Train loss at 1006 iteration is 3.2008726596832275 \n",
            "Train loss at 1007 iteration is 3.41241192817688 \n",
            "Train loss at 1008 iteration is 3.452781915664673 \n",
            "Train loss at 1009 iteration is 3.1881048679351807 \n",
            "Train loss at 1010 iteration is 3.532167673110962 \n",
            "Train loss at 1011 iteration is 3.513375759124756 \n",
            "Train loss at 1012 iteration is 3.421030282974243 \n",
            "Train loss at 1013 iteration is 3.397622585296631 \n",
            "Train loss at 1014 iteration is 3.4535975456237793 \n",
            "Train loss at 1015 iteration is 3.347837448120117 \n",
            "Train loss at 1016 iteration is 3.4960601329803467 \n",
            "Train loss at 1017 iteration is 3.5688681602478027 \n",
            "Train loss at 1018 iteration is 3.40348219871521 \n",
            "Train loss at 1019 iteration is 3.5750248432159424 \n",
            "Train loss at 1020 iteration is 3.554582357406616 \n",
            "Train loss at 1021 iteration is 3.490981340408325 \n",
            "Train loss at 1022 iteration is 3.440764904022217 \n",
            "Train loss at 1023 iteration is 3.361793041229248 \n",
            "Train loss at 1024 iteration is 3.553816795349121 \n",
            "Train loss at 1025 iteration is 3.4597928524017334 \n",
            "Train loss at 1026 iteration is 3.4252045154571533 \n",
            "Train loss at 1027 iteration is 3.368563175201416 \n",
            "Train loss at 1028 iteration is 3.6881816387176514 \n",
            "Train loss at 1029 iteration is 3.4577927589416504 \n",
            "Train loss at 1030 iteration is 3.3389549255371094 \n",
            "Train loss at 1031 iteration is 3.4004859924316406 \n",
            "Train loss at 1032 iteration is 3.6164560317993164 \n",
            "Train loss at 1033 iteration is 3.491157293319702 \n",
            "Train loss at 1034 iteration is 3.476991653442383 \n",
            "Train loss at 1035 iteration is 3.5096914768218994 \n",
            "Train loss at 1036 iteration is 3.554914712905884 \n",
            "Train loss at 1037 iteration is 3.537310838699341 \n",
            "Train loss at 1038 iteration is 3.593531608581543 \n",
            "Train loss at 1039 iteration is 3.4115898609161377 \n",
            "Train loss at 1040 iteration is 3.5399701595306396 \n",
            "Train loss at 1041 iteration is 3.4429304599761963 \n",
            "Train loss at 1042 iteration is 3.4030516147613525 \n",
            "Train loss at 1043 iteration is 3.307211399078369 \n",
            "Train loss at 1044 iteration is 3.344215154647827 \n",
            "Train loss at 1045 iteration is 3.4593300819396973 \n",
            "Train loss at 1046 iteration is 3.297787666320801 \n",
            "Train loss at 1047 iteration is 3.419569492340088 \n",
            "Train loss at 1048 iteration is 3.628314733505249 \n",
            "Train loss at 1049 iteration is 3.4430747032165527 \n",
            "Train loss at 1050 iteration is 3.597925901412964 \n",
            "Train loss at 1051 iteration is 3.3044803142547607 \n",
            "Train loss at 1052 iteration is 3.412477493286133 \n",
            "Train loss at 1053 iteration is 3.637017250061035 \n",
            "Train loss at 1054 iteration is 3.40667462348938 \n",
            "Train loss at 1055 iteration is 3.534641981124878 \n",
            "Train loss at 1056 iteration is 3.5898728370666504 \n",
            "Train loss at 1057 iteration is 3.457692861557007 \n",
            "Train loss at 1058 iteration is 3.3442866802215576 \n",
            "Train loss at 1059 iteration is 3.540541410446167 \n",
            "Train loss at 1060 iteration is 3.265848398208618 \n",
            "Train loss at 1061 iteration is 3.3636844158172607 \n",
            "Train loss at 1062 iteration is 3.436746597290039 \n",
            "Train loss at 1063 iteration is 3.470750331878662 \n",
            "Train loss at 1064 iteration is 3.3700308799743652 \n",
            "Train loss at 1065 iteration is 3.4865686893463135 \n",
            "Train loss at 1066 iteration is 3.4079811573028564 \n",
            "Train loss at 1067 iteration is 3.3395113945007324 \n",
            "Train loss at 1068 iteration is 3.4808943271636963 \n",
            "Train loss at 1069 iteration is 3.5067145824432373 \n",
            "Train loss at 1070 iteration is 3.328488349914551 \n",
            "Train loss at 1071 iteration is 3.517394781112671 \n",
            "Train loss at 1072 iteration is 3.5558652877807617 \n",
            "Train loss at 1073 iteration is 3.670525550842285 \n",
            "Train loss at 1074 iteration is 3.476151704788208 \n",
            "Train loss at 1075 iteration is 2.9097554683685303 \n",
            "Train loss at 1076 iteration is 3.4956259727478027 \n",
            "Train loss at 1077 iteration is 3.2030417919158936 \n",
            "Train loss at 1078 iteration is 3.331895112991333 \n",
            "Train loss at 1079 iteration is 3.5113584995269775 \n",
            "Train loss at 1080 iteration is 3.414214849472046 \n",
            "Train loss at 1081 iteration is 3.540733575820923 \n",
            "Train loss at 1082 iteration is 3.360281229019165 \n",
            "Train loss at 1083 iteration is 3.670276165008545 \n",
            "Train loss at 1084 iteration is 3.2774336338043213 \n",
            "Train loss at 1085 iteration is 3.4906258583068848 \n",
            "Train loss at 1086 iteration is 3.4018073081970215 \n",
            "Train loss at 1087 iteration is 3.4990973472595215 \n",
            "Train loss at 1088 iteration is 3.623384714126587 \n",
            "Train loss at 1089 iteration is 3.3875620365142822 \n",
            "Train loss at 1090 iteration is 3.279879570007324 \n",
            "Train loss at 1091 iteration is 3.383517026901245 \n",
            "Train loss at 1092 iteration is 3.5214686393737793 \n",
            "Train loss at 1093 iteration is 3.067725896835327 \n",
            "Train loss at 1094 iteration is 3.464373826980591 \n",
            "Train loss at 1095 iteration is 3.556145191192627 \n",
            "Train loss at 1096 iteration is 3.408661365509033 \n",
            "Train loss at 1097 iteration is 3.44663667678833 \n",
            "Train loss at 1098 iteration is 3.4305224418640137 \n",
            "Train loss at 1099 iteration is 3.483044385910034 \n",
            "Train loss at 1100 iteration is 3.251756191253662 \n",
            "Train loss at 1101 iteration is 3.4902048110961914 \n",
            "Train loss at 1102 iteration is 3.47664737701416 \n",
            "Train loss at 1103 iteration is 3.5794413089752197 \n",
            "Train loss at 1104 iteration is 3.482398748397827 \n",
            "Train loss at 1105 iteration is 3.3393115997314453 \n",
            "Train loss at 1106 iteration is 3.318842649459839 \n",
            "Train loss at 1107 iteration is 3.3102471828460693 \n",
            "Train loss at 1108 iteration is 3.7716073989868164 \n",
            "Train loss at 1109 iteration is 3.4390246868133545 \n",
            "Train loss at 1110 iteration is 3.4140465259552 \n",
            "Train loss at 1111 iteration is 3.5778937339782715 \n",
            "Train loss at 1112 iteration is 3.3855767250061035 \n",
            "Train loss at 1113 iteration is 3.391186237335205 \n",
            "Train loss at 1114 iteration is 3.497331380844116 \n",
            "Train loss at 1115 iteration is 3.5462441444396973 \n",
            "Train loss at 1116 iteration is 3.376678228378296 \n",
            "Train loss at 1117 iteration is 3.3313047885894775 \n",
            "Train loss at 1118 iteration is 3.3929851055145264 \n",
            "Train loss at 1119 iteration is 3.3256258964538574 \n",
            "Train loss at 1120 iteration is 3.6223361492156982 \n",
            "Train loss at 1121 iteration is 3.417344808578491 \n",
            "Train loss at 1122 iteration is 3.407222270965576 \n",
            "Train loss at 1123 iteration is 3.276130437850952 \n",
            "Train loss at 1124 iteration is 3.0818676948547363 \n",
            "Train loss at 1125 iteration is 3.3506033420562744 \n",
            "Train loss at 1126 iteration is 3.1110897064208984 \n",
            "Train loss at 1127 iteration is 3.3329944610595703 \n",
            "Train loss at 1128 iteration is 3.2078561782836914 \n",
            "Train loss at 1129 iteration is 3.34859561920166 \n",
            "Train loss at 1130 iteration is 3.266648530960083 \n",
            "Train loss at 1131 iteration is 3.5632050037384033 \n",
            "Train loss at 1132 iteration is 3.271728992462158 \n",
            "Train loss at 1133 iteration is 3.2770729064941406 \n",
            "Train loss at 1134 iteration is 3.4378366470336914 \n",
            "Train loss at 1135 iteration is 3.4285993576049805 \n",
            "Train loss at 1136 iteration is 3.387941360473633 \n",
            "Train loss at 1137 iteration is 3.3873372077941895 \n",
            "Train loss at 1138 iteration is 3.378164529800415 \n",
            "Train loss at 1139 iteration is 3.3479559421539307 \n",
            "Train loss at 1140 iteration is 3.3410563468933105 \n",
            "Train loss at 1141 iteration is 3.201406240463257 \n",
            "Train loss at 1142 iteration is 3.3155977725982666 \n",
            "Train loss at 1143 iteration is 3.370039939880371 \n",
            "Train loss at 1144 iteration is 3.2288320064544678 \n",
            "Train loss at 1145 iteration is 3.40857195854187 \n",
            "Train loss at 1146 iteration is 3.5975775718688965 \n",
            "Train loss at 1147 iteration is 3.477886199951172 \n",
            "Train loss at 1148 iteration is 3.308318614959717 \n",
            "Train loss at 1149 iteration is 3.30065655708313 \n",
            "Train loss at 1150 iteration is 3.3968987464904785 \n",
            "Train loss at 1151 iteration is 3.401869297027588 \n",
            "Train loss at 1152 iteration is 3.336472511291504 \n",
            "Train loss at 1153 iteration is 3.500631809234619 \n",
            "Train loss at 1154 iteration is 3.3794326782226562 \n",
            "Train loss at 1155 iteration is 3.3675971031188965 \n",
            "Train loss at 1156 iteration is 3.344407320022583 \n",
            "Train loss at 1157 iteration is 3.358549118041992 \n",
            "Train loss at 1158 iteration is 3.430755615234375 \n",
            "Train loss at 1159 iteration is 3.345600128173828 \n",
            "Train loss at 1160 iteration is 3.519313097000122 \n",
            "Train loss at 1161 iteration is 3.3447139263153076 \n",
            "Train loss at 1162 iteration is 3.477252721786499 \n",
            "Train loss at 1163 iteration is 3.316009283065796 \n",
            "Train loss at 1164 iteration is 3.2423255443573 \n",
            "Train loss at 1165 iteration is 3.5231800079345703 \n",
            "Train loss at 1166 iteration is 3.7464683055877686 \n",
            "Train loss at 1167 iteration is 3.413393259048462 \n",
            "Train loss at 1168 iteration is 3.258352518081665 \n",
            "Train loss at 1169 iteration is 3.144374132156372 \n",
            "Train loss at 1170 iteration is 3.3596880435943604 \n",
            "Train loss at 1171 iteration is 3.3535194396972656 \n",
            "Train loss at 1172 iteration is 3.450514316558838 \n",
            "Train loss at 1173 iteration is 3.3105545043945312 \n",
            "Train loss at 1174 iteration is 3.546699047088623 \n",
            "Train loss at 1175 iteration is 3.4628541469573975 \n",
            "Train loss at 1176 iteration is 3.2013373374938965 \n",
            "Train loss at 1177 iteration is 3.233910322189331 \n",
            "Train loss at 1178 iteration is 3.353466033935547 \n",
            "Train loss at 1179 iteration is 3.597693681716919 \n",
            "Train loss at 1180 iteration is 3.4156289100646973 \n",
            "Train loss at 1181 iteration is 3.0027730464935303 \n",
            "Train loss at 1182 iteration is 3.499807357788086 \n",
            "Train loss at 1183 iteration is 3.3307011127471924 \n",
            "Train loss at 1184 iteration is 3.6238303184509277 \n",
            "Train loss at 1185 iteration is 3.401512861251831 \n",
            "Train loss at 1186 iteration is 3.3231112957000732 \n",
            "Train loss at 1187 iteration is 3.1090972423553467 \n",
            "Train loss at 1188 iteration is 3.627403974533081 \n",
            "Train loss at 1189 iteration is 3.526670217514038 \n",
            "Train loss at 1190 iteration is 3.4353952407836914 \n",
            "Train loss at 1191 iteration is 3.3932087421417236 \n",
            "Train loss at 1192 iteration is 3.4937663078308105 \n",
            "Train loss at 1193 iteration is 3.5972790718078613 \n",
            "Train loss at 1194 iteration is 3.5186073780059814 \n",
            "Train loss at 1195 iteration is 3.435614585876465 \n",
            "Train loss at 1196 iteration is 3.4562900066375732 \n",
            "Train loss at 1197 iteration is 3.3343939781188965 \n",
            "Train loss at 1198 iteration is 3.3721885681152344 \n",
            "Train loss at 1199 iteration is 3.4493002891540527 \n",
            "Train loss at 1200 iteration is 3.381986141204834 \n",
            "Train loss at 1201 iteration is 3.214057207107544 \n",
            "Train loss at 1202 iteration is 3.3708794116973877 \n",
            "Train loss at 1203 iteration is 3.2767372131347656 \n",
            "Train loss at 1204 iteration is 3.4398610591888428 \n",
            "Train loss at 1205 iteration is 3.483013868331909 \n",
            "Train loss at 1206 iteration is 3.3972010612487793 \n",
            "Train loss at 1207 iteration is 3.4555070400238037 \n",
            "Train loss at 1208 iteration is 3.1708195209503174 \n",
            "Train loss at 1209 iteration is 3.462059497833252 \n",
            "Train loss at 1210 iteration is 3.4830102920532227 \n",
            "Train loss at 1211 iteration is 3.2237699031829834 \n",
            "Train loss at 1212 iteration is 3.304494857788086 \n",
            "Train loss at 1213 iteration is 3.3428006172180176 \n",
            "Train loss at 1214 iteration is 3.289451837539673 \n",
            "Train loss at 1215 iteration is 3.224620819091797 \n",
            "Train loss at 1216 iteration is 3.3782432079315186 \n",
            "Train loss at 1217 iteration is 3.365797758102417 \n",
            "Train loss at 1218 iteration is 3.4980382919311523 \n",
            "Train loss at 1219 iteration is 3.2948477268218994 \n",
            "Train loss at 1220 iteration is 3.3809802532196045 \n",
            "Train loss at 1221 iteration is 3.402291774749756 \n",
            "Train loss at 1222 iteration is 3.4208950996398926 \n",
            "Train loss at 1223 iteration is 3.313711643218994 \n",
            "Train loss at 1224 iteration is 3.31528902053833 \n",
            "Train loss at 1225 iteration is 3.4908902645111084 \n",
            "Train loss at 1226 iteration is 3.5098824501037598 \n",
            "Train loss at 1227 iteration is 3.319098711013794 \n",
            "Train loss at 1228 iteration is 3.4076457023620605 \n",
            "Train loss at 1229 iteration is 3.380533218383789 \n",
            "Train loss at 1230 iteration is 3.3713948726654053 \n",
            "Train loss at 1231 iteration is 3.3621981143951416 \n",
            "Train loss at 1232 iteration is 3.3517773151397705 \n",
            "Train loss at 1233 iteration is 3.3357436656951904 \n",
            "Train loss at 1234 iteration is 3.432605504989624 \n",
            "Train loss at 1235 iteration is 3.2835545539855957 \n",
            "Train loss at 1236 iteration is 3.37577486038208 \n",
            "Train loss at 1237 iteration is 3.3603241443634033 \n",
            "Train loss at 1238 iteration is 3.528798818588257 \n",
            "Train loss at 1239 iteration is 3.4578232765197754 \n",
            "Train loss at 1240 iteration is 3.180220127105713 \n",
            "Train loss at 1241 iteration is 3.5484423637390137 \n",
            "Train loss at 1242 iteration is 3.3827321529388428 \n",
            "Train loss at 1243 iteration is 3.32367205619812 \n",
            "Train loss at 1244 iteration is 3.3575682640075684 \n",
            "Train loss at 1245 iteration is 3.458070993423462 \n",
            "Train loss at 1246 iteration is 3.5695877075195312 \n",
            "Train loss at 1247 iteration is 3.391126871109009 \n",
            "Train loss at 1248 iteration is 3.2457642555236816 \n",
            "Train loss at 1249 iteration is 3.365528106689453 \n",
            "Train loss at 1250 iteration is 3.367499828338623 \n",
            "Train loss at 1251 iteration is 3.523261308670044 \n",
            "Train loss at 1252 iteration is 3.3394534587860107 \n",
            "Train loss at 1253 iteration is 3.4701132774353027 \n",
            "Train loss at 1254 iteration is 3.577908992767334 \n",
            "Train loss at 1255 iteration is 3.3879504203796387 \n",
            "Train loss at 1256 iteration is 3.483304977416992 \n",
            "Train loss at 1257 iteration is 3.218311071395874 \n",
            "Train loss at 1258 iteration is 3.658578872680664 \n",
            "Train loss at 1259 iteration is 3.535122871398926 \n",
            "Train loss at 1260 iteration is 3.4392266273498535 \n",
            "Train loss at 1261 iteration is 3.350432872772217 \n",
            "Train loss at 1262 iteration is 3.651754856109619 \n",
            "Train loss at 1263 iteration is 3.266584873199463 \n",
            "Train loss at 1264 iteration is 3.4030683040618896 \n",
            "Train loss at 1265 iteration is 3.4130046367645264 \n",
            "Train loss at 1266 iteration is 3.5141987800598145 \n",
            "Train loss at 1267 iteration is 3.3748583793640137 \n",
            "Train loss at 1268 iteration is 3.385418176651001 \n",
            "Train loss at 1269 iteration is 3.493842601776123 \n",
            "Train loss at 1270 iteration is 3.3307125568389893 \n",
            "Train loss at 1271 iteration is 3.4904403686523438 \n",
            "Train loss at 1272 iteration is 3.348639965057373 \n",
            "Train loss at 1273 iteration is 3.611278533935547 \n",
            "Train loss at 1274 iteration is 3.561129331588745 \n",
            "Train loss at 1275 iteration is 3.2116763591766357 \n",
            "Train loss at 1276 iteration is 3.3741888999938965 \n",
            "Train loss at 1277 iteration is 3.2510156631469727 \n",
            "Train loss at 1278 iteration is 3.3032028675079346 \n",
            "Train loss at 1279 iteration is 3.4620354175567627 \n",
            "Train loss at 1280 iteration is 3.480851650238037 \n",
            "Train loss at 1281 iteration is 3.426584005355835 \n",
            "Train loss at 1282 iteration is 3.693100690841675 \n",
            "Train loss at 1283 iteration is 3.2182881832122803 \n",
            "Train loss at 1284 iteration is 3.3435521125793457 \n",
            "Train loss at 1285 iteration is 3.6932692527770996 \n",
            "Train loss at 1286 iteration is 3.5025813579559326 \n",
            "Train loss at 1287 iteration is 3.487926959991455 \n",
            "Train loss at 1288 iteration is 3.477187156677246 \n",
            "Train loss at 1289 iteration is 3.369236469268799 \n",
            "Train loss at 1290 iteration is 3.5017917156219482 \n",
            "Train loss at 1291 iteration is 3.5322747230529785 \n",
            "Train loss at 1292 iteration is 3.460697889328003 \n",
            "Train loss at 1293 iteration is 3.3363633155822754 \n",
            "Train loss at 1294 iteration is 3.4437201023101807 \n",
            "Train loss at 1295 iteration is 3.3963356018066406 \n",
            "Train loss at 1296 iteration is 3.5030362606048584 \n",
            "Train loss at 1297 iteration is 3.285417079925537 \n",
            "Train loss at 1298 iteration is 3.4044365882873535 \n",
            "Train loss at 1299 iteration is 3.42801570892334 \n",
            "Train loss at 1300 iteration is 3.4762938022613525 \n",
            "Train loss at 1301 iteration is 3.426952600479126 \n",
            "Train loss at 1302 iteration is 3.4781012535095215 \n",
            "Train loss at 1303 iteration is 3.4978795051574707 \n",
            "Train loss at 1304 iteration is 3.3374931812286377 \n",
            "Train loss at 1305 iteration is 3.373678207397461 \n",
            "Train loss at 1306 iteration is 3.467364549636841 \n",
            "Train loss at 1307 iteration is 3.305696725845337 \n",
            "Train loss at 1308 iteration is 3.37015962600708 \n",
            "Train loss at 1309 iteration is 3.240816593170166 \n",
            "Train loss at 1310 iteration is 3.47420072555542 \n",
            "Train loss at 1311 iteration is 3.4002134799957275 \n",
            "Train loss at 1312 iteration is 3.2115914821624756 \n",
            "Train loss at 1313 iteration is 3.4294042587280273 \n",
            "Train loss at 1314 iteration is 3.382341146469116 \n",
            "Train loss at 1315 iteration is 3.4317822456359863 \n",
            "Train loss at 1316 iteration is 3.3433613777160645 \n",
            "Train loss at 1317 iteration is 3.3683407306671143 \n",
            "Train loss at 1318 iteration is 3.83240008354187 \n",
            "Train loss at 1319 iteration is 3.292508840560913 \n",
            "Train loss at 1320 iteration is 3.276467800140381 \n",
            "Train loss at 1321 iteration is 3.2307074069976807 \n",
            "Train loss at 1322 iteration is 3.3385303020477295 \n",
            "Train loss at 1323 iteration is 3.5104265213012695 \n",
            "Train loss at 1324 iteration is 3.365065574645996 \n",
            "Train loss at 1325 iteration is 3.3783416748046875 \n",
            "Train loss at 1326 iteration is 3.383209466934204 \n",
            "Train loss at 1327 iteration is 3.375211715698242 \n",
            "Train loss at 1328 iteration is 3.163740396499634 \n",
            "Train loss at 1329 iteration is 3.4676828384399414 \n",
            "Train loss at 1330 iteration is 3.256950616836548 \n",
            "Train loss at 1331 iteration is 3.147376537322998 \n",
            "Train loss at 1332 iteration is 3.125932216644287 \n",
            "Train loss at 1333 iteration is 3.4935450553894043 \n",
            "Train loss at 1334 iteration is 3.3249261379241943 \n",
            "Train loss at 1335 iteration is 3.429079532623291 \n",
            "Train loss at 1336 iteration is 3.451908588409424 \n",
            "Train loss at 1337 iteration is 3.3596370220184326 \n",
            "Train loss at 1338 iteration is 3.291490077972412 \n",
            "Train loss at 1339 iteration is 3.382164478302002 \n",
            "Train loss at 1340 iteration is 3.382448434829712 \n",
            "Train loss at 1341 iteration is 3.4479329586029053 \n",
            "Train loss at 1342 iteration is 3.400378942489624 \n",
            "Train loss at 1343 iteration is 3.431809902191162 \n",
            "Train loss at 1344 iteration is 3.25404953956604 \n",
            "Train loss at 1345 iteration is 3.5921192169189453 \n",
            "Train loss at 1346 iteration is 3.5291929244995117 \n",
            "Train loss at 1347 iteration is 3.396723508834839 \n",
            "Train loss at 1348 iteration is 3.2724785804748535 \n",
            "Train loss at 1349 iteration is 3.3329670429229736 \n",
            "Train loss at 1350 iteration is 3.2973031997680664 \n",
            "Train loss at 1351 iteration is 3.6567962169647217 \n",
            "Train loss at 1352 iteration is 3.5289876461029053 \n",
            "Train loss at 1353 iteration is 3.2540533542633057 \n",
            "Train loss at 1354 iteration is 3.414951801300049 \n",
            "Train loss at 1355 iteration is 3.3761537075042725 \n",
            "Train loss at 1356 iteration is 3.6692280769348145 \n",
            "Train loss at 1357 iteration is 3.5409483909606934 \n",
            "Train loss at 1358 iteration is 3.251643180847168 \n",
            "Train loss at 1359 iteration is 3.4401557445526123 \n",
            "Train loss at 1360 iteration is 3.476576328277588 \n",
            "Train loss at 1361 iteration is 3.3340539932250977 \n",
            "Train loss at 1362 iteration is 3.2503104209899902 \n",
            "Train loss at 1363 iteration is 3.303474187850952 \n",
            "Train loss at 1364 iteration is 3.183173894882202 \n",
            "Train loss at 1365 iteration is 3.432281494140625 \n",
            "Train loss at 1366 iteration is 3.553875684738159 \n",
            "Train loss at 1367 iteration is 3.4051218032836914 \n",
            "Train loss at 1368 iteration is 3.43753981590271 \n",
            "Train loss at 1369 iteration is 3.2230775356292725 \n",
            "Train loss at 1370 iteration is 3.387794256210327 \n",
            "Train loss at 1371 iteration is 3.7404839992523193 \n",
            "Train loss at 1372 iteration is 3.6450448036193848 \n",
            "Train loss at 1373 iteration is 3.3815953731536865 \n",
            "Train loss at 1374 iteration is 3.4633994102478027 \n",
            "Train loss at 1375 iteration is 3.66808819770813 \n",
            "Train loss at 1376 iteration is 3.5668063163757324 \n",
            "Train loss at 1377 iteration is 3.647394895553589 \n",
            "Train loss at 1378 iteration is 3.3089499473571777 \n",
            "Train loss at 1379 iteration is 3.1577823162078857 \n",
            "Train loss at 1380 iteration is 3.3614532947540283 \n",
            "Train loss at 1381 iteration is 3.32430100440979 \n",
            "Train loss at 1382 iteration is 3.3937060832977295 \n",
            "Train loss at 1383 iteration is 3.314006805419922 \n",
            "Train loss at 1384 iteration is 3.593895673751831 \n",
            "Train loss at 1385 iteration is 3.4132888317108154 \n",
            "Train loss at 1386 iteration is 3.2019240856170654 \n",
            "Train loss at 1387 iteration is 3.1889755725860596 \n",
            "Train loss at 1388 iteration is 3.451327085494995 \n",
            "Train loss at 1389 iteration is 3.2450857162475586 \n",
            "Train loss at 1390 iteration is 3.3813626766204834 \n",
            "Train loss at 1391 iteration is 3.3507239818573 \n",
            "Train loss at 1392 iteration is 3.512159585952759 \n",
            "Train loss at 1393 iteration is 3.4996283054351807 \n",
            "Train loss at 1394 iteration is 3.3727762699127197 \n",
            "Train loss at 1395 iteration is 3.3018012046813965 \n",
            "Train loss at 1396 iteration is 3.344829559326172 \n",
            "Train loss at 1397 iteration is 3.2720608711242676 \n",
            "Train loss at 1398 iteration is 3.432054281234741 \n",
            "Train loss at 1399 iteration is 3.283562421798706 \n",
            "Train loss at 1400 iteration is 3.485856056213379 \n",
            "Train loss at 1401 iteration is 3.5038886070251465 \n",
            "Train loss at 1402 iteration is 3.3823769092559814 \n",
            "Train loss at 1403 iteration is 3.519666910171509 \n",
            "Train loss at 1404 iteration is 3.541980743408203 \n",
            "Train loss at 1405 iteration is 3.56026554107666 \n",
            "Train loss at 1406 iteration is 3.3356051445007324 \n",
            "Train loss at 1407 iteration is 3.6193156242370605 \n",
            "Train loss at 1408 iteration is 3.5420849323272705 \n",
            "Train loss at 1409 iteration is 3.3020834922790527 \n",
            "Train loss at 1410 iteration is 3.358916997909546 \n",
            "Train loss at 1411 iteration is 3.247549533843994 \n",
            "Train loss at 1412 iteration is 3.5085980892181396 \n",
            "Train loss at 1413 iteration is 3.412539005279541 \n",
            "Train loss at 1414 iteration is 3.534269332885742 \n",
            "Train loss at 1415 iteration is 3.478982448577881 \n",
            "Train loss at 1416 iteration is 3.2139153480529785 \n",
            "Train loss at 1417 iteration is 3.2925517559051514 \n",
            "Train loss at 1418 iteration is 3.404500722885132 \n",
            "Train loss at 1419 iteration is 3.522092580795288 \n",
            "Train loss at 1420 iteration is 3.5993993282318115 \n",
            "Train loss at 1421 iteration is 3.228121280670166 \n",
            "Train loss at 1422 iteration is 3.0827860832214355 \n",
            "Train loss at 1423 iteration is 3.433344602584839 \n",
            "Train loss at 1424 iteration is 3.3959662914276123 \n",
            "Train loss at 1425 iteration is 3.501171350479126 \n",
            "Train loss at 1426 iteration is 3.329256057739258 \n",
            "Train loss at 1427 iteration is 3.4568419456481934 \n",
            "Train loss at 1428 iteration is 3.2075674533843994 \n",
            "Train loss at 1429 iteration is 3.3758621215820312 \n",
            "Train loss at 1430 iteration is 3.6187946796417236 \n",
            "Train loss at 1431 iteration is 3.5376222133636475 \n",
            "Train loss at 1432 iteration is 3.302536725997925 \n",
            "Train loss at 1433 iteration is 3.3416507244110107 \n",
            "Train loss at 1434 iteration is 3.273487091064453 \n",
            "Train loss at 1435 iteration is 3.4548144340515137 \n",
            "Train loss at 1436 iteration is 3.4252521991729736 \n",
            "Train loss at 1437 iteration is 3.512885332107544 \n",
            "Train loss at 1438 iteration is 3.4171342849731445 \n",
            "Train loss at 1439 iteration is 3.5416183471679688 \n",
            "Train loss at 1440 iteration is 3.3982338905334473 \n",
            "Train loss at 1441 iteration is 3.3693222999572754 \n",
            "Train loss at 1442 iteration is 3.5887808799743652 \n",
            "Train loss at 1443 iteration is 3.285665512084961 \n",
            "Train loss at 1444 iteration is 3.257974624633789 \n",
            "Train loss at 1445 iteration is 3.4473907947540283 \n",
            "Train loss at 1446 iteration is 3.202533006668091 \n",
            "Train loss at 1447 iteration is 3.462879180908203 \n",
            "Train loss at 1448 iteration is 3.6248364448547363 \n",
            "Train loss at 1449 iteration is 3.5052475929260254 \n",
            "Train loss at 1450 iteration is 3.492232322692871 \n",
            "Train loss at 1451 iteration is 3.3931448459625244 \n",
            "Train loss at 1452 iteration is 3.4703567028045654 \n",
            "Train loss at 1453 iteration is 3.2877657413482666 \n",
            "Train loss at 1454 iteration is 3.323559522628784 \n",
            "Train loss at 1455 iteration is 3.492736577987671 \n",
            "Train loss at 1456 iteration is 3.3419244289398193 \n",
            "Train loss at 1457 iteration is 3.627053737640381 \n",
            "Train loss at 1458 iteration is 3.2160441875457764 \n",
            "Train loss at 1459 iteration is 3.3723645210266113 \n",
            "Train loss at 1460 iteration is 3.242037773132324 \n",
            "Train loss at 1461 iteration is 3.4981689453125 \n",
            "Train loss at 1462 iteration is 3.4795901775360107 \n",
            "Train loss at 1463 iteration is 3.3630471229553223 \n",
            "Train loss at 1464 iteration is 3.2902843952178955 \n",
            "Train loss at 1465 iteration is 3.4658401012420654 \n",
            "Train loss at 1466 iteration is 3.320066213607788 \n",
            "Train loss at 1467 iteration is 3.1633262634277344 \n",
            "Train loss at 1468 iteration is 3.383655309677124 \n",
            "Train loss at 1469 iteration is 3.6331372261047363 \n",
            "Train loss at 1470 iteration is 3.1550893783569336 \n",
            "Train loss at 1471 iteration is 3.647028684616089 \n",
            "Train loss at 1472 iteration is 3.2657470703125 \n",
            "Train loss at 1473 iteration is 3.201425790786743 \n",
            "Train loss at 1474 iteration is 3.5871760845184326 \n",
            "Train loss at 1475 iteration is 3.4256680011749268 \n",
            "Train loss at 1476 iteration is 3.364055633544922 \n",
            "Train loss at 1477 iteration is 3.4895596504211426 \n",
            "Train loss at 1478 iteration is 3.4435887336730957 \n",
            "Train loss at 1479 iteration is 3.328773260116577 \n",
            "Train loss at 1480 iteration is 3.4006731510162354 \n",
            "Train loss at 1481 iteration is 3.3308959007263184 \n",
            "Train loss at 1482 iteration is 3.3279922008514404 \n",
            "Train loss at 1483 iteration is 3.4790384769439697 \n",
            "Train loss at 1484 iteration is 3.4128665924072266 \n",
            "Train loss at 1485 iteration is 3.5365846157073975 \n",
            "Train loss at 1486 iteration is 3.4302570819854736 \n",
            "Train loss at 1487 iteration is 3.2766001224517822 \n",
            "Train loss at 1488 iteration is 3.2958786487579346 \n",
            "Train loss at 1489 iteration is 3.4355757236480713 \n",
            "Train loss at 1490 iteration is 3.4387030601501465 \n",
            "Train loss at 1491 iteration is 3.5513381958007812 \n",
            "Train loss at 1492 iteration is 3.422788143157959 \n",
            "Train loss at 1493 iteration is 3.448134422302246 \n",
            "Train loss at 1494 iteration is 3.3309438228607178 \n",
            "Train loss at 1495 iteration is 3.3792808055877686 \n",
            "Train loss at 1496 iteration is 3.2500014305114746 \n",
            "Train loss at 1497 iteration is 3.514094114303589 \n",
            "Train loss at 1498 iteration is 3.496706485748291 \n",
            "Train loss at 1499 iteration is 3.399479627609253 \n",
            "Train loss at 1500 iteration is 3.4638171195983887 \n",
            "Train loss at 1501 iteration is 3.1883163452148438 \n",
            "Train loss at 1502 iteration is 3.484330654144287 \n",
            "Train loss at 1503 iteration is 3.461960554122925 \n",
            "Train loss at 1504 iteration is 3.360264539718628 \n",
            "Train loss at 1505 iteration is 3.2615058422088623 \n",
            "Train loss at 1506 iteration is 3.646578073501587 \n",
            "Train loss at 1507 iteration is 3.7411069869995117 \n",
            "Train loss at 1508 iteration is 3.4715726375579834 \n",
            "Train loss at 1509 iteration is 3.391024112701416 \n",
            "Train loss at 1510 iteration is 3.368623733520508 \n",
            "Train loss at 1511 iteration is 3.491283893585205 \n",
            "Train loss at 1512 iteration is 3.5207197666168213 \n",
            "Train loss at 1513 iteration is 3.4102189540863037 \n",
            "Train loss at 1514 iteration is 3.389400005340576 \n",
            "Train loss at 1515 iteration is 3.327626943588257 \n",
            "Train loss at 1516 iteration is 3.351623058319092 \n",
            "Train loss at 1517 iteration is 3.3941729068756104 \n",
            "Train loss at 1518 iteration is 3.5805060863494873 \n",
            "Train loss at 1519 iteration is 3.5303027629852295 \n",
            "Train loss at 1520 iteration is 3.326791524887085 \n",
            "Train loss at 1521 iteration is 3.359163522720337 \n",
            "Train loss at 1522 iteration is 3.5649547576904297 \n",
            "Train loss at 1523 iteration is 3.6699440479278564 \n",
            "Train loss at 1524 iteration is 3.320016860961914 \n",
            "Train loss at 1525 iteration is 3.543853998184204 \n",
            "Train loss at 1526 iteration is 3.283630847930908 \n",
            "Train loss at 1527 iteration is 3.639087438583374 \n",
            "Train loss at 1528 iteration is 3.576446771621704 \n",
            "Train loss at 1529 iteration is 3.503826856613159 \n",
            "Train loss at 1530 iteration is 3.266861915588379 \n",
            "Train loss at 1531 iteration is 3.3850936889648438 \n",
            "Train loss at 1532 iteration is 3.6434507369995117 \n",
            "Train loss at 1533 iteration is 3.4040656089782715 \n",
            "Train loss at 1534 iteration is 3.3779656887054443 \n",
            "Train loss at 1535 iteration is 3.4834420680999756 \n",
            "Train loss at 1536 iteration is 3.297999382019043 \n",
            "Train loss at 1537 iteration is 3.499483346939087 \n",
            "Train loss at 1538 iteration is 3.305743455886841 \n",
            "Train loss at 1539 iteration is 3.3173882961273193 \n",
            "Train loss at 1540 iteration is 3.5018184185028076 \n",
            "Train loss at 1541 iteration is 3.381720781326294 \n",
            "Train loss at 1542 iteration is 3.478149890899658 \n",
            "Train loss at 1543 iteration is 3.3929443359375 \n",
            "Train loss at 1544 iteration is 3.3396098613739014 \n",
            "Train loss at 1545 iteration is 3.5291452407836914 \n",
            "Train loss at 1546 iteration is 3.4219186305999756 \n",
            "Train loss at 1547 iteration is 3.436436176300049 \n",
            "Train loss at 1548 iteration is 3.362454891204834 \n",
            "Train loss at 1549 iteration is 3.5388996601104736 \n",
            "Train loss at 1550 iteration is 3.5408213138580322 \n",
            "Train loss at 1551 iteration is 3.335645914077759 \n",
            "Train loss at 1552 iteration is 3.2766382694244385 \n",
            "Train loss at 1553 iteration is 3.537336826324463 \n",
            "Train loss at 1554 iteration is 3.2409379482269287 \n",
            "Train loss at 1555 iteration is 3.4401586055755615 \n",
            "Train loss at 1556 iteration is 3.211979866027832 \n",
            "Train loss at 1557 iteration is 3.423279047012329 \n",
            "Train loss at 1558 iteration is 3.4488139152526855 \n",
            "Train loss at 1559 iteration is 3.555539131164551 \n",
            "Train loss at 1560 iteration is 3.6446125507354736 \n",
            "Train loss at 1561 iteration is 3.265134334564209 \n",
            "Train loss at 1562 iteration is 3.3189072608947754 \n",
            "Train loss at 1563 iteration is 3.4556374549865723 \n",
            "Train loss at 1564 iteration is 3.2819814682006836 \n",
            "Train loss at 1565 iteration is 3.286332845687866 \n",
            "Train loss at 1566 iteration is 3.6118578910827637 \n",
            "Train loss at 1567 iteration is 3.306473731994629 \n",
            "Train loss at 1568 iteration is 2.9297754764556885 \n",
            "Train loss at 1569 iteration is 3.5364787578582764 \n",
            "Train loss at 1570 iteration is 3.4252898693084717 \n",
            "Train loss at 1571 iteration is 3.305280923843384 \n",
            "Train loss at 1572 iteration is 3.1189510822296143 \n",
            "Train loss at 1573 iteration is 3.667663097381592 \n",
            "Train loss at 1574 iteration is 3.504910707473755 \n",
            "Train loss at 1575 iteration is 3.6990745067596436 \n",
            "Train loss at 1576 iteration is 3.2431044578552246 \n",
            "Train loss at 1577 iteration is 3.3987045288085938 \n",
            "Train loss at 1578 iteration is 3.486253499984741 \n",
            "Train loss at 1579 iteration is 3.4497532844543457 \n",
            "Train loss at 1580 iteration is 3.3397209644317627 \n",
            "Train loss at 1581 iteration is 3.3935863971710205 \n",
            "Train loss at 1582 iteration is 3.466512680053711 \n",
            "Train loss at 1583 iteration is 3.507620334625244 \n",
            "Train loss at 1584 iteration is 3.4255146980285645 \n",
            "Train loss at 1585 iteration is 3.4861488342285156 \n",
            "Train loss at 1586 iteration is 3.432313919067383 \n",
            "Train loss at 1587 iteration is 3.682081937789917 \n",
            "Train loss at 1588 iteration is 3.1613895893096924 \n",
            "Train loss at 1589 iteration is 3.3916780948638916 \n",
            "Train loss at 1590 iteration is 3.400298833847046 \n",
            "Train loss at 1591 iteration is 3.5238006114959717 \n",
            "Train loss at 1592 iteration is 3.6097593307495117 \n",
            "Train loss at 1593 iteration is 3.3699557781219482 \n",
            "Train loss at 1594 iteration is 3.301758050918579 \n",
            "Train loss at 1595 iteration is 3.3406553268432617 \n",
            "Train loss at 1596 iteration is 3.4119343757629395 \n",
            "Train loss at 1597 iteration is 3.462698459625244 \n",
            "Train loss at 1598 iteration is 3.115989923477173 \n",
            "Train loss at 1599 iteration is 3.2696533203125 \n",
            "Train loss at 1600 iteration is 3.28366756439209 \n",
            "Train loss at 1601 iteration is 3.392387866973877 \n",
            "Train loss at 1602 iteration is 3.5162360668182373 \n",
            "Train loss at 1603 iteration is 3.144651174545288 \n",
            "Train loss at 1604 iteration is 3.2988181114196777 \n",
            "Train loss at 1605 iteration is 3.152709722518921 \n",
            "Train loss at 1606 iteration is 3.5651450157165527 \n",
            "Train loss at 1607 iteration is 3.34108829498291 \n",
            "Train loss at 1608 iteration is 3.3979408740997314 \n",
            "Train loss at 1609 iteration is 3.1303200721740723 \n",
            "Train loss at 1610 iteration is 3.1386940479278564 \n",
            "Train loss at 1611 iteration is 3.5307986736297607 \n",
            "Train loss at 1612 iteration is 3.3621363639831543 \n",
            "Train loss at 1613 iteration is 3.5275778770446777 \n",
            "Train loss at 1614 iteration is 3.250502824783325 \n",
            "Train loss at 1615 iteration is 3.4143035411834717 \n",
            "Train loss at 1616 iteration is 3.2631001472473145 \n",
            "Train loss at 1617 iteration is 3.3479397296905518 \n",
            "Train loss at 1618 iteration is 3.5135884284973145 \n",
            "Train loss at 1619 iteration is 3.4902286529541016 \n",
            "Train loss at 1620 iteration is 3.3302135467529297 \n",
            "Train loss at 1621 iteration is 3.4912002086639404 \n",
            "Train loss at 1622 iteration is 3.2227866649627686 \n",
            "Train loss at 1623 iteration is 3.3446037769317627 \n",
            "Train loss at 1624 iteration is 3.4296281337738037 \n",
            "Train loss at 1625 iteration is 3.1644413471221924 \n",
            "Train loss at 1626 iteration is 3.5346548557281494 \n",
            "Train loss at 1627 iteration is 3.552455425262451 \n",
            "Train loss at 1628 iteration is 3.5606977939605713 \n",
            "Train loss at 1629 iteration is 3.3536834716796875 \n",
            "Train loss at 1630 iteration is 3.520190715789795 \n",
            "Train loss at 1631 iteration is 3.384303092956543 \n",
            "Train loss at 1632 iteration is 3.3495676517486572 \n",
            "Train loss at 1633 iteration is 3.315217971801758 \n",
            "Train loss at 1634 iteration is 3.319441318511963 \n",
            "Train loss at 1635 iteration is 3.605220079421997 \n",
            "Train loss at 1636 iteration is 3.378634214401245 \n",
            "Train loss at 1637 iteration is 3.4001996517181396 \n",
            "Train loss at 1638 iteration is 3.2642481327056885 \n",
            "Train loss at 1639 iteration is 3.344975471496582 \n",
            "Train loss at 1640 iteration is 3.440168619155884 \n",
            "Train loss at 1641 iteration is 3.514589786529541 \n",
            "Train loss at 1642 iteration is 3.344773054122925 \n",
            "Train loss at 1643 iteration is 3.142224073410034 \n",
            "Train loss at 1644 iteration is 3.154756784439087 \n",
            "Train loss at 1645 iteration is 3.478158473968506 \n",
            "Train loss at 1646 iteration is 3.7547495365142822 \n",
            "Train loss at 1647 iteration is 3.381213426589966 \n",
            "Train loss at 1648 iteration is 3.307614326477051 \n",
            "Train loss at 1649 iteration is 3.5539345741271973 \n",
            "Train loss at 1650 iteration is 3.388331174850464 \n",
            "Train loss at 1651 iteration is 3.256175994873047 \n",
            "Train loss at 1652 iteration is 3.4794135093688965 \n",
            "Train loss at 1653 iteration is 3.268507719039917 \n",
            "Train loss at 1654 iteration is 3.476574182510376 \n",
            "Train loss at 1655 iteration is 3.58162784576416 \n",
            "Train loss at 1656 iteration is 3.465472459793091 \n",
            "Train loss at 1657 iteration is 3.3805623054504395 \n",
            "Train loss at 1658 iteration is 3.2557966709136963 \n",
            "Train loss at 1659 iteration is 3.448989152908325 \n",
            "Train loss at 1660 iteration is 3.4379639625549316 \n",
            "Train loss at 1661 iteration is 3.6350412368774414 \n",
            "Train loss at 1662 iteration is 3.5474514961242676 \n",
            "Train loss at 1663 iteration is 3.354844093322754 \n",
            "Train loss at 1664 iteration is 3.186065912246704 \n",
            "Train loss at 1665 iteration is 3.433622121810913 \n",
            "Train loss at 1666 iteration is 3.39430832862854 \n",
            "Train loss at 1667 iteration is 3.424720525741577 \n",
            "Train loss at 1668 iteration is 3.4523885250091553 \n",
            "Train loss at 1669 iteration is 3.569269895553589 \n",
            "Train loss at 1670 iteration is 3.522449016571045 \n",
            "Train loss at 1671 iteration is 3.2294557094573975 \n",
            "Train loss at 1672 iteration is 3.4104018211364746 \n",
            "Train loss at 1673 iteration is 3.3040854930877686 \n",
            "Train loss at 1674 iteration is 3.3938372135162354 \n",
            "Train loss at 1675 iteration is 3.3506274223327637 \n",
            "Train loss at 1676 iteration is 3.4348392486572266 \n",
            "Train loss at 1677 iteration is 3.5335426330566406 \n",
            "Train loss at 1678 iteration is 3.440011501312256 \n",
            "Train loss at 1679 iteration is 3.1236538887023926 \n",
            "Train loss at 1680 iteration is 3.555441379547119 \n",
            "Train loss at 1681 iteration is 3.468376398086548 \n",
            "Train loss at 1682 iteration is 3.4395673274993896 \n",
            "Train loss at 1683 iteration is 3.235701560974121 \n",
            "Train loss at 1684 iteration is 3.4252092838287354 \n",
            "Train loss at 1685 iteration is 3.338304281234741 \n",
            "Train loss at 1686 iteration is 3.5120222568511963 \n",
            "Train loss at 1687 iteration is 3.296924591064453 \n",
            "Train loss at 1688 iteration is 3.241541862487793 \n",
            "Train loss at 1689 iteration is 3.49226713180542 \n",
            "Train loss at 1690 iteration is 3.155808925628662 \n",
            "Train loss at 1691 iteration is 3.2241673469543457 \n",
            "Train loss at 1692 iteration is 3.7407476902008057 \n",
            "Train loss at 1693 iteration is 3.3694896697998047 \n",
            "Train loss at 1694 iteration is 3.449934720993042 \n",
            "Train loss at 1695 iteration is 3.41056227684021 \n",
            "Train loss at 1696 iteration is 3.46347975730896 \n",
            "Train loss at 1697 iteration is 3.361973524093628 \n",
            "Train loss at 1698 iteration is 3.466437339782715 \n",
            "Train loss at 1699 iteration is 3.2815968990325928 \n",
            "Train loss at 1700 iteration is 3.418797731399536 \n",
            "Train loss at 1701 iteration is 3.416369915008545 \n",
            "Train loss at 1702 iteration is 3.4103143215179443 \n",
            "Train loss at 1703 iteration is 3.5889053344726562 \n",
            "Train loss at 1704 iteration is 3.4378280639648438 \n",
            "Train loss at 1705 iteration is 3.436579465866089 \n",
            "Train loss at 1706 iteration is 3.2255704402923584 \n",
            "Train loss at 1707 iteration is 3.335775375366211 \n",
            "Train loss at 1708 iteration is 3.466219663619995 \n",
            "Train loss at 1709 iteration is 3.444965124130249 \n",
            "Train loss at 1710 iteration is 3.4462358951568604 \n",
            "Train loss at 1711 iteration is 3.561347007751465 \n",
            "Train loss at 1712 iteration is 3.3204314708709717 \n",
            "Train loss at 1713 iteration is 3.2059743404388428 \n",
            "Train loss at 1714 iteration is 3.2661900520324707 \n",
            "Train loss at 1715 iteration is 3.4771952629089355 \n",
            "Train loss at 1716 iteration is 3.314894676208496 \n",
            "Train loss at 1717 iteration is 3.567145824432373 \n",
            "Train loss at 1718 iteration is 3.3854622840881348 \n",
            "Train loss at 1719 iteration is 3.2402658462524414 \n",
            "Train loss at 1720 iteration is 3.3605105876922607 \n",
            "Train loss at 1721 iteration is 3.4850354194641113 \n",
            "Train loss at 1722 iteration is 3.2025578022003174 \n",
            "Train loss at 1723 iteration is 3.529883623123169 \n",
            "Train loss at 1724 iteration is 3.147216558456421 \n",
            "Train loss at 1725 iteration is 3.229806661605835 \n",
            "Train loss at 1726 iteration is 3.3387222290039062 \n",
            "Train loss at 1727 iteration is 3.404472589492798 \n",
            "Train loss at 1728 iteration is 3.140716791152954 \n",
            "Train loss at 1729 iteration is 3.5422329902648926 \n",
            "Train loss at 1730 iteration is 3.569807767868042 \n",
            "Train loss at 1731 iteration is 3.4292991161346436 \n",
            "Train loss at 1732 iteration is 3.4231557846069336 \n",
            "Train loss at 1733 iteration is 3.346017837524414 \n",
            "Train loss at 1734 iteration is 3.3392179012298584 \n",
            "Train loss at 1735 iteration is 3.3221898078918457 \n",
            "Train loss at 1736 iteration is 3.444369316101074 \n",
            "Train loss at 1737 iteration is 3.6256508827209473 \n",
            "Train loss at 1738 iteration is 3.5370075702667236 \n",
            "Train loss at 1739 iteration is 3.623602867126465 \n",
            "Train loss at 1740 iteration is 3.3727447986602783 \n",
            "Train loss at 1741 iteration is 3.5501980781555176 \n",
            "Train loss at 1742 iteration is 3.6529362201690674 \n",
            "Train loss at 1743 iteration is 3.406067371368408 \n",
            "Train loss at 1744 iteration is 3.185201406478882 \n",
            "Train loss at 1745 iteration is 3.3848650455474854 \n",
            "Train loss at 1746 iteration is 3.1864442825317383 \n",
            "Train loss at 1747 iteration is 3.2889177799224854 \n",
            "Train loss at 1748 iteration is 3.3978142738342285 \n",
            "Train loss at 1749 iteration is 3.3242552280426025 \n",
            "Train loss at 1750 iteration is 3.3065454959869385 \n",
            "Train loss at 1751 iteration is 3.0667662620544434 \n",
            "Train loss at 1752 iteration is 3.211575984954834 \n",
            "Train loss at 1753 iteration is 3.4708497524261475 \n",
            "Train loss at 1754 iteration is 3.337491750717163 \n",
            "Train loss at 1755 iteration is 3.2298386096954346 \n",
            "Train loss at 1756 iteration is 3.4877536296844482 \n",
            "Train loss at 1757 iteration is 3.3951005935668945 \n",
            "Train loss at 1758 iteration is 3.294077157974243 \n",
            "Train loss at 1759 iteration is 3.299698829650879 \n",
            "Train loss at 1760 iteration is 3.4053192138671875 \n",
            "Train loss at 1761 iteration is 3.3550360202789307 \n",
            "Train loss at 1762 iteration is 3.5756261348724365 \n",
            "Train loss at 1763 iteration is 3.427229404449463 \n",
            "Train loss at 1764 iteration is 3.3462119102478027 \n",
            "Train loss at 1765 iteration is 3.31907320022583 \n",
            "Train loss at 1766 iteration is 3.2827208042144775 \n",
            "Train loss at 1767 iteration is 3.436286211013794 \n",
            "Train loss at 1768 iteration is 3.5063257217407227 \n",
            "Train loss at 1769 iteration is 3.46508526802063 \n",
            "Train loss at 1770 iteration is 3.3052978515625 \n",
            "Train loss at 1771 iteration is 3.464038133621216 \n",
            "Train loss at 1772 iteration is 3.4446020126342773 \n",
            "Train loss at 1773 iteration is 3.4332799911499023 \n",
            "Train loss at 1774 iteration is 3.388160228729248 \n",
            "Train loss at 1775 iteration is 3.306997537612915 \n",
            "Train loss at 1776 iteration is 3.282747268676758 \n",
            "Train loss at 1777 iteration is 3.492237091064453 \n",
            "Train loss at 1778 iteration is 3.2947874069213867 \n",
            "Train loss at 1779 iteration is 3.5699915885925293 \n",
            "Train loss at 1780 iteration is 3.326214551925659 \n",
            "Train loss at 1781 iteration is 3.371882915496826 \n",
            "Train loss at 1782 iteration is 3.48773455619812 \n",
            "Train loss at 1783 iteration is 3.3330607414245605 \n",
            "Train loss at 1784 iteration is 3.3259756565093994 \n",
            "Train loss at 1785 iteration is 3.4531090259552 \n",
            "Train loss at 1786 iteration is 3.506345748901367 \n",
            "Train loss at 1787 iteration is 3.2525110244750977 \n",
            "Train loss at 1788 iteration is 3.484492063522339 \n",
            "Train loss at 1789 iteration is 3.410550117492676 \n",
            "Train loss at 1790 iteration is 3.405106782913208 \n",
            "Train loss at 1791 iteration is 3.3897104263305664 \n",
            "Train loss at 1792 iteration is 3.0520923137664795 \n",
            "Train loss at 1793 iteration is 3.1169023513793945 \n",
            "Train loss at 1794 iteration is 3.174159288406372 \n",
            "Train loss at 1795 iteration is 3.2288053035736084 \n",
            "Train loss at 1796 iteration is 3.1589038372039795 \n",
            "Train loss at 1797 iteration is 3.2098374366760254 \n",
            "Train loss at 1798 iteration is 3.266057252883911 \n",
            "Train loss at 1799 iteration is 2.9894347190856934 \n",
            "Train loss at 1800 iteration is 3.0438694953918457 \n",
            "Train loss at 1801 iteration is 3.1791844367980957 \n",
            "Train loss at 1802 iteration is 3.0705199241638184 \n",
            "Train loss at 1803 iteration is 3.1078264713287354 \n",
            "Train loss at 1804 iteration is 3.279383420944214 \n",
            "Train loss at 1805 iteration is 3.2936718463897705 \n",
            "Train loss at 1806 iteration is 3.1396567821502686 \n",
            "Train loss at 1807 iteration is 3.2213220596313477 \n",
            "Train loss at 1808 iteration is 3.14882755279541 \n",
            "Train loss at 1809 iteration is 3.340129852294922 \n",
            "Train loss at 1810 iteration is 3.364825963973999 \n",
            "Train loss at 1811 iteration is 3.086700916290283 \n",
            "Train loss at 1812 iteration is 3.2450783252716064 \n",
            "Train loss at 1813 iteration is 3.2482941150665283 \n",
            "Train loss at 1814 iteration is 3.034886360168457 \n",
            "Train loss at 1815 iteration is 3.136106014251709 \n",
            "Train loss at 1816 iteration is 3.0758204460144043 \n",
            "Train loss at 1817 iteration is 3.147484540939331 \n",
            "Train loss at 1818 iteration is 3.2710931301116943 \n",
            "Train loss at 1819 iteration is 3.119758367538452 \n",
            "Train loss at 1820 iteration is 3.1467015743255615 \n",
            "Train loss at 1821 iteration is 3.4990971088409424 \n",
            "Train loss at 1822 iteration is 3.0246541500091553 \n",
            "Train loss at 1823 iteration is 3.21573805809021 \n",
            "Train loss at 1824 iteration is 3.4171197414398193 \n",
            "Train loss at 1825 iteration is 3.2120723724365234 \n",
            "Train loss at 1826 iteration is 3.0342600345611572 \n",
            "Train loss at 1827 iteration is 3.204672336578369 \n",
            "Train loss at 1828 iteration is 3.2330853939056396 \n",
            "Train loss at 1829 iteration is 3.277362585067749 \n",
            "Train loss at 1830 iteration is 3.137140989303589 \n",
            "Train loss at 1831 iteration is 3.215348958969116 \n",
            "Train loss at 1832 iteration is 3.4113848209381104 \n",
            "Train loss at 1833 iteration is 3.173529863357544 \n",
            "Train loss at 1834 iteration is 3.047689914703369 \n",
            "Train loss at 1835 iteration is 3.3287999629974365 \n",
            "Train loss at 1836 iteration is 3.1538164615631104 \n",
            "Train loss at 1837 iteration is 3.098923921585083 \n",
            "Train loss at 1838 iteration is 3.379821538925171 \n",
            "Train loss at 1839 iteration is 3.236560821533203 \n",
            "Train loss at 1840 iteration is 3.0901718139648438 \n",
            "Train loss at 1841 iteration is 3.058417320251465 \n",
            "Train loss at 1842 iteration is 3.05922794342041 \n",
            "Train loss at 1843 iteration is 3.174630641937256 \n",
            "Train loss at 1844 iteration is 3.138622283935547 \n",
            "Train loss at 1845 iteration is 2.989534854888916 \n",
            "Train loss at 1846 iteration is 3.0459752082824707 \n",
            "Train loss at 1847 iteration is 3.2570462226867676 \n",
            "Train loss at 1848 iteration is 3.0848278999328613 \n",
            "Train loss at 1849 iteration is 3.104203939437866 \n",
            "Train loss at 1850 iteration is 3.162794828414917 \n",
            "Train loss at 1851 iteration is 3.139030933380127 \n",
            "Train loss at 1852 iteration is 3.1434624195098877 \n",
            "Train loss at 1853 iteration is 3.1224000453948975 \n",
            "Train loss at 1854 iteration is 3.1685609817504883 \n",
            "Train loss at 1855 iteration is 3.319406747817993 \n",
            "Train loss at 1856 iteration is 3.02425217628479 \n",
            "Train loss at 1857 iteration is 2.9474895000457764 \n",
            "Train loss at 1858 iteration is 3.2481954097747803 \n",
            "Train loss at 1859 iteration is 3.12514591217041 \n",
            "Train loss at 1860 iteration is 3.382270574569702 \n",
            "Train loss at 1861 iteration is 3.2396836280822754 \n",
            "Train loss at 1862 iteration is 3.0221457481384277 \n",
            "Train loss at 1863 iteration is 3.2914035320281982 \n",
            "Train loss at 1864 iteration is 3.3152668476104736 \n",
            "Train loss at 1865 iteration is 3.2223939895629883 \n",
            "Train loss at 1866 iteration is 3.0991663932800293 \n",
            "Train loss at 1867 iteration is 3.108398914337158 \n",
            "Train loss at 1868 iteration is 3.114769220352173 \n",
            "Train loss at 1869 iteration is 3.1446969509124756 \n",
            "Train loss at 1870 iteration is 3.104557514190674 \n",
            "Train loss at 1871 iteration is 3.1166913509368896 \n",
            "Train loss at 1872 iteration is 3.057366371154785 \n",
            "Train loss at 1873 iteration is 3.102609395980835 \n",
            "Train loss at 1874 iteration is 3.312861919403076 \n",
            "Train loss at 1875 iteration is 3.180948495864868 \n",
            "Train loss at 1876 iteration is 3.1046812534332275 \n",
            "Train loss at 1877 iteration is 3.1515443325042725 \n",
            "Train loss at 1878 iteration is 3.03708815574646 \n",
            "Train loss at 1879 iteration is 2.9528181552886963 \n",
            "Train loss at 1880 iteration is 3.120814561843872 \n",
            "Train loss at 1881 iteration is 3.156728982925415 \n",
            "Train loss at 1882 iteration is 3.2066190242767334 \n",
            "Train loss at 1883 iteration is 3.0158581733703613 \n",
            "Train loss at 1884 iteration is 3.2978382110595703 \n",
            "Train loss at 1885 iteration is 3.1053802967071533 \n",
            "Train loss at 1886 iteration is 3.3228209018707275 \n",
            "Train loss at 1887 iteration is 2.994145393371582 \n",
            "Train loss at 1888 iteration is 3.198760747909546 \n",
            "Train loss at 1889 iteration is 2.7598683834075928 \n",
            "Train loss at 1890 iteration is 3.3256959915161133 \n",
            "Train loss at 1891 iteration is 3.3038885593414307 \n",
            "Train loss at 1892 iteration is 3.1493563652038574 \n",
            "Train loss at 1893 iteration is 3.068183183670044 \n",
            "Train loss at 1894 iteration is 3.324441909790039 \n",
            "Train loss at 1895 iteration is 3.090087413787842 \n",
            "Train loss at 1896 iteration is 2.891908645629883 \n",
            "Train loss at 1897 iteration is 3.287905216217041 \n",
            "Train loss at 1898 iteration is 3.047053575515747 \n",
            "Train loss at 1899 iteration is 2.9042317867279053 \n",
            "Train loss at 1900 iteration is 3.170670509338379 \n",
            "Train loss at 1901 iteration is 2.912306308746338 \n",
            "Train loss at 1902 iteration is 3.2464566230773926 \n",
            "Train loss at 1903 iteration is 3.052720069885254 \n",
            "Train loss at 1904 iteration is 3.2150957584381104 \n",
            "Train loss at 1905 iteration is 3.257617473602295 \n",
            "Train loss at 1906 iteration is 3.215881109237671 \n",
            "Train loss at 1907 iteration is 3.1735432147979736 \n",
            "Train loss at 1908 iteration is 3.0054354667663574 \n",
            "Train loss at 1909 iteration is 2.9879634380340576 \n",
            "Train loss at 1910 iteration is 3.1886327266693115 \n",
            "Train loss at 1911 iteration is 3.1808903217315674 \n",
            "Train loss at 1912 iteration is 3.306849956512451 \n",
            "Train loss at 1913 iteration is 3.0260047912597656 \n",
            "Train loss at 1914 iteration is 3.31414794921875 \n",
            "Train loss at 1915 iteration is 3.2320749759674072 \n",
            "Train loss at 1916 iteration is 3.1662437915802 \n",
            "Train loss at 1917 iteration is 3.10532808303833 \n",
            "Train loss at 1918 iteration is 2.988502264022827 \n",
            "Train loss at 1919 iteration is 3.333656072616577 \n",
            "Train loss at 1920 iteration is 3.1620583534240723 \n",
            "Train loss at 1921 iteration is 2.888580799102783 \n",
            "Train loss at 1922 iteration is 3.068420171737671 \n",
            "Train loss at 1923 iteration is 3.106431007385254 \n",
            "Train loss at 1924 iteration is 3.3022098541259766 \n",
            "Train loss at 1925 iteration is 3.124884843826294 \n",
            "Train loss at 1926 iteration is 3.313577890396118 \n",
            "Train loss at 1927 iteration is 2.945178270339966 \n",
            "Train loss at 1928 iteration is 3.0815296173095703 \n",
            "Train loss at 1929 iteration is 3.304873466491699 \n",
            "Train loss at 1930 iteration is 2.9787709712982178 \n",
            "Train loss at 1931 iteration is 3.369502305984497 \n",
            "Train loss at 1932 iteration is 3.1846323013305664 \n",
            "Train loss at 1933 iteration is 3.161142349243164 \n",
            "Train loss at 1934 iteration is 3.2250280380249023 \n",
            "Train loss at 1935 iteration is 3.238765001296997 \n",
            "Train loss at 1936 iteration is 3.2334060668945312 \n",
            "Train loss at 1937 iteration is 3.1765401363372803 \n",
            "Train loss at 1938 iteration is 3.051304817199707 \n",
            "Train loss at 1939 iteration is 3.218463897705078 \n",
            "Train loss at 1940 iteration is 3.2022862434387207 \n",
            "Train loss at 1941 iteration is 3.2008419036865234 \n",
            "Train loss at 1942 iteration is 3.232961893081665 \n",
            "Train loss at 1943 iteration is 3.3463828563690186 \n",
            "Train loss at 1944 iteration is 3.3295390605926514 \n",
            "Train loss at 1945 iteration is 3.3740234375 \n",
            "Train loss at 1946 iteration is 3.173072576522827 \n",
            "Train loss at 1947 iteration is 3.095402956008911 \n",
            "Train loss at 1948 iteration is 3.2449376583099365 \n",
            "Train loss at 1949 iteration is 3.414957046508789 \n",
            "Train loss at 1950 iteration is 3.2093160152435303 \n",
            "Train loss at 1951 iteration is 3.2282392978668213 \n",
            "Train loss at 1952 iteration is 3.0803451538085938 \n",
            "Train loss at 1953 iteration is 3.0593502521514893 \n",
            "Train loss at 1954 iteration is 3.1528806686401367 \n",
            "Train loss at 1955 iteration is 3.2563533782958984 \n",
            "Train loss at 1956 iteration is 3.0919573307037354 \n",
            "Train loss at 1957 iteration is 3.1240603923797607 \n",
            "Train loss at 1958 iteration is 3.111241340637207 \n",
            "Train loss at 1959 iteration is 3.2360265254974365 \n",
            "Train loss at 1960 iteration is 2.9558024406433105 \n",
            "Train loss at 1961 iteration is 3.1931047439575195 \n",
            "Train loss at 1962 iteration is 3.2862966060638428 \n",
            "Train loss at 1963 iteration is 3.2637224197387695 \n",
            "Train loss at 1964 iteration is 3.162381410598755 \n",
            "Train loss at 1965 iteration is 3.097808599472046 \n",
            "Train loss at 1966 iteration is 3.2708067893981934 \n",
            "Train loss at 1967 iteration is 3.2725746631622314 \n",
            "Train loss at 1968 iteration is 3.1990561485290527 \n",
            "Train loss at 1969 iteration is 3.251183032989502 \n",
            "Train loss at 1970 iteration is 3.106424331665039 \n",
            "Train loss at 1971 iteration is 3.237637758255005 \n",
            "Train loss at 1972 iteration is 3.3361101150512695 \n",
            "Train loss at 1973 iteration is 2.959138870239258 \n",
            "Train loss at 1974 iteration is 3.3290200233459473 \n",
            "Train loss at 1975 iteration is 3.315943956375122 \n",
            "Train loss at 1976 iteration is 3.1990931034088135 \n",
            "Train loss at 1977 iteration is 3.2083122730255127 \n",
            "Train loss at 1978 iteration is 3.2339632511138916 \n",
            "Train loss at 1979 iteration is 3.1501104831695557 \n",
            "Train loss at 1980 iteration is 3.1067793369293213 \n",
            "Train loss at 1981 iteration is 3.1900556087493896 \n",
            "Train loss at 1982 iteration is 3.280003070831299 \n",
            "Train loss at 1983 iteration is 3.368263006210327 \n",
            "Train loss at 1984 iteration is 3.0833730697631836 \n",
            "Train loss at 1985 iteration is 3.063163995742798 \n",
            "Train loss at 1986 iteration is 3.0870089530944824 \n",
            "Train loss at 1987 iteration is 3.3146140575408936 \n",
            "Train loss at 1988 iteration is 3.149315595626831 \n",
            "Train loss at 1989 iteration is 3.0821948051452637 \n",
            "Train loss at 1990 iteration is 3.5339760780334473 \n",
            "Train loss at 1991 iteration is 3.1881885528564453 \n",
            "Train loss at 1992 iteration is 3.163792371749878 \n",
            "Train loss at 1993 iteration is 3.212700843811035 \n",
            "Train loss at 1994 iteration is 3.242170572280884 \n",
            "Train loss at 1995 iteration is 3.103032112121582 \n",
            "Train loss at 1996 iteration is 3.171504497528076 \n",
            "Train loss at 1997 iteration is 3.217641830444336 \n",
            "Train loss at 1998 iteration is 3.3413279056549072 \n",
            "Train loss at 1999 iteration is 3.169538974761963 \n",
            "Train loss at 2000 iteration is 3.0994112491607666 \n",
            "Train loss at 2001 iteration is 3.3130719661712646 \n",
            "Train loss at 2002 iteration is 2.967522382736206 \n",
            "Train loss at 2003 iteration is 3.1382923126220703 \n",
            "Train loss at 2004 iteration is 3.275951862335205 \n",
            "Train loss at 2005 iteration is 3.2996649742126465 \n",
            "Train loss at 2006 iteration is 3.165851593017578 \n",
            "Train loss at 2007 iteration is 3.1626710891723633 \n",
            "Train loss at 2008 iteration is 3.231060028076172 \n",
            "Train loss at 2009 iteration is 3.252119541168213 \n",
            "Train loss at 2010 iteration is 3.1346983909606934 \n",
            "Train loss at 2011 iteration is 3.0025794506073 \n",
            "Train loss at 2012 iteration is 3.0084023475646973 \n",
            "Train loss at 2013 iteration is 3.2410295009613037 \n",
            "Train loss at 2014 iteration is 3.178374767303467 \n",
            "Train loss at 2015 iteration is 3.047248363494873 \n",
            "Train loss at 2016 iteration is 3.2664036750793457 \n",
            "Train loss at 2017 iteration is 3.1228156089782715 \n",
            "Train loss at 2018 iteration is 3.2212109565734863 \n",
            "Train loss at 2019 iteration is 3.1235713958740234 \n",
            "Train loss at 2020 iteration is 3.2286365032196045 \n",
            "Train loss at 2021 iteration is 3.0708296298980713 \n",
            "Train loss at 2022 iteration is 3.1967086791992188 \n",
            "Train loss at 2023 iteration is 3.160245418548584 \n",
            "Train loss at 2024 iteration is 3.130737781524658 \n",
            "Train loss at 2025 iteration is 3.310206890106201 \n",
            "Train loss at 2026 iteration is 3.2739245891571045 \n",
            "Train loss at 2027 iteration is 3.173513650894165 \n",
            "Train loss at 2028 iteration is 2.9394290447235107 \n",
            "Train loss at 2029 iteration is 3.07979679107666 \n",
            "Train loss at 2030 iteration is 3.37406063079834 \n",
            "Train loss at 2031 iteration is 3.229367733001709 \n",
            "Train loss at 2032 iteration is 2.903275966644287 \n",
            "Train loss at 2033 iteration is 3.108781576156616 \n",
            "Train loss at 2034 iteration is 3.313356637954712 \n",
            "Train loss at 2035 iteration is 3.2335643768310547 \n",
            "Train loss at 2036 iteration is 3.35616397857666 \n",
            "Train loss at 2037 iteration is 3.2428321838378906 \n",
            "Train loss at 2038 iteration is 3.172410011291504 \n",
            "Train loss at 2039 iteration is 2.9986982345581055 \n",
            "Train loss at 2040 iteration is 3.356445550918579 \n",
            "Train loss at 2041 iteration is 3.180605888366699 \n",
            "Train loss at 2042 iteration is 3.0638678073883057 \n",
            "Train loss at 2043 iteration is 3.169696807861328 \n",
            "Train loss at 2044 iteration is 3.1354622840881348 \n",
            "Train loss at 2045 iteration is 3.196373224258423 \n",
            "Train loss at 2046 iteration is 3.1097605228424072 \n",
            "Train loss at 2047 iteration is 3.1797704696655273 \n",
            "Train loss at 2048 iteration is 3.092803955078125 \n",
            "Train loss at 2049 iteration is 2.9962379932403564 \n",
            "Train loss at 2050 iteration is 3.114121198654175 \n",
            "Train loss at 2051 iteration is 3.0896708965301514 \n",
            "Train loss at 2052 iteration is 3.2275912761688232 \n",
            "Train loss at 2053 iteration is 3.076035261154175 \n",
            "Train loss at 2054 iteration is 3.1110174655914307 \n",
            "Train loss at 2055 iteration is 3.2137084007263184 \n",
            "Train loss at 2056 iteration is 3.2875826358795166 \n",
            "Train loss at 2057 iteration is 3.1311185359954834 \n",
            "Train loss at 2058 iteration is 3.14442777633667 \n",
            "Train loss at 2059 iteration is 3.121342658996582 \n",
            "Train loss at 2060 iteration is 3.2487876415252686 \n",
            "Train loss at 2061 iteration is 3.1869304180145264 \n",
            "Train loss at 2062 iteration is 2.9865951538085938 \n",
            "Train loss at 2063 iteration is 3.2796833515167236 \n",
            "Train loss at 2064 iteration is 2.9466171264648438 \n",
            "Train loss at 2065 iteration is 3.1597089767456055 \n",
            "Train loss at 2066 iteration is 3.148444175720215 \n",
            "Train loss at 2067 iteration is 3.0227346420288086 \n",
            "Train loss at 2068 iteration is 3.148998737335205 \n",
            "Train loss at 2069 iteration is 3.1704750061035156 \n",
            "Train loss at 2070 iteration is 3.3055880069732666 \n",
            "Train loss at 2071 iteration is 3.1701977252960205 \n",
            "Train loss at 2072 iteration is 3.2066564559936523 \n",
            "Train loss at 2073 iteration is 3.1952593326568604 \n",
            "Train loss at 2074 iteration is 3.0528063774108887 \n",
            "Train loss at 2075 iteration is 3.242981195449829 \n",
            "Train loss at 2076 iteration is 3.0678892135620117 \n",
            "Train loss at 2077 iteration is 3.2589194774627686 \n",
            "Train loss at 2078 iteration is 3.2895901203155518 \n",
            "Train loss at 2079 iteration is 3.0714972019195557 \n",
            "Train loss at 2080 iteration is 3.3702316284179688 \n",
            "Train loss at 2081 iteration is 3.161062240600586 \n",
            "Train loss at 2082 iteration is 3.3231210708618164 \n",
            "Train loss at 2083 iteration is 3.1070523262023926 \n",
            "Train loss at 2084 iteration is 3.2327117919921875 \n",
            "Train loss at 2085 iteration is 3.302363872528076 \n",
            "Train loss at 2086 iteration is 3.0855231285095215 \n",
            "Train loss at 2087 iteration is 2.958930492401123 \n",
            "Train loss at 2088 iteration is 3.2218189239501953 \n",
            "Train loss at 2089 iteration is 3.3440468311309814 \n",
            "Train loss at 2090 iteration is 3.3747830390930176 \n",
            "Train loss at 2091 iteration is 3.186561346054077 \n",
            "Train loss at 2092 iteration is 3.088716983795166 \n",
            "Train loss at 2093 iteration is 3.1077992916107178 \n",
            "Train loss at 2094 iteration is 3.1184301376342773 \n",
            "Train loss at 2095 iteration is 3.2859792709350586 \n",
            "Train loss at 2096 iteration is 3.1722559928894043 \n",
            "Train loss at 2097 iteration is 3.182420492172241 \n",
            "Train loss at 2098 iteration is 3.142396926879883 \n",
            "Train loss at 2099 iteration is 3.3362648487091064 \n",
            "Train loss at 2100 iteration is 3.2124500274658203 \n",
            "Train loss at 2101 iteration is 3.14509654045105 \n",
            "Train loss at 2102 iteration is 3.1612038612365723 \n",
            "Train loss at 2103 iteration is 3.3275768756866455 \n",
            "Train loss at 2104 iteration is 3.0376603603363037 \n",
            "Train loss at 2105 iteration is 3.0980424880981445 \n",
            "Train loss at 2106 iteration is 3.2261600494384766 \n",
            "Train loss at 2107 iteration is 3.123204469680786 \n",
            "Train loss at 2108 iteration is 3.0104715824127197 \n",
            "Train loss at 2109 iteration is 3.235373020172119 \n",
            "Train loss at 2110 iteration is 3.0212481021881104 \n",
            "Train loss at 2111 iteration is 3.294390916824341 \n",
            "Train loss at 2112 iteration is 3.285665512084961 \n",
            "Train loss at 2113 iteration is 3.211150646209717 \n",
            "Train loss at 2114 iteration is 3.4038052558898926 \n",
            "Train loss at 2115 iteration is 3.0400824546813965 \n",
            "Train loss at 2116 iteration is 3.2456772327423096 \n",
            "Train loss at 2117 iteration is 3.2962875366210938 \n",
            "Train loss at 2118 iteration is 3.0480363368988037 \n",
            "Train loss at 2119 iteration is 3.090477466583252 \n",
            "Train loss at 2120 iteration is 3.448134422302246 \n",
            "Train loss at 2121 iteration is 3.1562771797180176 \n",
            "Train loss at 2122 iteration is 3.1710569858551025 \n",
            "Train loss at 2123 iteration is 3.1477763652801514 \n",
            "Train loss at 2124 iteration is 3.187297821044922 \n",
            "Train loss at 2125 iteration is 3.1745147705078125 \n",
            "Train loss at 2126 iteration is 3.2232747077941895 \n",
            "Train loss at 2127 iteration is 3.208232879638672 \n",
            "Train loss at 2128 iteration is 3.0462684631347656 \n",
            "Train loss at 2129 iteration is 3.3187177181243896 \n",
            "Train loss at 2130 iteration is 3.217092752456665 \n",
            "Train loss at 2131 iteration is 3.165907382965088 \n",
            "Train loss at 2132 iteration is 3.2052295207977295 \n",
            "Train loss at 2133 iteration is 3.171288251876831 \n",
            "Train loss at 2134 iteration is 3.0321433544158936 \n",
            "Train loss at 2135 iteration is 3.1877212524414062 \n",
            "Train loss at 2136 iteration is 3.2742061614990234 \n",
            "Train loss at 2137 iteration is 3.149513006210327 \n",
            "Train loss at 2138 iteration is 2.99587082862854 \n",
            "Train loss at 2139 iteration is 3.278827428817749 \n",
            "Train loss at 2140 iteration is 3.0941197872161865 \n",
            "Train loss at 2141 iteration is 3.181143283843994 \n",
            "Train loss at 2142 iteration is 3.1509242057800293 \n",
            "Train loss at 2143 iteration is 3.1351590156555176 \n",
            "Train loss at 2144 iteration is 3.2322616577148438 \n",
            "Train loss at 2145 iteration is 3.135704278945923 \n",
            "Train loss at 2146 iteration is 3.1632015705108643 \n",
            "Train loss at 2147 iteration is 3.3096766471862793 \n",
            "Train loss at 2148 iteration is 3.0627620220184326 \n",
            "Train loss at 2149 iteration is 3.23207950592041 \n",
            "Train loss at 2150 iteration is 3.306764841079712 \n",
            "Train loss at 2151 iteration is 3.2960541248321533 \n",
            "Train loss at 2152 iteration is 3.1149399280548096 \n",
            "Train loss at 2153 iteration is 3.3800048828125 \n",
            "Train loss at 2154 iteration is 3.2100839614868164 \n",
            "Train loss at 2155 iteration is 2.8229846954345703 \n",
            "Train loss at 2156 iteration is 3.201930046081543 \n",
            "Train loss at 2157 iteration is 3.2481939792633057 \n",
            "Train loss at 2158 iteration is 3.1326210498809814 \n",
            "Train loss at 2159 iteration is 3.2427375316619873 \n",
            "Train loss at 2160 iteration is 3.374169111251831 \n",
            "Train loss at 2161 iteration is 3.1409332752227783 \n",
            "Train loss at 2162 iteration is 3.219245195388794 \n",
            "Train loss at 2163 iteration is 3.222419261932373 \n",
            "Train loss at 2164 iteration is 3.31889009475708 \n",
            "Train loss at 2165 iteration is 3.1321136951446533 \n",
            "Train loss at 2166 iteration is 3.186415433883667 \n",
            "Train loss at 2167 iteration is 3.3543574810028076 \n",
            "Train loss at 2168 iteration is 3.1802778244018555 \n",
            "Train loss at 2169 iteration is 3.05368709564209 \n",
            "Train loss at 2170 iteration is 3.124164581298828 \n",
            "Train loss at 2171 iteration is 3.1609795093536377 \n",
            "Train loss at 2172 iteration is 3.1424872875213623 \n",
            "Train loss at 2173 iteration is 2.9137632846832275 \n",
            "Train loss at 2174 iteration is 3.286853075027466 \n",
            "Train loss at 2175 iteration is 3.3326034545898438 \n",
            "Train loss at 2176 iteration is 3.4074392318725586 \n",
            "Train loss at 2177 iteration is 3.14860200881958 \n",
            "Train loss at 2178 iteration is 3.4535133838653564 \n",
            "Train loss at 2179 iteration is 3.1546144485473633 \n",
            "Train loss at 2180 iteration is 3.2780961990356445 \n",
            "Train loss at 2181 iteration is 3.283688545227051 \n",
            "Train loss at 2182 iteration is 3.0951356887817383 \n",
            "Train loss at 2183 iteration is 3.227292776107788 \n",
            "Train loss at 2184 iteration is 3.064208745956421 \n",
            "Train loss at 2185 iteration is 3.247267484664917 \n",
            "Train loss at 2186 iteration is 3.051419973373413 \n",
            "Train loss at 2187 iteration is 3.1554114818573 \n",
            "Train loss at 2188 iteration is 3.1752078533172607 \n",
            "Train loss at 2189 iteration is 3.2670466899871826 \n",
            "Train loss at 2190 iteration is 3.172287702560425 \n",
            "Train loss at 2191 iteration is 3.0829432010650635 \n",
            "Train loss at 2192 iteration is 3.1116974353790283 \n",
            "Train loss at 2193 iteration is 3.0984106063842773 \n",
            "Train loss at 2194 iteration is 3.3841395378112793 \n",
            "Train loss at 2195 iteration is 3.1407554149627686 \n",
            "Train loss at 2196 iteration is 3.201195240020752 \n",
            "Train loss at 2197 iteration is 3.227512836456299 \n",
            "Train loss at 2198 iteration is 3.2646002769470215 \n",
            "Train loss at 2199 iteration is 3.2140417098999023 \n",
            "Train loss at 2200 iteration is 3.1044692993164062 \n",
            "Train loss at 2201 iteration is 3.090559959411621 \n",
            "Train loss at 2202 iteration is 3.063990831375122 \n",
            "Train loss at 2203 iteration is 3.043883800506592 \n",
            "Train loss at 2204 iteration is 3.370396852493286 \n",
            "Train loss at 2205 iteration is 3.218001127243042 \n",
            "Train loss at 2206 iteration is 3.0668106079101562 \n",
            "Train loss at 2207 iteration is 3.323373794555664 \n",
            "Train loss at 2208 iteration is 3.0589005947113037 \n",
            "Train loss at 2209 iteration is 3.283264636993408 \n",
            "Train loss at 2210 iteration is 3.0496013164520264 \n",
            "Train loss at 2211 iteration is 3.20273756980896 \n",
            "Train loss at 2212 iteration is 2.8723607063293457 \n",
            "Train loss at 2213 iteration is 3.315396785736084 \n",
            "Train loss at 2214 iteration is 3.2244222164154053 \n",
            "Train loss at 2215 iteration is 3.1454238891601562 \n",
            "Train loss at 2216 iteration is 3.138589859008789 \n",
            "Train loss at 2217 iteration is 3.3211874961853027 \n",
            "Train loss at 2218 iteration is 3.337522506713867 \n",
            "Train loss at 2219 iteration is 3.173258066177368 \n",
            "Train loss at 2220 iteration is 3.37396502494812 \n",
            "Train loss at 2221 iteration is 3.0026133060455322 \n",
            "Train loss at 2222 iteration is 3.156731367111206 \n",
            "Train loss at 2223 iteration is 3.064364433288574 \n",
            "Train loss at 2224 iteration is 3.0462069511413574 \n",
            "Train loss at 2225 iteration is 3.4181034564971924 \n",
            "Train loss at 2226 iteration is 3.2439382076263428 \n",
            "Train loss at 2227 iteration is 3.197662830352783 \n",
            "Train loss at 2228 iteration is 3.2395458221435547 \n",
            "Train loss at 2229 iteration is 3.2459394931793213 \n",
            "Train loss at 2230 iteration is 3.3264873027801514 \n",
            "Train loss at 2231 iteration is 3.044572591781616 \n",
            "Train loss at 2232 iteration is 3.0879650115966797 \n",
            "Train loss at 2233 iteration is 3.19892954826355 \n",
            "Train loss at 2234 iteration is 3.0845203399658203 \n",
            "Train loss at 2235 iteration is 3.1736690998077393 \n",
            "Train loss at 2236 iteration is 3.1830618381500244 \n",
            "Train loss at 2237 iteration is 3.127086877822876 \n",
            "Train loss at 2238 iteration is 3.020969867706299 \n",
            "Train loss at 2239 iteration is 3.1709163188934326 \n",
            "Train loss at 2240 iteration is 3.282644748687744 \n",
            "Train loss at 2241 iteration is 3.181297540664673 \n",
            "Train loss at 2242 iteration is 3.172504186630249 \n",
            "Train loss at 2243 iteration is 3.3587727546691895 \n",
            "Train loss at 2244 iteration is 3.3661437034606934 \n",
            "Train loss at 2245 iteration is 3.1174261569976807 \n",
            "Train loss at 2246 iteration is 3.233428478240967 \n",
            "Train loss at 2247 iteration is 3.2058444023132324 \n",
            "Train loss at 2248 iteration is 3.377739429473877 \n",
            "Train loss at 2249 iteration is 2.986988067626953 \n",
            "Train loss at 2250 iteration is 3.180330991744995 \n",
            "Train loss at 2251 iteration is 3.131016254425049 \n",
            "Train loss at 2252 iteration is 3.1739726066589355 \n",
            "Train loss at 2253 iteration is 3.263962984085083 \n",
            "Train loss at 2254 iteration is 3.174180507659912 \n",
            "Train loss at 2255 iteration is 3.2145559787750244 \n",
            "Train loss at 2256 iteration is 3.428359270095825 \n",
            "Train loss at 2257 iteration is 3.091611862182617 \n",
            "Train loss at 2258 iteration is 3.161421775817871 \n",
            "Train loss at 2259 iteration is 3.251271963119507 \n",
            "Train loss at 2260 iteration is 3.203230857849121 \n",
            "Train loss at 2261 iteration is 3.2149016857147217 \n",
            "Train loss at 2262 iteration is 3.3129146099090576 \n",
            "Train loss at 2263 iteration is 3.0780599117279053 \n",
            "Train loss at 2264 iteration is 3.254378318786621 \n",
            "Train loss at 2265 iteration is 3.130418062210083 \n",
            "Train loss at 2266 iteration is 2.988374710083008 \n",
            "Train loss at 2267 iteration is 3.1870522499084473 \n",
            "Train loss at 2268 iteration is 3.3229615688323975 \n",
            "Train loss at 2269 iteration is 3.0064101219177246 \n",
            "Train loss at 2270 iteration is 3.328616142272949 \n",
            "Train loss at 2271 iteration is 3.3567826747894287 \n",
            "Train loss at 2272 iteration is 3.428262233734131 \n",
            "Train loss at 2273 iteration is 3.3793907165527344 \n",
            "Train loss at 2274 iteration is 3.154378652572632 \n",
            "Train loss at 2275 iteration is 3.278306245803833 \n",
            "Train loss at 2276 iteration is 3.0239715576171875 \n",
            "Train loss at 2277 iteration is 3.0637128353118896 \n",
            "Train loss at 2278 iteration is 3.481316566467285 \n",
            "Train loss at 2279 iteration is 3.337893486022949 \n",
            "Train loss at 2280 iteration is 3.041764259338379 \n",
            "Train loss at 2281 iteration is 3.0641517639160156 \n",
            "Train loss at 2282 iteration is 3.2545647621154785 \n",
            "Train loss at 2283 iteration is 3.425572395324707 \n",
            "Train loss at 2284 iteration is 3.3188633918762207 \n",
            "Train loss at 2285 iteration is 3.1557562351226807 \n",
            "Train loss at 2286 iteration is 3.0762786865234375 \n",
            "Train loss at 2287 iteration is 3.2282588481903076 \n",
            "Train loss at 2288 iteration is 3.1267786026000977 \n",
            "Train loss at 2289 iteration is 3.138903856277466 \n",
            "Train loss at 2290 iteration is 3.0878312587738037 \n",
            "Train loss at 2291 iteration is 3.2852468490600586 \n",
            "Train loss at 2292 iteration is 3.083937644958496 \n",
            "Train loss at 2293 iteration is 3.180630922317505 \n",
            "Train loss at 2294 iteration is 3.0777504444122314 \n",
            "Train loss at 2295 iteration is 3.3159568309783936 \n",
            "Train loss at 2296 iteration is 3.1662957668304443 \n",
            "Train loss at 2297 iteration is 3.2193045616149902 \n",
            "Train loss at 2298 iteration is 3.099334478378296 \n",
            "Train loss at 2299 iteration is 3.2013328075408936 \n",
            "Train loss at 2300 iteration is 3.3964028358459473 \n",
            "Train loss at 2301 iteration is 3.0978050231933594 \n",
            "Train loss at 2302 iteration is 2.888927698135376 \n",
            "Train loss at 2303 iteration is 3.3676719665527344 \n",
            "Train loss at 2304 iteration is 3.1405205726623535 \n",
            "Train loss at 2305 iteration is 3.1878504753112793 \n",
            "Train loss at 2306 iteration is 3.238037109375 \n",
            "Train loss at 2307 iteration is 3.180530309677124 \n",
            "Train loss at 2308 iteration is 3.2997236251831055 \n",
            "Train loss at 2309 iteration is 3.3028972148895264 \n",
            "Train loss at 2310 iteration is 3.33201265335083 \n",
            "Train loss at 2311 iteration is 3.040574312210083 \n",
            "Train loss at 2312 iteration is 3.2022643089294434 \n",
            "Train loss at 2313 iteration is 3.12658953666687 \n",
            "Train loss at 2314 iteration is 3.2317755222320557 \n",
            "Train loss at 2315 iteration is 3.387296438217163 \n",
            "Train loss at 2316 iteration is 3.091702699661255 \n",
            "Train loss at 2317 iteration is 3.133570671081543 \n",
            "Train loss at 2318 iteration is 3.280250072479248 \n",
            "Train loss at 2319 iteration is 2.9520936012268066 \n",
            "Train loss at 2320 iteration is 3.3208322525024414 \n",
            "Train loss at 2321 iteration is 3.1338155269622803 \n",
            "Train loss at 2322 iteration is 3.17045259475708 \n",
            "Train loss at 2323 iteration is 3.3372037410736084 \n",
            "Train loss at 2324 iteration is 3.246190309524536 \n",
            "Train loss at 2325 iteration is 3.387965202331543 \n",
            "Train loss at 2326 iteration is 3.1697094440460205 \n",
            "Train loss at 2327 iteration is 3.086294174194336 \n",
            "Train loss at 2328 iteration is 3.210221290588379 \n",
            "Train loss at 2329 iteration is 3.133267641067505 \n",
            "Train loss at 2330 iteration is 3.0457921028137207 \n",
            "Train loss at 2331 iteration is 3.258801221847534 \n",
            "Train loss at 2332 iteration is 3.3593838214874268 \n",
            "Train loss at 2333 iteration is 3.18251371383667 \n",
            "Train loss at 2334 iteration is 3.1072182655334473 \n",
            "Train loss at 2335 iteration is 3.0897555351257324 \n",
            "Train loss at 2336 iteration is 3.090296983718872 \n",
            "Train loss at 2337 iteration is 3.0989253520965576 \n",
            "Train loss at 2338 iteration is 3.2503662109375 \n",
            "Train loss at 2339 iteration is 3.148991107940674 \n",
            "Train loss at 2340 iteration is 3.487494945526123 \n",
            "Train loss at 2341 iteration is 3.230651617050171 \n",
            "Train loss at 2342 iteration is 3.112070083618164 \n",
            "Train loss at 2343 iteration is 3.142385244369507 \n",
            "Train loss at 2344 iteration is 3.232243061065674 \n",
            "Train loss at 2345 iteration is 3.0670201778411865 \n",
            "Train loss at 2346 iteration is 3.2834291458129883 \n",
            "Train loss at 2347 iteration is 3.4462764263153076 \n",
            "Train loss at 2348 iteration is 3.183218240737915 \n",
            "Train loss at 2349 iteration is 3.1761481761932373 \n",
            "Train loss at 2350 iteration is 3.201394557952881 \n",
            "Train loss at 2351 iteration is 3.2445242404937744 \n",
            "Train loss at 2352 iteration is 3.310140609741211 \n",
            "Train loss at 2353 iteration is 3.1672959327697754 \n",
            "Train loss at 2354 iteration is 3.1783368587493896 \n",
            "Train loss at 2355 iteration is 3.3238332271575928 \n",
            "Train loss at 2356 iteration is 3.3558878898620605 \n",
            "Train loss at 2357 iteration is 3.1296849250793457 \n",
            "Train loss at 2358 iteration is 3.2624928951263428 \n",
            "Train loss at 2359 iteration is 3.2863564491271973 \n",
            "Train loss at 2360 iteration is 3.2606446743011475 \n",
            "Train loss at 2361 iteration is 3.2774770259857178 \n",
            "Train loss at 2362 iteration is 3.2046258449554443 \n",
            "Train loss at 2363 iteration is 3.2461259365081787 \n",
            "Train loss at 2364 iteration is 3.2284722328186035 \n",
            "Train loss at 2365 iteration is 3.1913673877716064 \n",
            "Train loss at 2366 iteration is 3.3251399993896484 \n",
            "Train loss at 2367 iteration is 3.280567169189453 \n",
            "Train loss at 2368 iteration is 2.9992728233337402 \n",
            "Train loss at 2369 iteration is 3.196826219558716 \n",
            "Train loss at 2370 iteration is 3.2503697872161865 \n",
            "Train loss at 2371 iteration is 3.3168697357177734 \n",
            "Train loss at 2372 iteration is 3.1595723628997803 \n",
            "Train loss at 2373 iteration is 2.894674777984619 \n",
            "Train loss at 2374 iteration is 3.195286512374878 \n",
            "Train loss at 2375 iteration is 3.18641996383667 \n",
            "Train loss at 2376 iteration is 3.121535062789917 \n",
            "Train loss at 2377 iteration is 3.298854112625122 \n",
            "Train loss at 2378 iteration is 3.2605884075164795 \n",
            "Train loss at 2379 iteration is 3.235332727432251 \n",
            "Train loss at 2380 iteration is 3.2025246620178223 \n",
            "Train loss at 2381 iteration is 3.1538445949554443 \n",
            "Train loss at 2382 iteration is 3.1204426288604736 \n",
            "Train loss at 2383 iteration is 3.2584152221679688 \n",
            "Train loss at 2384 iteration is 3.1825733184814453 \n",
            "Train loss at 2385 iteration is 3.0335195064544678 \n",
            "Train loss at 2386 iteration is 3.220484733581543 \n",
            "Train loss at 2387 iteration is 3.2358813285827637 \n",
            "Train loss at 2388 iteration is 3.4601683616638184 \n",
            "Train loss at 2389 iteration is 3.0232760906219482 \n",
            "Train loss at 2390 iteration is 3.0699663162231445 \n",
            "Train loss at 2391 iteration is 3.304274559020996 \n",
            "Train loss at 2392 iteration is 3.256925106048584 \n",
            "Train loss at 2393 iteration is 3.1415040493011475 \n",
            "Train loss at 2394 iteration is 3.2898874282836914 \n",
            "Train loss at 2395 iteration is 3.174525499343872 \n",
            "Train loss at 2396 iteration is 3.236743211746216 \n",
            "Train loss at 2397 iteration is 3.064811944961548 \n",
            "Train loss at 2398 iteration is 3.144805431365967 \n",
            "Train loss at 2399 iteration is 3.1854121685028076 \n",
            "Train loss at 2400 iteration is 3.122105121612549 \n",
            "Train loss at 2401 iteration is 3.0815653800964355 \n",
            "Train loss at 2402 iteration is 3.2724609375 \n",
            "Train loss at 2403 iteration is 3.4086592197418213 \n",
            "Train loss at 2404 iteration is 3.2604527473449707 \n",
            "Train loss at 2405 iteration is 3.1212892532348633 \n",
            "Train loss at 2406 iteration is 3.1475532054901123 \n",
            "Train loss at 2407 iteration is 3.2956907749176025 \n",
            "Train loss at 2408 iteration is 3.2139060497283936 \n",
            "Train loss at 2409 iteration is 3.108642578125 \n",
            "Train loss at 2410 iteration is 3.473525285720825 \n",
            "Train loss at 2411 iteration is 3.18880033493042 \n",
            "Train loss at 2412 iteration is 3.05096435546875 \n",
            "Train loss at 2413 iteration is 3.3900978565216064 \n",
            "Train loss at 2414 iteration is 3.3501298427581787 \n",
            "Train loss at 2415 iteration is 3.085552930831909 \n",
            "Train loss at 2416 iteration is 3.348389148712158 \n",
            "Train loss at 2417 iteration is 3.1561408042907715 \n",
            "Train loss at 2418 iteration is 3.05810546875 \n",
            "Train loss at 2419 iteration is 3.2190515995025635 \n",
            "Train loss at 2420 iteration is 3.3053925037384033 \n",
            "Train loss at 2421 iteration is 3.1885509490966797 \n",
            "Train loss at 2422 iteration is 3.3627185821533203 \n",
            "Train loss at 2423 iteration is 3.262777090072632 \n",
            "Train loss at 2424 iteration is 3.3139448165893555 \n",
            "Train loss at 2425 iteration is 3.389054536819458 \n",
            "Train loss at 2426 iteration is 3.262305736541748 \n",
            "Train loss at 2427 iteration is 3.0572540760040283 \n",
            "Train loss at 2428 iteration is 3.248293876647949 \n",
            "Train loss at 2429 iteration is 3.187621831893921 \n",
            "Train loss at 2430 iteration is 3.207127332687378 \n",
            "Train loss at 2431 iteration is 3.4029436111450195 \n",
            "Train loss at 2432 iteration is 3.082751989364624 \n",
            "Train loss at 2433 iteration is 3.1556224822998047 \n",
            "Train loss at 2434 iteration is 3.398491621017456 \n",
            "Train loss at 2435 iteration is 3.271655797958374 \n",
            "Train loss at 2436 iteration is 3.1738171577453613 \n",
            "Train loss at 2437 iteration is 3.3218634128570557 \n",
            "Train loss at 2438 iteration is 3.3351118564605713 \n",
            "Train loss at 2439 iteration is 3.2285008430480957 \n",
            "Train loss at 2440 iteration is 3.1858856678009033 \n",
            "Train loss at 2441 iteration is 3.375504970550537 \n",
            "Train loss at 2442 iteration is 3.1774799823760986 \n",
            "Train loss at 2443 iteration is 3.117929697036743 \n",
            "Train loss at 2444 iteration is 3.1943519115448 \n",
            "Train loss at 2445 iteration is 3.2255632877349854 \n",
            "Train loss at 2446 iteration is 3.170154571533203 \n",
            "Train loss at 2447 iteration is 3.2272889614105225 \n",
            "Train loss at 2448 iteration is 3.2159152030944824 \n",
            "Train loss at 2449 iteration is 3.447080135345459 \n",
            "Train loss at 2450 iteration is 3.2029213905334473 \n",
            "Train loss at 2451 iteration is 3.2265236377716064 \n",
            "Train loss at 2452 iteration is 3.136204481124878 \n",
            "Train loss at 2453 iteration is 3.278958797454834 \n",
            "Train loss at 2454 iteration is 3.452951431274414 \n",
            "Train loss at 2455 iteration is 3.1141088008880615 \n",
            "Train loss at 2456 iteration is 3.37212872505188 \n",
            "Train loss at 2457 iteration is 3.3040685653686523 \n",
            "Train loss at 2458 iteration is 2.9450838565826416 \n",
            "Train loss at 2459 iteration is 3.0189208984375 \n",
            "Train loss at 2460 iteration is 3.3737988471984863 \n",
            "Train loss at 2461 iteration is 3.268162965774536 \n",
            "Train loss at 2462 iteration is 3.263577938079834 \n",
            "Train loss at 2463 iteration is 3.0917704105377197 \n",
            "Train loss at 2464 iteration is 3.042318820953369 \n",
            "Train loss at 2465 iteration is 3.2184019088745117 \n",
            "Train loss at 2466 iteration is 2.982903242111206 \n",
            "Train loss at 2467 iteration is 3.2349369525909424 \n",
            "Train loss at 2468 iteration is 3.128331422805786 \n",
            "Train loss at 2469 iteration is 3.1788275241851807 \n",
            "Train loss at 2470 iteration is 3.038522243499756 \n",
            "Train loss at 2471 iteration is 3.1691486835479736 \n",
            "Train loss at 2472 iteration is 3.4913315773010254 \n",
            "Train loss at 2473 iteration is 3.243746042251587 \n",
            "Train loss at 2474 iteration is 3.2456624507904053 \n",
            "Train loss at 2475 iteration is 3.271494150161743 \n",
            "Train loss at 2476 iteration is 3.1336095333099365 \n",
            "Train loss at 2477 iteration is 3.2262420654296875 \n",
            "Train loss at 2478 iteration is 3.462036371231079 \n",
            "Train loss at 2479 iteration is 3.134147882461548 \n",
            "Train loss at 2480 iteration is 3.2822275161743164 \n",
            "Train loss at 2481 iteration is 3.187156915664673 \n",
            "Train loss at 2482 iteration is 3.268698215484619 \n",
            "Train loss at 2483 iteration is 3.2643516063690186 \n",
            "Train loss at 2484 iteration is 3.2506721019744873 \n",
            "Train loss at 2485 iteration is 3.1641502380371094 \n",
            "Train loss at 2486 iteration is 3.1152541637420654 \n",
            "Train loss at 2487 iteration is 3.396926164627075 \n",
            "Train loss at 2488 iteration is 3.1898279190063477 \n",
            "Train loss at 2489 iteration is 3.075371503829956 \n",
            "Train loss at 2490 iteration is 2.9895007610321045 \n",
            "Train loss at 2491 iteration is 3.2654120922088623 \n",
            "Train loss at 2492 iteration is 3.2606887817382812 \n",
            "Train loss at 2493 iteration is 3.0492091178894043 \n",
            "Train loss at 2494 iteration is 3.008730888366699 \n",
            "Train loss at 2495 iteration is 3.2579188346862793 \n",
            "Train loss at 2496 iteration is 3.27707839012146 \n",
            "Train loss at 2497 iteration is 3.2068676948547363 \n",
            "Train loss at 2498 iteration is 3.0403318405151367 \n",
            "Train loss at 2499 iteration is 2.990417242050171 \n",
            "Train loss at 2500 iteration is 3.207667350769043 \n",
            "Train loss at 2501 iteration is 3.395256996154785 \n",
            "Train loss at 2502 iteration is 3.243147850036621 \n",
            "Train loss at 2503 iteration is 3.1017720699310303 \n",
            "Train loss at 2504 iteration is 3.162299633026123 \n",
            "Train loss at 2505 iteration is 3.3472023010253906 \n",
            "Train loss at 2506 iteration is 3.3834149837493896 \n",
            "Train loss at 2507 iteration is 3.269620895385742 \n",
            "Train loss at 2508 iteration is 3.217374324798584 \n",
            "Train loss at 2509 iteration is 3.2879955768585205 \n",
            "Train loss at 2510 iteration is 3.211656332015991 \n",
            "Train loss at 2511 iteration is 3.3034887313842773 \n",
            "Train loss at 2512 iteration is 3.2700815200805664 \n",
            "Train loss at 2513 iteration is 3.341118574142456 \n",
            "Train loss at 2514 iteration is 3.3053908348083496 \n",
            "Train loss at 2515 iteration is 3.111140489578247 \n",
            "Train loss at 2516 iteration is 3.3485023975372314 \n",
            "Train loss at 2517 iteration is 3.303161144256592 \n",
            "Train loss at 2518 iteration is 3.1669130325317383 \n",
            "Train loss at 2519 iteration is 3.2074148654937744 \n",
            "Train loss at 2520 iteration is 3.2744343280792236 \n",
            "Train loss at 2521 iteration is 3.227544069290161 \n",
            "Train loss at 2522 iteration is 3.2596287727355957 \n",
            "Train loss at 2523 iteration is 3.2966678142547607 \n",
            "Train loss at 2524 iteration is 3.2311387062072754 \n",
            "Train loss at 2525 iteration is 3.4127888679504395 \n",
            "Train loss at 2526 iteration is 3.030938148498535 \n",
            "Train loss at 2527 iteration is 3.028294801712036 \n",
            "Train loss at 2528 iteration is 3.2919936180114746 \n",
            "Train loss at 2529 iteration is 3.2061314582824707 \n",
            "Train loss at 2530 iteration is 3.0872035026550293 \n",
            "Train loss at 2531 iteration is 3.3868420124053955 \n",
            "Train loss at 2532 iteration is 3.261383056640625 \n",
            "Train loss at 2533 iteration is 3.3870038986206055 \n",
            "Train loss at 2534 iteration is 3.1535797119140625 \n",
            "Train loss at 2535 iteration is 3.008732795715332 \n",
            "Train loss at 2536 iteration is 3.3801891803741455 \n",
            "Train loss at 2537 iteration is 3.2344815731048584 \n",
            "Train loss at 2538 iteration is 3.3172597885131836 \n",
            "Train loss at 2539 iteration is 3.291635751724243 \n",
            "Train loss at 2540 iteration is 3.1888630390167236 \n",
            "Train loss at 2541 iteration is 3.077094554901123 \n",
            "Train loss at 2542 iteration is 3.2631118297576904 \n",
            "Train loss at 2543 iteration is 3.1444735527038574 \n",
            "Train loss at 2544 iteration is 3.1475541591644287 \n",
            "Train loss at 2545 iteration is 3.2158167362213135 \n",
            "Train loss at 2546 iteration is 3.2217700481414795 \n",
            "Train loss at 2547 iteration is 3.2734029293060303 \n",
            "Train loss at 2548 iteration is 3.2771553993225098 \n",
            "Train loss at 2549 iteration is 3.0573432445526123 \n",
            "Train loss at 2550 iteration is 3.2690107822418213 \n",
            "Train loss at 2551 iteration is 3.409621238708496 \n",
            "Train loss at 2552 iteration is 3.4289724826812744 \n",
            "Train loss at 2553 iteration is 3.35394287109375 \n",
            "Train loss at 2554 iteration is 3.1477489471435547 \n",
            "Train loss at 2555 iteration is 3.29258394241333 \n",
            "Train loss at 2556 iteration is 3.2418577671051025 \n",
            "Train loss at 2557 iteration is 3.2720961570739746 \n",
            "Train loss at 2558 iteration is 3.2813069820404053 \n",
            "Train loss at 2559 iteration is 3.328853130340576 \n",
            "Train loss at 2560 iteration is 3.03210711479187 \n",
            "Train loss at 2561 iteration is 3.0074961185455322 \n",
            "Train loss at 2562 iteration is 3.1919498443603516 \n",
            "Train loss at 2563 iteration is 3.2445216178894043 \n",
            "Train loss at 2564 iteration is 3.1180737018585205 \n",
            "Train loss at 2565 iteration is 3.204838991165161 \n",
            "Train loss at 2566 iteration is 3.265660524368286 \n",
            "Train loss at 2567 iteration is 3.436713933944702 \n",
            "Train loss at 2568 iteration is 3.002204179763794 \n",
            "Train loss at 2569 iteration is 3.2481937408447266 \n",
            "Train loss at 2570 iteration is 2.9531328678131104 \n",
            "Train loss at 2571 iteration is 3.1128110885620117 \n",
            "Train loss at 2572 iteration is 3.0054304599761963 \n",
            "Train loss at 2573 iteration is 3.1739416122436523 \n",
            "Train loss at 2574 iteration is 3.0999128818511963 \n",
            "Train loss at 2575 iteration is 3.41086483001709 \n",
            "Train loss at 2576 iteration is 3.1813125610351562 \n",
            "Train loss at 2577 iteration is 3.4560916423797607 \n",
            "Train loss at 2578 iteration is 3.0660722255706787 \n",
            "Train loss at 2579 iteration is 3.3321709632873535 \n",
            "Train loss at 2580 iteration is 3.355137586593628 \n",
            "Train loss at 2581 iteration is 3.301248788833618 \n",
            "Train loss at 2582 iteration is 3.3305201530456543 \n",
            "Train loss at 2583 iteration is 3.1257526874542236 \n",
            "Train loss at 2584 iteration is 3.033580780029297 \n",
            "Train loss at 2585 iteration is 3.2052106857299805 \n",
            "Train loss at 2586 iteration is 3.1719398498535156 \n",
            "Train loss at 2587 iteration is 3.4113783836364746 \n",
            "Train loss at 2588 iteration is 3.3841962814331055 \n",
            "Train loss at 2589 iteration is 3.233739137649536 \n",
            "Train loss at 2590 iteration is 3.2579662799835205 \n",
            "Train loss at 2591 iteration is 3.4484660625457764 \n",
            "Train loss at 2592 iteration is 3.388244152069092 \n",
            "Train loss at 2593 iteration is 3.428891181945801 \n",
            "Train loss at 2594 iteration is 3.352796792984009 \n",
            "Train loss at 2595 iteration is 3.4508304595947266 \n",
            "Train loss at 2596 iteration is 3.230053663253784 \n",
            "Train loss at 2597 iteration is 3.363229274749756 \n",
            "Train loss at 2598 iteration is 3.0927858352661133 \n",
            "Train loss at 2599 iteration is 3.0998969078063965 \n",
            "Train loss at 2600 iteration is 3.2583513259887695 \n",
            "Train loss at 2601 iteration is 3.3790764808654785 \n",
            "Train loss at 2602 iteration is 3.2293951511383057 \n",
            "Train loss at 2603 iteration is 3.326498031616211 \n",
            "Train loss at 2604 iteration is 3.0817525386810303 \n",
            "Train loss at 2605 iteration is 3.286062002182007 \n",
            "Train loss at 2606 iteration is 3.459653377532959 \n",
            "Train loss at 2607 iteration is 3.105354070663452 \n",
            "Train loss at 2608 iteration is 3.147047281265259 \n",
            "Train loss at 2609 iteration is 3.2113640308380127 \n",
            "Train loss at 2610 iteration is 3.0711638927459717 \n",
            "Train loss at 2611 iteration is 3.3517136573791504 \n",
            "Train loss at 2612 iteration is 3.3275182247161865 \n",
            "Train loss at 2613 iteration is 3.2318472862243652 \n",
            "Train loss at 2614 iteration is 3.1348750591278076 \n",
            "Train loss at 2615 iteration is 3.4331188201904297 \n",
            "Train loss at 2616 iteration is 3.2149484157562256 \n",
            "Train loss at 2617 iteration is 3.0907914638519287 \n",
            "Train loss at 2618 iteration is 3.251521587371826 \n",
            "Train loss at 2619 iteration is 3.216550350189209 \n",
            "Train loss at 2620 iteration is 3.4353787899017334 \n",
            "Train loss at 2621 iteration is 3.351447582244873 \n",
            "Train loss at 2622 iteration is 3.239973306655884 \n",
            "Train loss at 2623 iteration is 3.421300172805786 \n",
            "Train loss at 2624 iteration is 3.2988083362579346 \n",
            "Train loss at 2625 iteration is 3.1870100498199463 \n",
            "Train loss at 2626 iteration is 3.133660078048706 \n",
            "Train loss at 2627 iteration is 3.2619946002960205 \n",
            "Train loss at 2628 iteration is 3.2892861366271973 \n",
            "Train loss at 2629 iteration is 3.458085298538208 \n",
            "Train loss at 2630 iteration is 3.0582356452941895 \n",
            "Train loss at 2631 iteration is 3.1152238845825195 \n",
            "Train loss at 2632 iteration is 3.0044984817504883 \n",
            "Train loss at 2633 iteration is 3.324047327041626 \n",
            "Train loss at 2634 iteration is 3.34417462348938 \n",
            "Train loss at 2635 iteration is 3.005080223083496 \n",
            "Train loss at 2636 iteration is 3.0505266189575195 \n",
            "Train loss at 2637 iteration is 3.168203115463257 \n",
            "Train loss at 2638 iteration is 2.990027666091919 \n",
            "Train loss at 2639 iteration is 3.106968402862549 \n",
            "Train loss at 2640 iteration is 3.2908473014831543 \n",
            "Train loss at 2641 iteration is 3.3447482585906982 \n",
            "Train loss at 2642 iteration is 3.283296585083008 \n",
            "Train loss at 2643 iteration is 3.415125608444214 \n",
            "Train loss at 2644 iteration is 3.25030779838562 \n",
            "Train loss at 2645 iteration is 3.1385607719421387 \n",
            "Train loss at 2646 iteration is 3.2466230392456055 \n",
            "Train loss at 2647 iteration is 3.234714984893799 \n",
            "Train loss at 2648 iteration is 3.314272880554199 \n",
            "Train loss at 2649 iteration is 3.142693281173706 \n",
            "Train loss at 2650 iteration is 3.3230223655700684 \n",
            "Train loss at 2651 iteration is 3.2877488136291504 \n",
            "Train loss at 2652 iteration is 3.246570587158203 \n",
            "Train loss at 2653 iteration is 3.3455326557159424 \n",
            "Train loss at 2654 iteration is 3.1624081134796143 \n",
            "Train loss at 2655 iteration is 3.0130863189697266 \n",
            "Train loss at 2656 iteration is 3.12785267829895 \n",
            "Train loss at 2657 iteration is 3.017979145050049 \n",
            "Train loss at 2658 iteration is 3.1673686504364014 \n",
            "Train loss at 2659 iteration is 3.522688388824463 \n",
            "Train loss at 2660 iteration is 3.3298802375793457 \n",
            "Train loss at 2661 iteration is 3.475274085998535 \n",
            "Train loss at 2662 iteration is 3.067824125289917 \n",
            "Train loss at 2663 iteration is 3.0920398235321045 \n",
            "Train loss at 2664 iteration is 3.203951120376587 \n",
            "Train loss at 2665 iteration is 3.155133008956909 \n",
            "Train loss at 2666 iteration is 3.0951755046844482 \n",
            "Train loss at 2667 iteration is 2.9754087924957275 \n",
            "Train loss at 2668 iteration is 3.183164596557617 \n",
            "Train loss at 2669 iteration is 3.2450878620147705 \n",
            "Train loss at 2670 iteration is 3.1949875354766846 \n",
            "Train loss at 2671 iteration is 3.264219045639038 \n",
            "Train loss at 2672 iteration is 3.297476053237915 \n",
            "Train loss at 2673 iteration is 3.0577292442321777 \n",
            "Train loss at 2674 iteration is 3.1913554668426514 \n",
            "Train loss at 2675 iteration is 3.252511501312256 \n",
            "Train loss at 2676 iteration is 3.3630948066711426 \n",
            "Train loss at 2677 iteration is 3.420247793197632 \n",
            "Train loss at 2678 iteration is 3.0755841732025146 \n",
            "Train loss at 2679 iteration is 3.0493016242980957 \n",
            "Train loss at 2680 iteration is 3.163235664367676 \n",
            "Train loss at 2681 iteration is 3.286839008331299 \n",
            "Train loss at 2682 iteration is 3.3194072246551514 \n",
            "Train loss at 2683 iteration is 3.2712061405181885 \n",
            "Train loss at 2684 iteration is 3.2616827487945557 \n",
            "Train loss at 2685 iteration is 3.2413830757141113 \n",
            "Train loss at 2686 iteration is 3.23173189163208 \n",
            "Train loss at 2687 iteration is 3.0819997787475586 \n",
            "Train loss at 2688 iteration is 3.0093910694122314 \n",
            "Train loss at 2689 iteration is 2.9414660930633545 \n",
            "Train loss at 2690 iteration is 2.974069595336914 \n",
            "Train loss at 2691 iteration is 2.7206671237945557 \n",
            "Train loss at 2692 iteration is 3.0806400775909424 \n",
            "Train loss at 2693 iteration is 2.878359079360962 \n",
            "Train loss at 2694 iteration is 2.9602506160736084 \n",
            "Train loss at 2695 iteration is 2.910762071609497 \n",
            "Train loss at 2696 iteration is 2.9569625854492188 \n",
            "Train loss at 2697 iteration is 2.9873085021972656 \n",
            "Train loss at 2698 iteration is 2.9445414543151855 \n",
            "Train loss at 2699 iteration is 2.9973607063293457 \n",
            "Train loss at 2700 iteration is 2.8993279933929443 \n",
            "Train loss at 2701 iteration is 3.0364599227905273 \n",
            "Train loss at 2702 iteration is 2.885636806488037 \n",
            "Train loss at 2703 iteration is 2.8914802074432373 \n",
            "Train loss at 2704 iteration is 3.040170669555664 \n",
            "Train loss at 2705 iteration is 2.8617780208587646 \n",
            "Train loss at 2706 iteration is 3.0534844398498535 \n",
            "Train loss at 2707 iteration is 2.9350745677948 \n",
            "Train loss at 2708 iteration is 3.0071287155151367 \n",
            "Train loss at 2709 iteration is 2.867272138595581 \n",
            "Train loss at 2710 iteration is 3.1370506286621094 \n",
            "Train loss at 2711 iteration is 2.870896100997925 \n",
            "Train loss at 2712 iteration is 2.817838430404663 \n",
            "Train loss at 2713 iteration is 2.970649480819702 \n",
            "Train loss at 2714 iteration is 2.962775230407715 \n",
            "Train loss at 2715 iteration is 3.061126947402954 \n",
            "Train loss at 2716 iteration is 2.9247798919677734 \n",
            "Train loss at 2717 iteration is 3.0425517559051514 \n",
            "Train loss at 2718 iteration is 2.9057114124298096 \n",
            "Train loss at 2719 iteration is 3.0150349140167236 \n",
            "Train loss at 2720 iteration is 2.8159773349761963 \n",
            "Train loss at 2721 iteration is 2.9686355590820312 \n",
            "Train loss at 2722 iteration is 2.9691162109375 \n",
            "Train loss at 2723 iteration is 2.9153716564178467 \n",
            "Train loss at 2724 iteration is 2.8563265800476074 \n",
            "Train loss at 2725 iteration is 3.057464838027954 \n",
            "Train loss at 2726 iteration is 3.0258166790008545 \n",
            "Train loss at 2727 iteration is 2.946370840072632 \n",
            "Train loss at 2728 iteration is 2.9589035511016846 \n",
            "Train loss at 2729 iteration is 3.1402463912963867 \n",
            "Train loss at 2730 iteration is 2.7937257289886475 \n",
            "Train loss at 2731 iteration is 3.0426816940307617 \n",
            "Train loss at 2732 iteration is 3.0130138397216797 \n",
            "Train loss at 2733 iteration is 2.966510772705078 \n",
            "Train loss at 2734 iteration is 3.0265798568725586 \n",
            "Train loss at 2735 iteration is 2.9439265727996826 \n",
            "Train loss at 2736 iteration is 2.8870627880096436 \n",
            "Train loss at 2737 iteration is 2.8550071716308594 \n",
            "Train loss at 2738 iteration is 2.972710132598877 \n",
            "Train loss at 2739 iteration is 3.0325510501861572 \n",
            "Train loss at 2740 iteration is 2.9549612998962402 \n",
            "Train loss at 2741 iteration is 2.913452625274658 \n",
            "Train loss at 2742 iteration is 2.9923095703125 \n",
            "Train loss at 2743 iteration is 2.9984071254730225 \n",
            "Train loss at 2744 iteration is 3.028705358505249 \n",
            "Train loss at 2745 iteration is 3.1126708984375 \n",
            "Train loss at 2746 iteration is 3.1021175384521484 \n",
            "Train loss at 2747 iteration is 2.95706844329834 \n",
            "Train loss at 2748 iteration is 2.788645029067993 \n",
            "Train loss at 2749 iteration is 3.1012959480285645 \n",
            "Train loss at 2750 iteration is 3.0402445793151855 \n",
            "Train loss at 2751 iteration is 3.0582427978515625 \n",
            "Train loss at 2752 iteration is 3.0010998249053955 \n",
            "Train loss at 2753 iteration is 3.0557243824005127 \n",
            "Train loss at 2754 iteration is 2.904709815979004 \n",
            "Train loss at 2755 iteration is 2.766000986099243 \n",
            "Train loss at 2756 iteration is 2.9232077598571777 \n",
            "Train loss at 2757 iteration is 2.952582597732544 \n",
            "Train loss at 2758 iteration is 2.9324288368225098 \n",
            "Train loss at 2759 iteration is 2.8838047981262207 \n",
            "Train loss at 2760 iteration is 2.975924253463745 \n",
            "Train loss at 2761 iteration is 2.950105905532837 \n",
            "Train loss at 2762 iteration is 3.0940940380096436 \n",
            "Train loss at 2763 iteration is 3.0442895889282227 \n",
            "Train loss at 2764 iteration is 2.9444425106048584 \n",
            "Train loss at 2765 iteration is 2.8976831436157227 \n",
            "Train loss at 2766 iteration is 3.043531656265259 \n",
            "Train loss at 2767 iteration is 2.881197690963745 \n",
            "Train loss at 2768 iteration is 2.8791427612304688 \n",
            "Train loss at 2769 iteration is 2.784792900085449 \n",
            "Train loss at 2770 iteration is 2.821782112121582 \n",
            "Train loss at 2771 iteration is 2.8379416465759277 \n",
            "Train loss at 2772 iteration is 3.063889980316162 \n",
            "Train loss at 2773 iteration is 2.882526159286499 \n",
            "Train loss at 2774 iteration is 2.812659978866577 \n",
            "Train loss at 2775 iteration is 2.9343087673187256 \n",
            "Train loss at 2776 iteration is 2.9889886379241943 \n",
            "Train loss at 2777 iteration is 3.1436357498168945 \n",
            "Train loss at 2778 iteration is 2.968456506729126 \n",
            "Train loss at 2779 iteration is 2.9891152381896973 \n",
            "Train loss at 2780 iteration is 3.075472116470337 \n",
            "Train loss at 2781 iteration is 2.9181222915649414 \n",
            "Train loss at 2782 iteration is 2.8256754875183105 \n",
            "Train loss at 2783 iteration is 3.016299247741699 \n",
            "Train loss at 2784 iteration is 3.3155386447906494 \n",
            "Train loss at 2785 iteration is 2.9732747077941895 \n",
            "Train loss at 2786 iteration is 3.0578393936157227 \n",
            "Train loss at 2787 iteration is 2.783344030380249 \n",
            "Train loss at 2788 iteration is 2.967393398284912 \n",
            "Train loss at 2789 iteration is 3.1335220336914062 \n",
            "Train loss at 2790 iteration is 2.9895179271698 \n",
            "Train loss at 2791 iteration is 2.8771309852600098 \n",
            "Train loss at 2792 iteration is 3.022433280944824 \n",
            "Train loss at 2793 iteration is 2.9872875213623047 \n",
            "Train loss at 2794 iteration is 3.0157742500305176 \n",
            "Train loss at 2795 iteration is 2.899142026901245 \n",
            "Train loss at 2796 iteration is 3.1177878379821777 \n",
            "Train loss at 2797 iteration is 3.0040524005889893 \n",
            "Train loss at 2798 iteration is 3.1689980030059814 \n",
            "Train loss at 2799 iteration is 3.1000750064849854 \n",
            "Train loss at 2800 iteration is 3.008957862854004 \n",
            "Train loss at 2801 iteration is 3.089927911758423 \n",
            "Train loss at 2802 iteration is 3.034172773361206 \n",
            "Train loss at 2803 iteration is 2.895273447036743 \n",
            "Train loss at 2804 iteration is 3.0962493419647217 \n",
            "Train loss at 2805 iteration is 3.158682346343994 \n",
            "Train loss at 2806 iteration is 2.9030158519744873 \n",
            "Train loss at 2807 iteration is 2.906677007675171 \n",
            "Train loss at 2808 iteration is 2.9782485961914062 \n",
            "Train loss at 2809 iteration is 2.948197841644287 \n",
            "Train loss at 2810 iteration is 2.9439806938171387 \n",
            "Train loss at 2811 iteration is 2.986898899078369 \n",
            "Train loss at 2812 iteration is 3.003568172454834 \n",
            "Train loss at 2813 iteration is 3.1908528804779053 \n",
            "Train loss at 2814 iteration is 2.9440104961395264 \n",
            "Train loss at 2815 iteration is 2.8521835803985596 \n",
            "Train loss at 2816 iteration is 3.13506817817688 \n",
            "Train loss at 2817 iteration is 3.0663421154022217 \n",
            "Train loss at 2818 iteration is 2.805337905883789 \n",
            "Train loss at 2819 iteration is 3.0180015563964844 \n",
            "Train loss at 2820 iteration is 2.9833180904388428 \n",
            "Train loss at 2821 iteration is 2.9050872325897217 \n",
            "Train loss at 2822 iteration is 3.013380527496338 \n",
            "Train loss at 2823 iteration is 3.087214708328247 \n",
            "Train loss at 2824 iteration is 3.060023069381714 \n",
            "Train loss at 2825 iteration is 3.011183500289917 \n",
            "Train loss at 2826 iteration is 2.88789963722229 \n",
            "Train loss at 2827 iteration is 2.9848134517669678 \n",
            "Train loss at 2828 iteration is 3.090895652770996 \n",
            "Train loss at 2829 iteration is 3.053875684738159 \n",
            "Train loss at 2830 iteration is 2.799912452697754 \n",
            "Train loss at 2831 iteration is 2.851076364517212 \n",
            "Train loss at 2832 iteration is 3.047778606414795 \n",
            "Train loss at 2833 iteration is 2.9552998542785645 \n",
            "Train loss at 2834 iteration is 2.8398008346557617 \n",
            "Train loss at 2835 iteration is 2.807213306427002 \n",
            "Train loss at 2836 iteration is 3.0877163410186768 \n",
            "Train loss at 2837 iteration is 3.065351963043213 \n",
            "Train loss at 2838 iteration is 2.9122445583343506 \n",
            "Train loss at 2839 iteration is 3.0115652084350586 \n",
            "Train loss at 2840 iteration is 2.9793498516082764 \n",
            "Train loss at 2841 iteration is 2.9704275131225586 \n",
            "Train loss at 2842 iteration is 3.194622755050659 \n",
            "Train loss at 2843 iteration is 3.094095230102539 \n",
            "Train loss at 2844 iteration is 3.0499255657196045 \n",
            "Train loss at 2845 iteration is 3.040666103363037 \n",
            "Train loss at 2846 iteration is 3.1468753814697266 \n",
            "Train loss at 2847 iteration is 3.0473430156707764 \n",
            "Train loss at 2848 iteration is 3.115180015563965 \n",
            "Train loss at 2849 iteration is 3.0314884185791016 \n",
            "Train loss at 2850 iteration is 2.811067581176758 \n",
            "Train loss at 2851 iteration is 2.941767454147339 \n",
            "Train loss at 2852 iteration is 2.980686902999878 \n",
            "Train loss at 2853 iteration is 3.0487794876098633 \n",
            "Train loss at 2854 iteration is 2.935110569000244 \n",
            "Train loss at 2855 iteration is 3.023045301437378 \n",
            "Train loss at 2856 iteration is 3.025428533554077 \n",
            "Train loss at 2857 iteration is 3.1682350635528564 \n",
            "Train loss at 2858 iteration is 2.9019036293029785 \n",
            "Train loss at 2859 iteration is 2.9857888221740723 \n",
            "Train loss at 2860 iteration is 3.0860252380371094 \n",
            "Train loss at 2861 iteration is 3.128812074661255 \n",
            "Train loss at 2862 iteration is 2.91947603225708 \n",
            "Train loss at 2863 iteration is 2.9389657974243164 \n",
            "Train loss at 2864 iteration is 2.992281913757324 \n",
            "Train loss at 2865 iteration is 2.964972972869873 \n",
            "Train loss at 2866 iteration is 2.9100513458251953 \n",
            "Train loss at 2867 iteration is 2.853822708129883 \n",
            "Train loss at 2868 iteration is 2.9131689071655273 \n",
            "Train loss at 2869 iteration is 2.902790069580078 \n",
            "Train loss at 2870 iteration is 2.9847841262817383 \n",
            "Train loss at 2871 iteration is 2.9152822494506836 \n",
            "Train loss at 2872 iteration is 3.138218641281128 \n",
            "Train loss at 2873 iteration is 3.0220978260040283 \n",
            "Train loss at 2874 iteration is 2.8574044704437256 \n",
            "Train loss at 2875 iteration is 3.0766654014587402 \n",
            "Train loss at 2876 iteration is 2.839688301086426 \n",
            "Train loss at 2877 iteration is 2.916640043258667 \n",
            "Train loss at 2878 iteration is 2.9436604976654053 \n",
            "Train loss at 2879 iteration is 2.94999623298645 \n",
            "Train loss at 2880 iteration is 3.0002288818359375 \n",
            "Train loss at 2881 iteration is 2.8569767475128174 \n",
            "Train loss at 2882 iteration is 2.8578624725341797 \n",
            "Train loss at 2883 iteration is 3.2011477947235107 \n",
            "Train loss at 2884 iteration is 2.960202693939209 \n",
            "Train loss at 2885 iteration is 3.125539779663086 \n",
            "Train loss at 2886 iteration is 3.026414155960083 \n",
            "Train loss at 2887 iteration is 2.9821414947509766 \n",
            "Train loss at 2888 iteration is 2.9871559143066406 \n",
            "Train loss at 2889 iteration is 3.1188244819641113 \n",
            "Train loss at 2890 iteration is 2.9503555297851562 \n",
            "Train loss at 2891 iteration is 3.001682758331299 \n",
            "Train loss at 2892 iteration is 2.991433620452881 \n",
            "Train loss at 2893 iteration is 2.9015932083129883 \n",
            "Train loss at 2894 iteration is 2.9211363792419434 \n",
            "Train loss at 2895 iteration is 2.808288812637329 \n",
            "Train loss at 2896 iteration is 2.9512879848480225 \n",
            "Train loss at 2897 iteration is 3.020077705383301 \n",
            "Train loss at 2898 iteration is 2.8358707427978516 \n",
            "Train loss at 2899 iteration is 2.8818957805633545 \n",
            "Train loss at 2900 iteration is 3.013580799102783 \n",
            "Train loss at 2901 iteration is 3.014967679977417 \n",
            "Train loss at 2902 iteration is 2.938400983810425 \n",
            "Train loss at 2903 iteration is 3.004775047302246 \n",
            "Train loss at 2904 iteration is 3.0195882320404053 \n",
            "Train loss at 2905 iteration is 2.9808526039123535 \n",
            "Train loss at 2906 iteration is 3.0017495155334473 \n",
            "Train loss at 2907 iteration is 2.9989466667175293 \n",
            "Train loss at 2908 iteration is 3.0345396995544434 \n",
            "Train loss at 2909 iteration is 2.794407367706299 \n",
            "Train loss at 2910 iteration is 2.8992083072662354 \n",
            "Train loss at 2911 iteration is 2.9282596111297607 \n",
            "Train loss at 2912 iteration is 3.040928363800049 \n",
            "Train loss at 2913 iteration is 3.010037899017334 \n",
            "Train loss at 2914 iteration is 3.143242120742798 \n",
            "Train loss at 2915 iteration is 3.0536484718322754 \n",
            "Train loss at 2916 iteration is 3.053008794784546 \n",
            "Train loss at 2917 iteration is 3.0619730949401855 \n",
            "Train loss at 2918 iteration is 3.1859543323516846 \n",
            "Train loss at 2919 iteration is 2.8901681900024414 \n",
            "Train loss at 2920 iteration is 2.876215696334839 \n",
            "Train loss at 2921 iteration is 2.826563835144043 \n",
            "Train loss at 2922 iteration is 3.0063507556915283 \n",
            "Train loss at 2923 iteration is 2.9514002799987793 \n",
            "Train loss at 2924 iteration is 2.919236898422241 \n",
            "Train loss at 2925 iteration is 2.972419500350952 \n",
            "Train loss at 2926 iteration is 3.0850887298583984 \n",
            "Train loss at 2927 iteration is 2.88804030418396 \n",
            "Train loss at 2928 iteration is 2.8940024375915527 \n",
            "Train loss at 2929 iteration is 2.9855458736419678 \n",
            "Train loss at 2930 iteration is 3.1267707347869873 \n",
            "Train loss at 2931 iteration is 2.8731069564819336 \n",
            "Train loss at 2932 iteration is 3.0151453018188477 \n",
            "Train loss at 2933 iteration is 3.1328039169311523 \n",
            "Train loss at 2934 iteration is 3.0214312076568604 \n",
            "Train loss at 2935 iteration is 2.943953275680542 \n",
            "Train loss at 2936 iteration is 3.0555529594421387 \n",
            "Train loss at 2937 iteration is 3.158510684967041 \n",
            "Train loss at 2938 iteration is 3.134507656097412 \n",
            "Train loss at 2939 iteration is 2.906716823577881 \n",
            "Train loss at 2940 iteration is 2.971406936645508 \n",
            "Train loss at 2941 iteration is 2.985870122909546 \n",
            "Train loss at 2942 iteration is 2.921389102935791 \n",
            "Train loss at 2943 iteration is 2.9341232776641846 \n",
            "Train loss at 2944 iteration is 2.9675307273864746 \n",
            "Train loss at 2945 iteration is 2.794677257537842 \n",
            "Train loss at 2946 iteration is 2.9716637134552 \n",
            "Train loss at 2947 iteration is 2.9101781845092773 \n",
            "Train loss at 2948 iteration is 3.0340664386749268 \n",
            "Train loss at 2949 iteration is 2.9892168045043945 \n",
            "Train loss at 2950 iteration is 3.1268138885498047 \n",
            "Train loss at 2951 iteration is 3.1383864879608154 \n",
            "Train loss at 2952 iteration is 3.0371668338775635 \n",
            "Train loss at 2953 iteration is 2.917776346206665 \n",
            "Train loss at 2954 iteration is 3.0602715015411377 \n",
            "Train loss at 2955 iteration is 3.0165531635284424 \n",
            "Train loss at 2956 iteration is 3.012528896331787 \n",
            "Train loss at 2957 iteration is 2.9612114429473877 \n",
            "Train loss at 2958 iteration is 3.1766207218170166 \n",
            "Train loss at 2959 iteration is 3.1909852027893066 \n",
            "Train loss at 2960 iteration is 3.0208120346069336 \n",
            "Train loss at 2961 iteration is 3.054241180419922 \n",
            "Train loss at 2962 iteration is 2.938406467437744 \n",
            "Train loss at 2963 iteration is 3.198740243911743 \n",
            "Train loss at 2964 iteration is 2.993657112121582 \n",
            "Train loss at 2965 iteration is 2.8224308490753174 \n",
            "Train loss at 2966 iteration is 2.851947069168091 \n",
            "Train loss at 2967 iteration is 3.149610757827759 \n",
            "Train loss at 2968 iteration is 2.9972846508026123 \n",
            "Train loss at 2969 iteration is 3.004939556121826 \n",
            "Train loss at 2970 iteration is 2.78991436958313 \n",
            "Train loss at 2971 iteration is 3.055464506149292 \n",
            "Train loss at 2972 iteration is 2.999168872833252 \n",
            "Train loss at 2973 iteration is 2.892817258834839 \n",
            "Train loss at 2974 iteration is 2.8364908695220947 \n",
            "Train loss at 2975 iteration is 2.94883131980896 \n",
            "Train loss at 2976 iteration is 3.0853142738342285 \n",
            "Train loss at 2977 iteration is 2.9334845542907715 \n",
            "Train loss at 2978 iteration is 2.911909818649292 \n",
            "Train loss at 2979 iteration is 2.9613847732543945 \n",
            "Train loss at 2980 iteration is 2.83305287361145 \n",
            "Train loss at 2981 iteration is 2.9491286277770996 \n",
            "Train loss at 2982 iteration is 2.786406993865967 \n",
            "Train loss at 2983 iteration is 3.031156539916992 \n",
            "Train loss at 2984 iteration is 3.0063438415527344 \n",
            "Train loss at 2985 iteration is 2.861812114715576 \n",
            "Train loss at 2986 iteration is 3.125790596008301 \n",
            "Train loss at 2987 iteration is 3.2366530895233154 \n",
            "Train loss at 2988 iteration is 2.906613826751709 \n",
            "Train loss at 2989 iteration is 2.8606340885162354 \n",
            "Train loss at 2990 iteration is 3.0082082748413086 \n",
            "Train loss at 2991 iteration is 2.8535284996032715 \n",
            "Train loss at 2992 iteration is 2.989577293395996 \n",
            "Train loss at 2993 iteration is 3.028702974319458 \n",
            "Train loss at 2994 iteration is 2.8417582511901855 \n",
            "Train loss at 2995 iteration is 2.9473023414611816 \n",
            "Train loss at 2996 iteration is 2.8154940605163574 \n",
            "Train loss at 2997 iteration is 2.9790523052215576 \n",
            "Train loss at 2998 iteration is 2.7601284980773926 \n",
            "Train loss at 2999 iteration is 3.104755401611328 \n",
            "Train loss at 3000 iteration is 2.9896678924560547 \n",
            "Train loss at 3001 iteration is 3.00628924369812 \n",
            "Train loss at 3002 iteration is 2.8055927753448486 \n",
            "Train loss at 3003 iteration is 2.856745481491089 \n",
            "Train loss at 3004 iteration is 3.1028456687927246 \n",
            "Train loss at 3005 iteration is 3.148940086364746 \n",
            "Train loss at 3006 iteration is 3.0425097942352295 \n",
            "Train loss at 3007 iteration is 2.924851655960083 \n",
            "Train loss at 3008 iteration is 2.8776443004608154 \n",
            "Train loss at 3009 iteration is 3.149266242980957 \n",
            "Train loss at 3010 iteration is 3.019810676574707 \n",
            "Train loss at 3011 iteration is 3.0235273838043213 \n",
            "Train loss at 3012 iteration is 2.9619438648223877 \n",
            "Train loss at 3013 iteration is 3.031355381011963 \n",
            "Train loss at 3014 iteration is 3.072448968887329 \n",
            "Train loss at 3015 iteration is 2.997664451599121 \n",
            "Train loss at 3016 iteration is 3.0077250003814697 \n",
            "Train loss at 3017 iteration is 3.0672638416290283 \n",
            "Train loss at 3018 iteration is 3.0056419372558594 \n",
            "Train loss at 3019 iteration is 3.207174301147461 \n",
            "Train loss at 3020 iteration is 3.017531394958496 \n",
            "Train loss at 3021 iteration is 3.1192116737365723 \n",
            "Train loss at 3022 iteration is 3.04284405708313 \n",
            "Train loss at 3023 iteration is 3.0706827640533447 \n",
            "Train loss at 3024 iteration is 2.925968885421753 \n",
            "Train loss at 3025 iteration is 2.8254075050354004 \n",
            "Train loss at 3026 iteration is 3.085374593734741 \n",
            "Train loss at 3027 iteration is 2.988457441329956 \n",
            "Train loss at 3028 iteration is 3.018500804901123 \n",
            "Train loss at 3029 iteration is 2.8707387447357178 \n",
            "Train loss at 3030 iteration is 3.1209475994110107 \n",
            "Train loss at 3031 iteration is 2.8440539836883545 \n",
            "Train loss at 3032 iteration is 2.986335277557373 \n",
            "Train loss at 3033 iteration is 3.0030665397644043 \n",
            "Train loss at 3034 iteration is 3.1182637214660645 \n",
            "Train loss at 3035 iteration is 3.016602039337158 \n",
            "Train loss at 3036 iteration is 3.217041015625 \n",
            "Train loss at 3037 iteration is 2.9174253940582275 \n",
            "Train loss at 3038 iteration is 2.9677724838256836 \n",
            "Train loss at 3039 iteration is 3.109609603881836 \n",
            "Train loss at 3040 iteration is 3.187462329864502 \n",
            "Train loss at 3041 iteration is 3.0482399463653564 \n",
            "Train loss at 3042 iteration is 3.042295217514038 \n",
            "Train loss at 3043 iteration is 2.9357986450195312 \n",
            "Train loss at 3044 iteration is 3.0182037353515625 \n",
            "Train loss at 3045 iteration is 2.9748871326446533 \n",
            "Train loss at 3046 iteration is 2.9212138652801514 \n",
            "Train loss at 3047 iteration is 3.120445966720581 \n",
            "Train loss at 3048 iteration is 3.043363094329834 \n",
            "Train loss at 3049 iteration is 2.988532781600952 \n",
            "Train loss at 3050 iteration is 2.9610908031463623 \n",
            "Train loss at 3051 iteration is 3.147339105606079 \n",
            "Train loss at 3052 iteration is 2.8323230743408203 \n",
            "Train loss at 3053 iteration is 3.051298141479492 \n",
            "Train loss at 3054 iteration is 3.265597343444824 \n",
            "Train loss at 3055 iteration is 2.961557149887085 \n",
            "Train loss at 3056 iteration is 2.969921827316284 \n",
            "Train loss at 3057 iteration is 3.2217094898223877 \n",
            "Train loss at 3058 iteration is 3.1188299655914307 \n",
            "Train loss at 3059 iteration is 3.028639793395996 \n",
            "Train loss at 3060 iteration is 2.951183557510376 \n",
            "Train loss at 3061 iteration is 2.8138506412506104 \n",
            "Train loss at 3062 iteration is 2.8874990940093994 \n",
            "Train loss at 3063 iteration is 3.0032386779785156 \n",
            "Train loss at 3064 iteration is 3.03837513923645 \n",
            "Train loss at 3065 iteration is 3.062541961669922 \n",
            "Train loss at 3066 iteration is 2.8750133514404297 \n",
            "Train loss at 3067 iteration is 2.992894411087036 \n",
            "Train loss at 3068 iteration is 2.933032989501953 \n",
            "Train loss at 3069 iteration is 2.932649612426758 \n",
            "Train loss at 3070 iteration is 2.988309621810913 \n",
            "Train loss at 3071 iteration is 2.9734203815460205 \n",
            "Train loss at 3072 iteration is 3.0298123359680176 \n",
            "Train loss at 3073 iteration is 2.8213908672332764 \n",
            "Train loss at 3074 iteration is 3.0708987712860107 \n",
            "Train loss at 3075 iteration is 2.8018884658813477 \n",
            "Train loss at 3076 iteration is 3.051987886428833 \n",
            "Train loss at 3077 iteration is 2.991297960281372 \n",
            "Train loss at 3078 iteration is 2.9559972286224365 \n",
            "Train loss at 3079 iteration is 2.952871322631836 \n",
            "Train loss at 3080 iteration is 3.1702165603637695 \n",
            "Train loss at 3081 iteration is 3.0060367584228516 \n",
            "Train loss at 3082 iteration is 2.862100124359131 \n",
            "Train loss at 3083 iteration is 3.021078109741211 \n",
            "Train loss at 3084 iteration is 2.9810431003570557 \n",
            "Train loss at 3085 iteration is 3.05635142326355 \n",
            "Train loss at 3086 iteration is 3.140101432800293 \n",
            "Train loss at 3087 iteration is 2.9377353191375732 \n",
            "Train loss at 3088 iteration is 2.99507737159729 \n",
            "Train loss at 3089 iteration is 3.0687105655670166 \n",
            "Train loss at 3090 iteration is 3.050795316696167 \n",
            "Train loss at 3091 iteration is 3.1501145362854004 \n",
            "Train loss at 3092 iteration is 2.9211127758026123 \n",
            "Train loss at 3093 iteration is 3.059216260910034 \n",
            "Train loss at 3094 iteration is 3.0474417209625244 \n",
            "Train loss at 3095 iteration is 3.115330934524536 \n",
            "Train loss at 3096 iteration is 3.2204954624176025 \n",
            "Train loss at 3097 iteration is 3.1153132915496826 \n",
            "Train loss at 3098 iteration is 2.973661422729492 \n",
            "Train loss at 3099 iteration is 2.9376907348632812 \n",
            "Train loss at 3100 iteration is 3.1601290702819824 \n",
            "Train loss at 3101 iteration is 3.151998281478882 \n",
            "Train loss at 3102 iteration is 3.2736291885375977 \n",
            "Train loss at 3103 iteration is 3.107419013977051 \n",
            "Train loss at 3104 iteration is 3.113341808319092 \n",
            "Train loss at 3105 iteration is 2.8644630908966064 \n",
            "Train loss at 3106 iteration is 3.062803030014038 \n",
            "Train loss at 3107 iteration is 3.1218011379241943 \n",
            "Train loss at 3108 iteration is 3.016141414642334 \n",
            "Train loss at 3109 iteration is 3.0293147563934326 \n",
            "Train loss at 3110 iteration is 3.045982837677002 \n",
            "Train loss at 3111 iteration is 3.0298988819122314 \n",
            "Train loss at 3112 iteration is 2.8732426166534424 \n",
            "Train loss at 3113 iteration is 3.054259777069092 \n",
            "Train loss at 3114 iteration is 2.8073832988739014 \n",
            "Train loss at 3115 iteration is 3.075343370437622 \n",
            "Train loss at 3116 iteration is 3.0929312705993652 \n",
            "Train loss at 3117 iteration is 2.88041090965271 \n",
            "Train loss at 3118 iteration is 3.109194278717041 \n",
            "Train loss at 3119 iteration is 3.0979597568511963 \n",
            "Train loss at 3120 iteration is 2.876311779022217 \n",
            "Train loss at 3121 iteration is 3.0753822326660156 \n",
            "Train loss at 3122 iteration is 3.1143064498901367 \n",
            "Train loss at 3123 iteration is 3.099226236343384 \n",
            "Train loss at 3124 iteration is 3.03068208694458 \n",
            "Train loss at 3125 iteration is 3.086617946624756 \n",
            "Train loss at 3126 iteration is 3.1342365741729736 \n",
            "Train loss at 3127 iteration is 2.92740535736084 \n",
            "Train loss at 3128 iteration is 3.0864789485931396 \n",
            "Train loss at 3129 iteration is 3.040245532989502 \n",
            "Train loss at 3130 iteration is 3.078913927078247 \n",
            "Train loss at 3131 iteration is 3.1656925678253174 \n",
            "Train loss at 3132 iteration is 2.9350616931915283 \n",
            "Train loss at 3133 iteration is 2.81260347366333 \n",
            "Train loss at 3134 iteration is 2.982245683670044 \n",
            "Train loss at 3135 iteration is 3.0722410678863525 \n",
            "Train loss at 3136 iteration is 3.1342294216156006 \n",
            "Train loss at 3137 iteration is 2.9723849296569824 \n",
            "Train loss at 3138 iteration is 3.1151974201202393 \n",
            "Train loss at 3139 iteration is 3.001278877258301 \n",
            "Train loss at 3140 iteration is 2.986877202987671 \n",
            "Train loss at 3141 iteration is 2.9861674308776855 \n",
            "Train loss at 3142 iteration is 3.02404522895813 \n",
            "Train loss at 3143 iteration is 3.039168357849121 \n",
            "Train loss at 3144 iteration is 2.9941506385803223 \n",
            "Train loss at 3145 iteration is 3.021446704864502 \n",
            "Train loss at 3146 iteration is 2.9442286491394043 \n",
            "Train loss at 3147 iteration is 3.118699312210083 \n",
            "Train loss at 3148 iteration is 3.0818605422973633 \n",
            "Train loss at 3149 iteration is 2.9876046180725098 \n",
            "Train loss at 3150 iteration is 2.9426448345184326 \n",
            "Train loss at 3151 iteration is 2.865642786026001 \n",
            "Train loss at 3152 iteration is 3.0525615215301514 \n",
            "Train loss at 3153 iteration is 3.1506218910217285 \n",
            "Train loss at 3154 iteration is 2.9694252014160156 \n",
            "Train loss at 3155 iteration is 3.1308488845825195 \n",
            "Train loss at 3156 iteration is 2.8388946056365967 \n",
            "Train loss at 3157 iteration is 3.084984302520752 \n",
            "Train loss at 3158 iteration is 3.0829646587371826 \n",
            "Train loss at 3159 iteration is 3.2489371299743652 \n",
            "Train loss at 3160 iteration is 3.0485565662384033 \n",
            "Train loss at 3161 iteration is 3.2373290061950684 \n",
            "Train loss at 3162 iteration is 3.146967649459839 \n",
            "Train loss at 3163 iteration is 3.1141514778137207 \n",
            "Train loss at 3164 iteration is 2.997166872024536 \n",
            "Train loss at 3165 iteration is 3.086455821990967 \n",
            "Train loss at 3166 iteration is 3.088409900665283 \n",
            "Train loss at 3167 iteration is 2.795147657394409 \n",
            "Train loss at 3168 iteration is 3.102093458175659 \n",
            "Train loss at 3169 iteration is 3.115884780883789 \n",
            "Train loss at 3170 iteration is 3.1452903747558594 \n",
            "Train loss at 3171 iteration is 3.060807943344116 \n",
            "Train loss at 3172 iteration is 3.251070976257324 \n",
            "Train loss at 3173 iteration is 2.934703826904297 \n",
            "Train loss at 3174 iteration is 2.933518886566162 \n",
            "Train loss at 3175 iteration is 2.9799141883850098 \n",
            "Train loss at 3176 iteration is 3.0185317993164062 \n",
            "Train loss at 3177 iteration is 3.0797276496887207 \n",
            "Train loss at 3178 iteration is 3.0891852378845215 \n",
            "Train loss at 3179 iteration is 3.1034998893737793 \n",
            "Train loss at 3180 iteration is 2.963989019393921 \n",
            "Train loss at 3181 iteration is 3.0790302753448486 \n",
            "Train loss at 3182 iteration is 3.1413533687591553 \n",
            "Train loss at 3183 iteration is 3.179079294204712 \n",
            "Train loss at 3184 iteration is 2.963376998901367 \n",
            "Train loss at 3185 iteration is 3.069016695022583 \n",
            "Train loss at 3186 iteration is 3.1491332054138184 \n",
            "Train loss at 3187 iteration is 2.9750754833221436 \n",
            "Train loss at 3188 iteration is 3.0298571586608887 \n",
            "Train loss at 3189 iteration is 3.1245903968811035 \n",
            "Train loss at 3190 iteration is 3.166588068008423 \n",
            "Train loss at 3191 iteration is 2.946638345718384 \n",
            "Train loss at 3192 iteration is 2.924086570739746 \n",
            "Train loss at 3193 iteration is 2.9325168132781982 \n",
            "Train loss at 3194 iteration is 2.8802576065063477 \n",
            "Train loss at 3195 iteration is 3.1207940578460693 \n",
            "Train loss at 3196 iteration is 3.027944803237915 \n",
            "Train loss at 3197 iteration is 3.2313764095306396 \n",
            "Train loss at 3198 iteration is 2.9291436672210693 \n",
            "Train loss at 3199 iteration is 3.091214656829834 \n",
            "Train loss at 3200 iteration is 3.059691905975342 \n",
            "Train loss at 3201 iteration is 3.1466286182403564 \n",
            "Train loss at 3202 iteration is 3.095782518386841 \n",
            "Train loss at 3203 iteration is 2.8839828968048096 \n",
            "Train loss at 3204 iteration is 3.2003061771392822 \n",
            "Train loss at 3205 iteration is 3.070685625076294 \n",
            "Train loss at 3206 iteration is 3.0925819873809814 \n",
            "Train loss at 3207 iteration is 3.0429975986480713 \n",
            "Train loss at 3208 iteration is 3.0489773750305176 \n",
            "Train loss at 3209 iteration is 3.130401134490967 \n",
            "Train loss at 3210 iteration is 3.0910892486572266 \n",
            "Train loss at 3211 iteration is 2.9199492931365967 \n",
            "Train loss at 3212 iteration is 2.8843066692352295 \n",
            "Train loss at 3213 iteration is 3.081319808959961 \n",
            "Train loss at 3214 iteration is 3.057419538497925 \n",
            "Train loss at 3215 iteration is 3.049513578414917 \n",
            "Train loss at 3216 iteration is 3.0879223346710205 \n",
            "Train loss at 3217 iteration is 2.940343141555786 \n",
            "Train loss at 3218 iteration is 2.9301884174346924 \n",
            "Train loss at 3219 iteration is 3.1462182998657227 \n",
            "Train loss at 3220 iteration is 2.9589345455169678 \n",
            "Train loss at 3221 iteration is 3.1118812561035156 \n",
            "Train loss at 3222 iteration is 3.036680221557617 \n",
            "Train loss at 3223 iteration is 3.0047755241394043 \n",
            "Train loss at 3224 iteration is 2.927473306655884 \n",
            "Train loss at 3225 iteration is 2.983753204345703 \n",
            "Train loss at 3226 iteration is 3.147627830505371 \n",
            "Train loss at 3227 iteration is 3.008000373840332 \n",
            "Train loss at 3228 iteration is 3.071220874786377 \n",
            "Train loss at 3229 iteration is 3.1599674224853516 \n",
            "Train loss at 3230 iteration is 2.9800233840942383 \n",
            "Train loss at 3231 iteration is 3.1074259281158447 \n",
            "Train loss at 3232 iteration is 3.110692024230957 \n",
            "Train loss at 3233 iteration is 2.9293553829193115 \n",
            "Train loss at 3234 iteration is 3.085357904434204 \n",
            "Train loss at 3235 iteration is 3.123134136199951 \n",
            "Train loss at 3236 iteration is 2.686868906021118 \n",
            "Train loss at 3237 iteration is 3.140157461166382 \n",
            "Train loss at 3238 iteration is 2.9269165992736816 \n",
            "Train loss at 3239 iteration is 3.096212148666382 \n",
            "Train loss at 3240 iteration is 2.8301937580108643 \n",
            "Train loss at 3241 iteration is 3.0799317359924316 \n",
            "Train loss at 3242 iteration is 3.1021370887756348 \n",
            "Train loss at 3243 iteration is 2.9657981395721436 \n",
            "Train loss at 3244 iteration is 3.126176118850708 \n",
            "Train loss at 3245 iteration is 3.152317523956299 \n",
            "Train loss at 3246 iteration is 2.8416152000427246 \n",
            "Train loss at 3247 iteration is 2.9697654247283936 \n",
            "Train loss at 3248 iteration is 2.93196702003479 \n",
            "Train loss at 3249 iteration is 2.9557974338531494 \n",
            "Train loss at 3250 iteration is 3.1571333408355713 \n",
            "Train loss at 3251 iteration is 3.0716397762298584 \n",
            "Train loss at 3252 iteration is 3.1129069328308105 \n",
            "Train loss at 3253 iteration is 2.9335014820098877 \n",
            "Train loss at 3254 iteration is 3.0889580249786377 \n",
            "Train loss at 3255 iteration is 3.129183292388916 \n",
            "Train loss at 3256 iteration is 2.8780903816223145 \n",
            "Train loss at 3257 iteration is 2.9941282272338867 \n",
            "Train loss at 3258 iteration is 3.057478666305542 \n",
            "Train loss at 3259 iteration is 3.002493381500244 \n",
            "Train loss at 3260 iteration is 2.9488298892974854 \n",
            "Train loss at 3261 iteration is 3.036370277404785 \n",
            "Train loss at 3262 iteration is 2.9497921466827393 \n",
            "Train loss at 3263 iteration is 2.8382389545440674 \n",
            "Train loss at 3264 iteration is 3.194169759750366 \n",
            "Train loss at 3265 iteration is 3.020029067993164 \n",
            "Train loss at 3266 iteration is 3.0388941764831543 \n",
            "Train loss at 3267 iteration is 3.088407039642334 \n",
            "Train loss at 3268 iteration is 2.9450674057006836 \n",
            "Train loss at 3269 iteration is 3.0224201679229736 \n",
            "Train loss at 3270 iteration is 3.0186829566955566 \n",
            "Train loss at 3271 iteration is 3.038222312927246 \n",
            "Train loss at 3272 iteration is 3.0242416858673096 \n",
            "Train loss at 3273 iteration is 3.096698045730591 \n",
            "Train loss at 3274 iteration is 3.082467794418335 \n",
            "Train loss at 3275 iteration is 3.054279088973999 \n",
            "Train loss at 3276 iteration is 3.213902473449707 \n",
            "Train loss at 3277 iteration is 3.1309256553649902 \n",
            "Train loss at 3278 iteration is 3.2004153728485107 \n",
            "Train loss at 3279 iteration is 3.17154860496521 \n",
            "Train loss at 3280 iteration is 3.0266096591949463 \n",
            "Train loss at 3281 iteration is 3.2299981117248535 \n",
            "Train loss at 3282 iteration is 2.9683897495269775 \n",
            "Train loss at 3283 iteration is 2.8343629837036133 \n",
            "Train loss at 3284 iteration is 3.186621904373169 \n",
            "Train loss at 3285 iteration is 3.1729538440704346 \n",
            "Train loss at 3286 iteration is 3.057213068008423 \n",
            "Train loss at 3287 iteration is 2.9506242275238037 \n",
            "Train loss at 3288 iteration is 3.1162023544311523 \n",
            "Train loss at 3289 iteration is 2.9895033836364746 \n",
            "Train loss at 3290 iteration is 3.067898750305176 \n",
            "Train loss at 3291 iteration is 3.0679171085357666 \n",
            "Train loss at 3292 iteration is 3.066948652267456 \n",
            "Train loss at 3293 iteration is 3.0147109031677246 \n",
            "Train loss at 3294 iteration is 3.1577277183532715 \n",
            "Train loss at 3295 iteration is 3.040769338607788 \n",
            "Train loss at 3296 iteration is 3.088758945465088 \n",
            "Train loss at 3297 iteration is 3.0165562629699707 \n",
            "Train loss at 3298 iteration is 3.079218864440918 \n",
            "Train loss at 3299 iteration is 2.964040994644165 \n",
            "Train loss at 3300 iteration is 2.943787097930908 \n",
            "Train loss at 3301 iteration is 3.1052281856536865 \n",
            "Train loss at 3302 iteration is 3.2078170776367188 \n",
            "Train loss at 3303 iteration is 2.7803258895874023 \n",
            "Train loss at 3304 iteration is 3.158132314682007 \n",
            "Train loss at 3305 iteration is 3.0480527877807617 \n",
            "Train loss at 3306 iteration is 3.256979465484619 \n",
            "Train loss at 3307 iteration is 2.778191089630127 \n",
            "Train loss at 3308 iteration is 2.91330623626709 \n",
            "Train loss at 3309 iteration is 3.1183412075042725 \n",
            "Train loss at 3310 iteration is 3.1306800842285156 \n",
            "Train loss at 3311 iteration is 3.1368134021759033 \n",
            "Train loss at 3312 iteration is 2.9892892837524414 \n",
            "Train loss at 3313 iteration is 2.9725470542907715 \n",
            "Train loss at 3314 iteration is 2.959589958190918 \n",
            "Train loss at 3315 iteration is 3.095742702484131 \n",
            "Train loss at 3316 iteration is 2.984898090362549 \n",
            "Train loss at 3317 iteration is 3.0649869441986084 \n",
            "Train loss at 3318 iteration is 3.0510566234588623 \n",
            "Train loss at 3319 iteration is 2.962585210800171 \n",
            "Train loss at 3320 iteration is 3.0207290649414062 \n",
            "Train loss at 3321 iteration is 2.90968656539917 \n",
            "Train loss at 3322 iteration is 3.0177531242370605 \n",
            "Train loss at 3323 iteration is 3.1890175342559814 \n",
            "Train loss at 3324 iteration is 2.919565439224243 \n",
            "Train loss at 3325 iteration is 3.0434882640838623 \n",
            "Train loss at 3326 iteration is 3.2326340675354004 \n",
            "Train loss at 3327 iteration is 3.218441963195801 \n",
            "Train loss at 3328 iteration is 2.9793858528137207 \n",
            "Train loss at 3329 iteration is 2.7809336185455322 \n",
            "Train loss at 3330 iteration is 2.9791271686553955 \n",
            "Train loss at 3331 iteration is 3.034618854522705 \n",
            "Train loss at 3332 iteration is 3.018126964569092 \n",
            "Train loss at 3333 iteration is 3.095329523086548 \n",
            "Train loss at 3334 iteration is 3.1806886196136475 \n",
            "Train loss at 3335 iteration is 3.0796995162963867 \n",
            "Train loss at 3336 iteration is 3.052100896835327 \n",
            "Train loss at 3337 iteration is 3.002129077911377 \n",
            "Train loss at 3338 iteration is 3.2285561561584473 \n",
            "Train loss at 3339 iteration is 3.057955741882324 \n",
            "Train loss at 3340 iteration is 3.0577569007873535 \n",
            "Train loss at 3341 iteration is 3.0702359676361084 \n",
            "Train loss at 3342 iteration is 3.104562520980835 \n",
            "Train loss at 3343 iteration is 2.972477674484253 \n",
            "Train loss at 3344 iteration is 3.2718164920806885 \n",
            "Train loss at 3345 iteration is 3.0740578174591064 \n",
            "Train loss at 3346 iteration is 2.9346232414245605 \n",
            "Train loss at 3347 iteration is 3.0127062797546387 \n",
            "Train loss at 3348 iteration is 2.9529407024383545 \n",
            "Train loss at 3349 iteration is 3.1074955463409424 \n",
            "Train loss at 3350 iteration is 3.1647467613220215 \n",
            "Train loss at 3351 iteration is 3.0303544998168945 \n",
            "Train loss at 3352 iteration is 3.112968921661377 \n",
            "Train loss at 3353 iteration is 3.2313666343688965 \n",
            "Train loss at 3354 iteration is 3.1775941848754883 \n",
            "Train loss at 3355 iteration is 3.1120121479034424 \n",
            "Train loss at 3356 iteration is 3.0708811283111572 \n",
            "Train loss at 3357 iteration is 3.0858242511749268 \n",
            "Train loss at 3358 iteration is 3.102219820022583 \n",
            "Train loss at 3359 iteration is 3.0880625247955322 \n",
            "Train loss at 3360 iteration is 3.046827554702759 \n",
            "Train loss at 3361 iteration is 2.994267225265503 \n",
            "Train loss at 3362 iteration is 3.3229641914367676 \n",
            "Train loss at 3363 iteration is 3.0765979290008545 \n",
            "Train loss at 3364 iteration is 3.186460018157959 \n",
            "Train loss at 3365 iteration is 3.1926095485687256 \n",
            "Train loss at 3366 iteration is 2.945265054702759 \n",
            "Train loss at 3367 iteration is 2.940340042114258 \n",
            "Train loss at 3368 iteration is 3.21852970123291 \n",
            "Train loss at 3369 iteration is 3.166722536087036 \n",
            "Train loss at 3370 iteration is 3.11419415473938 \n",
            "Train loss at 3371 iteration is 3.1216535568237305 \n",
            "Train loss at 3372 iteration is 3.0211522579193115 \n",
            "Train loss at 3373 iteration is 3.323960304260254 \n",
            "Train loss at 3374 iteration is 2.93660306930542 \n",
            "Train loss at 3375 iteration is 3.1915016174316406 \n",
            "Train loss at 3376 iteration is 3.1966850757598877 \n",
            "Train loss at 3377 iteration is 3.094794511795044 \n",
            "Train loss at 3378 iteration is 2.974393129348755 \n",
            "Train loss at 3379 iteration is 3.047208070755005 \n",
            "Train loss at 3380 iteration is 2.9468159675598145 \n",
            "Train loss at 3381 iteration is 2.8922479152679443 \n",
            "Train loss at 3382 iteration is 3.262960910797119 \n",
            "Train loss at 3383 iteration is 3.0123977661132812 \n",
            "Train loss at 3384 iteration is 3.1022794246673584 \n",
            "Train loss at 3385 iteration is 3.0782337188720703 \n",
            "Train loss at 3386 iteration is 3.029789686203003 \n",
            "Train loss at 3387 iteration is 2.947401523590088 \n",
            "Train loss at 3388 iteration is 3.246958017349243 \n",
            "Train loss at 3389 iteration is 3.157762050628662 \n",
            "Train loss at 3390 iteration is 3.19136643409729 \n",
            "Train loss at 3391 iteration is 3.1915271282196045 \n",
            "Train loss at 3392 iteration is 2.94048810005188 \n",
            "Train loss at 3393 iteration is 3.074740171432495 \n",
            "Train loss at 3394 iteration is 3.0575919151306152 \n",
            "Train loss at 3395 iteration is 2.9641685485839844 \n",
            "Train loss at 3396 iteration is 2.937040328979492 \n",
            "Train loss at 3397 iteration is 3.296544313430786 \n",
            "Train loss at 3398 iteration is 3.027496099472046 \n",
            "Train loss at 3399 iteration is 3.052483558654785 \n",
            "Train loss at 3400 iteration is 3.1279172897338867 \n",
            "Train loss at 3401 iteration is 2.8378069400787354 \n",
            "Train loss at 3402 iteration is 3.1641244888305664 \n",
            "Train loss at 3403 iteration is 2.887791872024536 \n",
            "Train loss at 3404 iteration is 2.9510581493377686 \n",
            "Train loss at 3405 iteration is 3.057633638381958 \n",
            "Train loss at 3406 iteration is 2.862699270248413 \n",
            "Train loss at 3407 iteration is 3.155144453048706 \n",
            "Train loss at 3408 iteration is 3.1319005489349365 \n",
            "Train loss at 3409 iteration is 3.065486192703247 \n",
            "Train loss at 3410 iteration is 3.1237447261810303 \n",
            "Train loss at 3411 iteration is 3.2650837898254395 \n",
            "Train loss at 3412 iteration is 3.0164783000946045 \n",
            "Train loss at 3413 iteration is 3.1077303886413574 \n",
            "Train loss at 3414 iteration is 3.0734293460845947 \n",
            "Train loss at 3415 iteration is 3.123218059539795 \n",
            "Train loss at 3416 iteration is 3.225539207458496 \n",
            "Train loss at 3417 iteration is 3.0215187072753906 \n",
            "Train loss at 3418 iteration is 3.186711072921753 \n",
            "Train loss at 3419 iteration is 2.9268693923950195 \n",
            "Train loss at 3420 iteration is 3.1370882987976074 \n",
            "Train loss at 3421 iteration is 3.0092194080352783 \n",
            "Train loss at 3422 iteration is 2.762463092803955 \n",
            "Train loss at 3423 iteration is 3.273036003112793 \n",
            "Train loss at 3424 iteration is 3.0043344497680664 \n",
            "Train loss at 3425 iteration is 3.0992536544799805 \n",
            "Train loss at 3426 iteration is 3.0676486492156982 \n",
            "Train loss at 3427 iteration is 2.881356716156006 \n",
            "Train loss at 3428 iteration is 3.1112585067749023 \n",
            "Train loss at 3429 iteration is 3.0817301273345947 \n",
            "Train loss at 3430 iteration is 3.0744237899780273 \n",
            "Train loss at 3431 iteration is 3.0305840969085693 \n",
            "Train loss at 3432 iteration is 3.1488609313964844 \n",
            "Train loss at 3433 iteration is 2.925955057144165 \n",
            "Train loss at 3434 iteration is 3.074672222137451 \n",
            "Train loss at 3435 iteration is 3.1822924613952637 \n",
            "Train loss at 3436 iteration is 3.252790927886963 \n",
            "Train loss at 3437 iteration is 3.097308874130249 \n",
            "Train loss at 3438 iteration is 3.234513998031616 \n",
            "Train loss at 3439 iteration is 2.9196040630340576 \n",
            "Train loss at 3440 iteration is 3.024613618850708 \n",
            "Train loss at 3441 iteration is 3.1565723419189453 \n",
            "Train loss at 3442 iteration is 3.3309621810913086 \n",
            "Train loss at 3443 iteration is 2.9199860095977783 \n",
            "Train loss at 3444 iteration is 3.034813642501831 \n",
            "Train loss at 3445 iteration is 2.8640880584716797 \n",
            "Train loss at 3446 iteration is 3.1829946041107178 \n",
            "Train loss at 3447 iteration is 3.0157580375671387 \n",
            "Train loss at 3448 iteration is 3.000917911529541 \n",
            "Train loss at 3449 iteration is 3.059948205947876 \n",
            "Train loss at 3450 iteration is 3.115025520324707 \n",
            "Train loss at 3451 iteration is 3.1786715984344482 \n",
            "Train loss at 3452 iteration is 2.999382734298706 \n",
            "Train loss at 3453 iteration is 3.026395320892334 \n",
            "Train loss at 3454 iteration is 2.9238317012786865 \n",
            "Train loss at 3455 iteration is 3.161140203475952 \n",
            "Train loss at 3456 iteration is 3.105825901031494 \n",
            "Train loss at 3457 iteration is 2.9713690280914307 \n",
            "Train loss at 3458 iteration is 3.060878038406372 \n",
            "Train loss at 3459 iteration is 3.0854897499084473 \n",
            "Train loss at 3460 iteration is 3.189159393310547 \n",
            "Train loss at 3461 iteration is 3.1464240550994873 \n",
            "Train loss at 3462 iteration is 3.0761406421661377 \n",
            "Train loss at 3463 iteration is 3.0524044036865234 \n",
            "Train loss at 3464 iteration is 2.944256544113159 \n",
            "Train loss at 3465 iteration is 3.000807285308838 \n",
            "Train loss at 3466 iteration is 2.799008369445801 \n",
            "Train loss at 3467 iteration is 3.164217948913574 \n",
            "Train loss at 3468 iteration is 2.9455792903900146 \n",
            "Train loss at 3469 iteration is 3.045595407485962 \n",
            "Train loss at 3470 iteration is 3.3011293411254883 \n",
            "Train loss at 3471 iteration is 3.166558265686035 \n",
            "Train loss at 3472 iteration is 3.233959913253784 \n",
            "Train loss at 3473 iteration is 2.9037933349609375 \n",
            "Train loss at 3474 iteration is 2.958258867263794 \n",
            "Train loss at 3475 iteration is 3.1088175773620605 \n",
            "Train loss at 3476 iteration is 3.4483330249786377 \n",
            "Train loss at 3477 iteration is 3.2511701583862305 \n",
            "Train loss at 3478 iteration is 3.0401763916015625 \n",
            "Train loss at 3479 iteration is 2.8869807720184326 \n",
            "Train loss at 3480 iteration is 2.914262056350708 \n",
            "Train loss at 3481 iteration is 2.932035446166992 \n",
            "Train loss at 3482 iteration is 2.9467251300811768 \n",
            "Train loss at 3483 iteration is 3.03952956199646 \n",
            "Train loss at 3484 iteration is 2.921983480453491 \n",
            "Train loss at 3485 iteration is 2.985764741897583 \n",
            "Train loss at 3486 iteration is 3.166393756866455 \n",
            "Train loss at 3487 iteration is 3.1170356273651123 \n",
            "Train loss at 3488 iteration is 2.883671522140503 \n",
            "Train loss at 3489 iteration is 2.9321184158325195 \n",
            "Train loss at 3490 iteration is 2.9473109245300293 \n",
            "Train loss at 3491 iteration is 3.241804599761963 \n",
            "Train loss at 3492 iteration is 3.013286828994751 \n",
            "Train loss at 3493 iteration is 3.0770816802978516 \n",
            "Train loss at 3494 iteration is 3.0890090465545654 \n",
            "Train loss at 3495 iteration is 3.0304009914398193 \n",
            "Train loss at 3496 iteration is 3.1394801139831543 \n",
            "Train loss at 3497 iteration is 3.185330867767334 \n",
            "Train loss at 3498 iteration is 3.1303443908691406 \n",
            "Train loss at 3499 iteration is 2.9857609272003174 \n",
            "Train loss at 3500 iteration is 3.1029183864593506 \n",
            "Train loss at 3501 iteration is 2.9192700386047363 \n",
            "Train loss at 3502 iteration is 3.1059410572052 \n",
            "Train loss at 3503 iteration is 3.0799458026885986 \n",
            "Train loss at 3504 iteration is 3.1966490745544434 \n",
            "Train loss at 3505 iteration is 3.103175163269043 \n",
            "Train loss at 3506 iteration is 3.0717508792877197 \n",
            "Train loss at 3507 iteration is 3.122147798538208 \n",
            "Train loss at 3508 iteration is 3.147160291671753 \n",
            "Train loss at 3509 iteration is 3.0926513671875 \n",
            "Train loss at 3510 iteration is 3.1384153366088867 \n",
            "Train loss at 3511 iteration is 2.9630849361419678 \n",
            "Train loss at 3512 iteration is 3.099518060684204 \n",
            "Train loss at 3513 iteration is 3.075428009033203 \n",
            "Train loss at 3514 iteration is 3.0642943382263184 \n",
            "Train loss at 3515 iteration is 3.103250503540039 \n",
            "Train loss at 3516 iteration is 2.976599931716919 \n",
            "Train loss at 3517 iteration is 3.1041290760040283 \n",
            "Train loss at 3518 iteration is 3.069063425064087 \n",
            "Train loss at 3519 iteration is 3.1158580780029297 \n",
            "Train loss at 3520 iteration is 2.957430839538574 \n",
            "Train loss at 3521 iteration is 3.1145575046539307 \n",
            "Train loss at 3522 iteration is 2.9172306060791016 \n",
            "Train loss at 3523 iteration is 3.1997809410095215 \n",
            "Train loss at 3524 iteration is 3.0921640396118164 \n",
            "Train loss at 3525 iteration is 3.114028215408325 \n",
            "Train loss at 3526 iteration is 3.066122531890869 \n",
            "Train loss at 3527 iteration is 3.156018018722534 \n",
            "Train loss at 3528 iteration is 2.9293177127838135 \n",
            "Train loss at 3529 iteration is 3.125565767288208 \n",
            "Train loss at 3530 iteration is 3.1930103302001953 \n",
            "Train loss at 3531 iteration is 2.882502555847168 \n",
            "Train loss at 3532 iteration is 3.1009151935577393 \n",
            "Train loss at 3533 iteration is 3.104928970336914 \n",
            "Train loss at 3534 iteration is 3.126408815383911 \n",
            "Train loss at 3535 iteration is 3.0140037536621094 \n",
            "Train loss at 3536 iteration is 3.013015031814575 \n",
            "Train loss at 3537 iteration is 2.9611964225769043 \n",
            "Train loss at 3538 iteration is 3.052767753601074 \n",
            "Train loss at 3539 iteration is 3.0138118267059326 \n",
            "Train loss at 3540 iteration is 2.9177334308624268 \n",
            "Train loss at 3541 iteration is 3.222882032394409 \n",
            "Train loss at 3542 iteration is 3.083563804626465 \n",
            "Train loss at 3543 iteration is 2.9533939361572266 \n",
            "Train loss at 3544 iteration is 3.2968287467956543 \n",
            "Train loss at 3545 iteration is 3.09311580657959 \n",
            "Train loss at 3546 iteration is 3.2391433715820312 \n",
            "Train loss at 3547 iteration is 3.139639377593994 \n",
            "Train loss at 3548 iteration is 3.1195805072784424 \n",
            "Train loss at 3549 iteration is 2.9313385486602783 \n",
            "Train loss at 3550 iteration is 3.02420973777771 \n",
            "Train loss at 3551 iteration is 3.288543939590454 \n",
            "Train loss at 3552 iteration is 3.1018130779266357 \n",
            "Train loss at 3553 iteration is 3.1578800678253174 \n",
            "Train loss at 3554 iteration is 3.346658229827881 \n",
            "Train loss at 3555 iteration is 3.03308367729187 \n",
            "Train loss at 3556 iteration is 3.1226770877838135 \n",
            "Train loss at 3557 iteration is 3.098139524459839 \n",
            "Train loss at 3558 iteration is 3.052406072616577 \n",
            "Train loss at 3559 iteration is 2.9687376022338867 \n",
            "Train loss at 3560 iteration is 3.0355818271636963 \n",
            "Train loss at 3561 iteration is 3.2870912551879883 \n",
            "Train loss at 3562 iteration is 3.177104949951172 \n",
            "Train loss at 3563 iteration is 3.1816012859344482 \n",
            "Train loss at 3564 iteration is 2.9130313396453857 \n",
            "Train loss at 3565 iteration is 3.0170373916625977 \n",
            "Train loss at 3566 iteration is 3.0482375621795654 \n",
            "Train loss at 3567 iteration is 3.1735153198242188 \n",
            "Train loss at 3568 iteration is 3.0870087146759033 \n",
            "Train loss at 3569 iteration is 2.9765429496765137 \n",
            "Train loss at 3570 iteration is 2.818742036819458 \n",
            "Train loss at 3571 iteration is 3.162851333618164 \n",
            "Train loss at 3572 iteration is 3.0588645935058594 \n",
            "Train loss at 3573 iteration is 3.0922439098358154 \n",
            "Train loss at 3574 iteration is 3.0686233043670654 \n",
            "Train loss at 3575 iteration is 3.0771896839141846 \n",
            "Train loss at 3576 iteration is 3.1123955249786377 \n",
            "Train loss at 3577 iteration is 3.0805351734161377 \n",
            "Train loss at 3578 iteration is 3.198923110961914 \n",
            "Train loss at 3579 iteration is 3.1949353218078613 \n",
            "Train loss at 3580 iteration is 2.965411424636841 \n",
            "Train loss at 3581 iteration is 3.0777485370635986 \n",
            "Train loss at 3582 iteration is 3.1084437370300293 \n",
            "Train loss at 3583 iteration is 3.0903594493865967 \n",
            "Train loss at 3584 iteration is 2.7030112743377686 \n",
            "Train loss at 3585 iteration is 2.7838053703308105 \n",
            "Train loss at 3586 iteration is 2.706564426422119 \n",
            "Train loss at 3587 iteration is 2.7823879718780518 \n",
            "Train loss at 3588 iteration is 2.6587092876434326 \n",
            "Train loss at 3589 iteration is 2.8760006427764893 \n",
            "Train loss at 3590 iteration is 2.9903523921966553 \n",
            "Train loss at 3591 iteration is 2.903517484664917 \n",
            "Train loss at 3592 iteration is 2.654505968093872 \n",
            "Train loss at 3593 iteration is 2.9199059009552 \n",
            "Train loss at 3594 iteration is 2.7619941234588623 \n",
            "Train loss at 3595 iteration is 2.8859996795654297 \n",
            "Train loss at 3596 iteration is 2.8223395347595215 \n",
            "Train loss at 3597 iteration is 2.6158618927001953 \n",
            "Train loss at 3598 iteration is 2.7240443229675293 \n",
            "Train loss at 3599 iteration is 2.744525194168091 \n",
            "Train loss at 3600 iteration is 2.7106852531433105 \n",
            "Train loss at 3601 iteration is 2.686845302581787 \n",
            "Train loss at 3602 iteration is 2.7100424766540527 \n",
            "Train loss at 3603 iteration is 2.8586583137512207 \n",
            "Train loss at 3604 iteration is 2.5811421871185303 \n",
            "Train loss at 3605 iteration is 2.6966378688812256 \n",
            "Train loss at 3606 iteration is 2.7897839546203613 \n",
            "Train loss at 3607 iteration is 2.7734978199005127 \n",
            "Train loss at 3608 iteration is 2.8095109462738037 \n",
            "Train loss at 3609 iteration is 2.7495036125183105 \n",
            "Train loss at 3610 iteration is 2.942793607711792 \n",
            "Train loss at 3611 iteration is 2.668497085571289 \n",
            "Train loss at 3612 iteration is 2.727027177810669 \n",
            "Train loss at 3613 iteration is 2.7402546405792236 \n",
            "Train loss at 3614 iteration is 2.828744411468506 \n",
            "Train loss at 3615 iteration is 2.6822328567504883 \n",
            "Train loss at 3616 iteration is 2.6122050285339355 \n",
            "Train loss at 3617 iteration is 2.705843925476074 \n",
            "Train loss at 3618 iteration is 2.860356330871582 \n",
            "Train loss at 3619 iteration is 2.873396158218384 \n",
            "Train loss at 3620 iteration is 2.8544983863830566 \n",
            "Train loss at 3621 iteration is 2.7990121841430664 \n",
            "Train loss at 3622 iteration is 2.878889322280884 \n",
            "Train loss at 3623 iteration is 2.751352310180664 \n",
            "Train loss at 3624 iteration is 2.863677978515625 \n",
            "Train loss at 3625 iteration is 2.7784957885742188 \n",
            "Train loss at 3626 iteration is 2.720553398132324 \n",
            "Train loss at 3627 iteration is 2.7790822982788086 \n",
            "Train loss at 3628 iteration is 2.6506903171539307 \n",
            "Train loss at 3629 iteration is 2.8434391021728516 \n",
            "Train loss at 3630 iteration is 2.8799259662628174 \n",
            "Train loss at 3631 iteration is 2.8136510848999023 \n",
            "Train loss at 3632 iteration is 2.752568006515503 \n",
            "Train loss at 3633 iteration is 2.752413034439087 \n",
            "Train loss at 3634 iteration is 2.915295124053955 \n",
            "Train loss at 3635 iteration is 2.8089940547943115 \n",
            "Train loss at 3636 iteration is 2.9179294109344482 \n",
            "Train loss at 3637 iteration is 2.8237063884735107 \n",
            "Train loss at 3638 iteration is 2.9425277709960938 \n",
            "Train loss at 3639 iteration is 2.838599681854248 \n",
            "Train loss at 3640 iteration is 2.716334104537964 \n",
            "Train loss at 3641 iteration is 2.864396333694458 \n",
            "Train loss at 3642 iteration is 2.7726595401763916 \n",
            "Train loss at 3643 iteration is 2.7443981170654297 \n",
            "Train loss at 3644 iteration is 2.8733012676239014 \n",
            "Train loss at 3645 iteration is 2.8311192989349365 \n",
            "Train loss at 3646 iteration is 2.774726152420044 \n",
            "Train loss at 3647 iteration is 2.901175022125244 \n",
            "Train loss at 3648 iteration is 2.8004486560821533 \n",
            "Train loss at 3649 iteration is 2.719409704208374 \n",
            "Train loss at 3650 iteration is 2.7425954341888428 \n",
            "Train loss at 3651 iteration is 2.7388317584991455 \n",
            "Train loss at 3652 iteration is 2.9530086517333984 \n",
            "Train loss at 3653 iteration is 2.766166925430298 \n",
            "Train loss at 3654 iteration is 2.7357685565948486 \n",
            "Train loss at 3655 iteration is 2.6862785816192627 \n",
            "Train loss at 3656 iteration is 2.782533884048462 \n",
            "Train loss at 3657 iteration is 2.926363229751587 \n",
            "Train loss at 3658 iteration is 2.7642006874084473 \n",
            "Train loss at 3659 iteration is 2.772554636001587 \n",
            "Train loss at 3660 iteration is 2.688958168029785 \n",
            "Train loss at 3661 iteration is 2.9350874423980713 \n",
            "Train loss at 3662 iteration is 2.7361128330230713 \n",
            "Train loss at 3663 iteration is 2.892225503921509 \n",
            "Train loss at 3664 iteration is 2.51010799407959 \n",
            "Train loss at 3665 iteration is 2.938366174697876 \n",
            "Train loss at 3666 iteration is 2.7083492279052734 \n",
            "Train loss at 3667 iteration is 2.81545352935791 \n",
            "Train loss at 3668 iteration is 2.924238681793213 \n",
            "Train loss at 3669 iteration is 2.8320298194885254 \n",
            "Train loss at 3670 iteration is 2.8804867267608643 \n",
            "Train loss at 3671 iteration is 2.9141483306884766 \n",
            "Train loss at 3672 iteration is 2.8395209312438965 \n",
            "Train loss at 3673 iteration is 2.7790393829345703 \n",
            "Train loss at 3674 iteration is 2.7455203533172607 \n",
            "Train loss at 3675 iteration is 2.843522071838379 \n",
            "Train loss at 3676 iteration is 2.838520050048828 \n",
            "Train loss at 3677 iteration is 2.9091124534606934 \n",
            "Train loss at 3678 iteration is 2.681265115737915 \n",
            "Train loss at 3679 iteration is 2.7792677879333496 \n",
            "Train loss at 3680 iteration is 2.813443183898926 \n",
            "Train loss at 3681 iteration is 2.8324809074401855 \n",
            "Train loss at 3682 iteration is 2.7175679206848145 \n",
            "Train loss at 3683 iteration is 2.7300031185150146 \n",
            "Train loss at 3684 iteration is 2.854081869125366 \n",
            "Train loss at 3685 iteration is 2.8541293144226074 \n",
            "Train loss at 3686 iteration is 2.889029026031494 \n",
            "Train loss at 3687 iteration is 3.026658535003662 \n",
            "Train loss at 3688 iteration is 2.7925944328308105 \n",
            "Train loss at 3689 iteration is 2.9536795616149902 \n",
            "Train loss at 3690 iteration is 2.610171318054199 \n",
            "Train loss at 3691 iteration is 2.90211820602417 \n",
            "Train loss at 3692 iteration is 2.94830322265625 \n",
            "Train loss at 3693 iteration is 2.841125726699829 \n",
            "Train loss at 3694 iteration is 2.762756109237671 \n",
            "Train loss at 3695 iteration is 2.780272960662842 \n",
            "Train loss at 3696 iteration is 2.6621129512786865 \n",
            "Train loss at 3697 iteration is 2.7710819244384766 \n",
            "Train loss at 3698 iteration is 2.6139891147613525 \n",
            "Train loss at 3699 iteration is 2.928046941757202 \n",
            "Train loss at 3700 iteration is 2.952179431915283 \n",
            "Train loss at 3701 iteration is 2.9369795322418213 \n",
            "Train loss at 3702 iteration is 2.5687639713287354 \n",
            "Train loss at 3703 iteration is 2.891244649887085 \n",
            "Train loss at 3704 iteration is 2.747802257537842 \n",
            "Train loss at 3705 iteration is 2.94273042678833 \n",
            "Train loss at 3706 iteration is 2.738847494125366 \n",
            "Train loss at 3707 iteration is 2.832386016845703 \n",
            "Train loss at 3708 iteration is 2.6284334659576416 \n",
            "Train loss at 3709 iteration is 2.809241771697998 \n",
            "Train loss at 3710 iteration is 2.730306386947632 \n",
            "Train loss at 3711 iteration is 2.8565621376037598 \n",
            "Train loss at 3712 iteration is 2.7317752838134766 \n",
            "Train loss at 3713 iteration is 2.944528102874756 \n",
            "Train loss at 3714 iteration is 2.8179492950439453 \n",
            "Train loss at 3715 iteration is 2.8372700214385986 \n",
            "Train loss at 3716 iteration is 2.902543544769287 \n",
            "Train loss at 3717 iteration is 2.831450939178467 \n",
            "Train loss at 3718 iteration is 2.807908773422241 \n",
            "Train loss at 3719 iteration is 2.74393630027771 \n",
            "Train loss at 3720 iteration is 2.9685587882995605 \n",
            "Train loss at 3721 iteration is 2.6817843914031982 \n",
            "Train loss at 3722 iteration is 2.847040891647339 \n",
            "Train loss at 3723 iteration is 2.9173996448516846 \n",
            "Train loss at 3724 iteration is 3.0279529094696045 \n",
            "Train loss at 3725 iteration is 2.670323133468628 \n",
            "Train loss at 3726 iteration is 2.877627372741699 \n",
            "Train loss at 3727 iteration is 2.8677172660827637 \n",
            "Train loss at 3728 iteration is 2.803800344467163 \n",
            "Train loss at 3729 iteration is 2.862344741821289 \n",
            "Train loss at 3730 iteration is 2.810332775115967 \n",
            "Train loss at 3731 iteration is 2.6446518898010254 \n",
            "Train loss at 3732 iteration is 2.742983818054199 \n",
            "Train loss at 3733 iteration is 2.8668694496154785 \n",
            "Train loss at 3734 iteration is 2.962151288986206 \n",
            "Train loss at 3735 iteration is 2.872483253479004 \n",
            "Train loss at 3736 iteration is 2.863708019256592 \n",
            "Train loss at 3737 iteration is 2.789470911026001 \n",
            "Train loss at 3738 iteration is 2.983612060546875 \n",
            "Train loss at 3739 iteration is 3.0282070636749268 \n",
            "Train loss at 3740 iteration is 2.780268907546997 \n",
            "Train loss at 3741 iteration is 2.8538124561309814 \n",
            "Train loss at 3742 iteration is 2.7682976722717285 \n",
            "Train loss at 3743 iteration is 2.870755910873413 \n",
            "Train loss at 3744 iteration is 2.7096047401428223 \n",
            "Train loss at 3745 iteration is 2.86922025680542 \n",
            "Train loss at 3746 iteration is 2.827829599380493 \n",
            "Train loss at 3747 iteration is 2.711780309677124 \n",
            "Train loss at 3748 iteration is 2.5809290409088135 \n",
            "Train loss at 3749 iteration is 3.0454347133636475 \n",
            "Train loss at 3750 iteration is 2.793314218521118 \n",
            "Train loss at 3751 iteration is 2.7303428649902344 \n",
            "Train loss at 3752 iteration is 2.8379769325256348 \n",
            "Train loss at 3753 iteration is 2.8448359966278076 \n",
            "Train loss at 3754 iteration is 2.7175636291503906 \n",
            "Train loss at 3755 iteration is 2.911998748779297 \n",
            "Train loss at 3756 iteration is 2.7758700847625732 \n",
            "Train loss at 3757 iteration is 2.762176275253296 \n",
            "Train loss at 3758 iteration is 2.7798678874969482 \n",
            "Train loss at 3759 iteration is 2.8781259059906006 \n",
            "Train loss at 3760 iteration is 2.8534622192382812 \n",
            "Train loss at 3761 iteration is 2.769948959350586 \n",
            "Train loss at 3762 iteration is 2.865654468536377 \n",
            "Train loss at 3763 iteration is 3.003269672393799 \n",
            "Train loss at 3764 iteration is 2.6423966884613037 \n",
            "Train loss at 3765 iteration is 2.9549970626831055 \n",
            "Train loss at 3766 iteration is 3.0128138065338135 \n",
            "Train loss at 3767 iteration is 2.772481679916382 \n",
            "Train loss at 3768 iteration is 2.876894474029541 \n",
            "Train loss at 3769 iteration is 2.921035051345825 \n",
            "Train loss at 3770 iteration is 2.9181017875671387 \n",
            "Train loss at 3771 iteration is 2.9777653217315674 \n",
            "Train loss at 3772 iteration is 2.8344788551330566 \n",
            "Train loss at 3773 iteration is 2.7981629371643066 \n",
            "Train loss at 3774 iteration is 2.8294076919555664 \n",
            "Train loss at 3775 iteration is 2.833876371383667 \n",
            "Train loss at 3776 iteration is 2.896385431289673 \n",
            "Train loss at 3777 iteration is 2.655972957611084 \n",
            "Train loss at 3778 iteration is 2.7329838275909424 \n",
            "Train loss at 3779 iteration is 2.8430850505828857 \n",
            "Train loss at 3780 iteration is 2.758636713027954 \n",
            "Train loss at 3781 iteration is 3.0170514583587646 \n",
            "Train loss at 3782 iteration is 2.8772127628326416 \n",
            "Train loss at 3783 iteration is 2.9075419902801514 \n",
            "Train loss at 3784 iteration is 2.921121835708618 \n",
            "Train loss at 3785 iteration is 2.85514497756958 \n",
            "Train loss at 3786 iteration is 2.8617255687713623 \n",
            "Train loss at 3787 iteration is 2.9552018642425537 \n",
            "Train loss at 3788 iteration is 2.8202688694000244 \n",
            "Train loss at 3789 iteration is 2.80111026763916 \n",
            "Train loss at 3790 iteration is 2.831712245941162 \n",
            "Train loss at 3791 iteration is 2.9522361755371094 \n",
            "Train loss at 3792 iteration is 2.80782151222229 \n",
            "Train loss at 3793 iteration is 2.892561674118042 \n",
            "Train loss at 3794 iteration is 2.894681692123413 \n",
            "Train loss at 3795 iteration is 2.927999258041382 \n",
            "Train loss at 3796 iteration is 2.9214093685150146 \n",
            "Train loss at 3797 iteration is 2.9947879314422607 \n",
            "Train loss at 3798 iteration is 2.765833854675293 \n",
            "Train loss at 3799 iteration is 3.003376007080078 \n",
            "Train loss at 3800 iteration is 2.751842498779297 \n",
            "Train loss at 3801 iteration is 2.9816179275512695 \n",
            "Train loss at 3802 iteration is 2.951122283935547 \n",
            "Train loss at 3803 iteration is 2.929622173309326 \n",
            "Train loss at 3804 iteration is 2.9238948822021484 \n",
            "Train loss at 3805 iteration is 2.757509231567383 \n",
            "Train loss at 3806 iteration is 2.7174084186553955 \n",
            "Train loss at 3807 iteration is 2.7532119750976562 \n",
            "Train loss at 3808 iteration is 2.9065067768096924 \n",
            "Train loss at 3809 iteration is 2.7985782623291016 \n",
            "Train loss at 3810 iteration is 2.890472888946533 \n",
            "Train loss at 3811 iteration is 2.8253705501556396 \n",
            "Train loss at 3812 iteration is 2.7311792373657227 \n",
            "Train loss at 3813 iteration is 2.9090006351470947 \n",
            "Train loss at 3814 iteration is 2.710188388824463 \n",
            "Train loss at 3815 iteration is 2.836933135986328 \n",
            "Train loss at 3816 iteration is 2.7919728755950928 \n",
            "Train loss at 3817 iteration is 2.7849695682525635 \n",
            "Train loss at 3818 iteration is 2.7327780723571777 \n",
            "Train loss at 3819 iteration is 3.010166883468628 \n",
            "Train loss at 3820 iteration is 2.758512496948242 \n",
            "Train loss at 3821 iteration is 2.7461767196655273 \n",
            "Train loss at 3822 iteration is 2.974405527114868 \n",
            "Train loss at 3823 iteration is 2.8754029273986816 \n",
            "Train loss at 3824 iteration is 2.7756218910217285 \n",
            "Train loss at 3825 iteration is 2.6298248767852783 \n",
            "Train loss at 3826 iteration is 2.937441825866699 \n",
            "Train loss at 3827 iteration is 2.8955962657928467 \n",
            "Train loss at 3828 iteration is 2.8695521354675293 \n",
            "Train loss at 3829 iteration is 2.9305219650268555 \n",
            "Train loss at 3830 iteration is 2.721491813659668 \n",
            "Train loss at 3831 iteration is 2.858731985092163 \n",
            "Train loss at 3832 iteration is 2.8674404621124268 \n",
            "Train loss at 3833 iteration is 2.9188599586486816 \n",
            "Train loss at 3834 iteration is 2.7948126792907715 \n",
            "Train loss at 3835 iteration is 2.810397148132324 \n",
            "Train loss at 3836 iteration is 2.835361957550049 \n",
            "Train loss at 3837 iteration is 2.9503400325775146 \n",
            "Train loss at 3838 iteration is 2.7259089946746826 \n",
            "Train loss at 3839 iteration is 2.789304494857788 \n",
            "Train loss at 3840 iteration is 2.89414119720459 \n",
            "Train loss at 3841 iteration is 2.7947587966918945 \n",
            "Train loss at 3842 iteration is 3.006150245666504 \n",
            "Train loss at 3843 iteration is 2.7601585388183594 \n",
            "Train loss at 3844 iteration is 2.634511709213257 \n",
            "Train loss at 3845 iteration is 2.736948013305664 \n",
            "Train loss at 3846 iteration is 2.8830413818359375 \n",
            "Train loss at 3847 iteration is 2.9408533573150635 \n",
            "Train loss at 3848 iteration is 3.033747434616089 \n",
            "Train loss at 3849 iteration is 2.9248149394989014 \n",
            "Train loss at 3850 iteration is 2.94588565826416 \n",
            "Train loss at 3851 iteration is 2.7599873542785645 \n",
            "Train loss at 3852 iteration is 2.6774468421936035 \n",
            "Train loss at 3853 iteration is 2.9222412109375 \n",
            "Train loss at 3854 iteration is 2.7142417430877686 \n",
            "Train loss at 3855 iteration is 3.155264377593994 \n",
            "Train loss at 3856 iteration is 2.807253122329712 \n",
            "Train loss at 3857 iteration is 2.715461015701294 \n",
            "Train loss at 3858 iteration is 2.790619373321533 \n",
            "Train loss at 3859 iteration is 3.0416359901428223 \n",
            "Train loss at 3860 iteration is 2.8837504386901855 \n",
            "Train loss at 3861 iteration is 2.751905918121338 \n",
            "Train loss at 3862 iteration is 2.991142511367798 \n",
            "Train loss at 3863 iteration is 2.961754322052002 \n",
            "Train loss at 3864 iteration is 2.7833831310272217 \n",
            "Train loss at 3865 iteration is 2.867783546447754 \n",
            "Train loss at 3866 iteration is 2.8079304695129395 \n",
            "Train loss at 3867 iteration is 2.684248208999634 \n",
            "Train loss at 3868 iteration is 2.7899012565612793 \n",
            "Train loss at 3869 iteration is 2.802354574203491 \n",
            "Train loss at 3870 iteration is 2.880744218826294 \n",
            "Train loss at 3871 iteration is 2.8427507877349854 \n",
            "Train loss at 3872 iteration is 2.830141544342041 \n",
            "Train loss at 3873 iteration is 2.9726383686065674 \n",
            "Train loss at 3874 iteration is 2.8635752201080322 \n",
            "Train loss at 3875 iteration is 2.977642297744751 \n",
            "Train loss at 3876 iteration is 2.9442763328552246 \n",
            "Train loss at 3877 iteration is 2.8569698333740234 \n",
            "Train loss at 3878 iteration is 2.853062391281128 \n",
            "Train loss at 3879 iteration is 2.8467519283294678 \n",
            "Train loss at 3880 iteration is 2.8199973106384277 \n",
            "Train loss at 3881 iteration is 2.689115524291992 \n",
            "Train loss at 3882 iteration is 2.8433027267456055 \n",
            "Train loss at 3883 iteration is 2.694540023803711 \n",
            "Train loss at 3884 iteration is 2.809446096420288 \n",
            "Train loss at 3885 iteration is 2.8539793491363525 \n",
            "Train loss at 3886 iteration is 2.7728116512298584 \n",
            "Train loss at 3887 iteration is 2.886575698852539 \n",
            "Train loss at 3888 iteration is 2.707775592803955 \n",
            "Train loss at 3889 iteration is 2.7782790660858154 \n",
            "Train loss at 3890 iteration is 2.912166118621826 \n",
            "Train loss at 3891 iteration is 3.007659673690796 \n",
            "Train loss at 3892 iteration is 2.9590060710906982 \n",
            "Train loss at 3893 iteration is 2.962975263595581 \n",
            "Train loss at 3894 iteration is 2.8760921955108643 \n",
            "Train loss at 3895 iteration is 2.7176101207733154 \n",
            "Train loss at 3896 iteration is 2.755124807357788 \n",
            "Train loss at 3897 iteration is 2.789607286453247 \n",
            "Train loss at 3898 iteration is 3.0261952877044678 \n",
            "Train loss at 3899 iteration is 2.8392295837402344 \n",
            "Train loss at 3900 iteration is 2.8012731075286865 \n",
            "Train loss at 3901 iteration is 2.916285991668701 \n",
            "Train loss at 3902 iteration is 2.916896343231201 \n",
            "Train loss at 3903 iteration is 2.9088191986083984 \n",
            "Train loss at 3904 iteration is 2.9535117149353027 \n",
            "Train loss at 3905 iteration is 2.640984296798706 \n",
            "Train loss at 3906 iteration is 2.7420296669006348 \n",
            "Train loss at 3907 iteration is 2.8706417083740234 \n",
            "Train loss at 3908 iteration is 2.8138225078582764 \n",
            "Train loss at 3909 iteration is 2.8819470405578613 \n",
            "Train loss at 3910 iteration is 2.982609272003174 \n",
            "Train loss at 3911 iteration is 2.8448305130004883 \n",
            "Train loss at 3912 iteration is 2.8142974376678467 \n",
            "Train loss at 3913 iteration is 2.76562237739563 \n",
            "Train loss at 3914 iteration is 2.7786777019500732 \n",
            "Train loss at 3915 iteration is 2.7820823192596436 \n",
            "Train loss at 3916 iteration is 2.868330955505371 \n",
            "Train loss at 3917 iteration is 3.12210750579834 \n",
            "Train loss at 3918 iteration is 2.8636226654052734 \n",
            "Train loss at 3919 iteration is 2.8711771965026855 \n",
            "Train loss at 3920 iteration is 2.6964926719665527 \n",
            "Train loss at 3921 iteration is 2.9523024559020996 \n",
            "Train loss at 3922 iteration is 2.8552517890930176 \n",
            "Train loss at 3923 iteration is 2.882974624633789 \n",
            "Train loss at 3924 iteration is 2.8457717895507812 \n",
            "Train loss at 3925 iteration is 2.89383602142334 \n",
            "Train loss at 3926 iteration is 2.8215579986572266 \n",
            "Train loss at 3927 iteration is 2.945848226547241 \n",
            "Train loss at 3928 iteration is 2.8193187713623047 \n",
            "Train loss at 3929 iteration is 2.831252098083496 \n",
            "Train loss at 3930 iteration is 2.917487859725952 \n",
            "Train loss at 3931 iteration is 2.957411289215088 \n",
            "Train loss at 3932 iteration is 2.8844568729400635 \n",
            "Train loss at 3933 iteration is 2.8739125728607178 \n",
            "Train loss at 3934 iteration is 2.8435399532318115 \n",
            "Train loss at 3935 iteration is 2.834108829498291 \n",
            "Train loss at 3936 iteration is 2.726398229598999 \n",
            "Train loss at 3937 iteration is 3.050372838973999 \n",
            "Train loss at 3938 iteration is 2.856860876083374 \n",
            "Train loss at 3939 iteration is 2.666945219039917 \n",
            "Train loss at 3940 iteration is 2.954402446746826 \n",
            "Train loss at 3941 iteration is 2.9391236305236816 \n",
            "Train loss at 3942 iteration is 2.9259495735168457 \n",
            "Train loss at 3943 iteration is 2.969543218612671 \n",
            "Train loss at 3944 iteration is 2.895137071609497 \n",
            "Train loss at 3945 iteration is 2.889411449432373 \n",
            "Train loss at 3946 iteration is 2.9862406253814697 \n",
            "Train loss at 3947 iteration is 2.850172519683838 \n",
            "Train loss at 3948 iteration is 2.8194196224212646 \n",
            "Train loss at 3949 iteration is 3.0219693183898926 \n",
            "Train loss at 3950 iteration is 2.894606351852417 \n",
            "Train loss at 3951 iteration is 2.741208076477051 \n",
            "Train loss at 3952 iteration is 2.8057048320770264 \n",
            "Train loss at 3953 iteration is 2.7940497398376465 \n",
            "Train loss at 3954 iteration is 3.012873649597168 \n",
            "Train loss at 3955 iteration is 3.058943033218384 \n",
            "Train loss at 3956 iteration is 2.7284281253814697 \n",
            "Train loss at 3957 iteration is 2.8972227573394775 \n",
            "Train loss at 3958 iteration is 2.810154676437378 \n",
            "Train loss at 3959 iteration is 3.0527093410491943 \n",
            "Train loss at 3960 iteration is 3.098349094390869 \n",
            "Train loss at 3961 iteration is 2.7546451091766357 \n",
            "Train loss at 3962 iteration is 2.9057276248931885 \n",
            "Train loss at 3963 iteration is 2.959965229034424 \n",
            "Train loss at 3964 iteration is 2.8593199253082275 \n",
            "Train loss at 3965 iteration is 2.7671003341674805 \n",
            "Train loss at 3966 iteration is 2.8825650215148926 \n",
            "Train loss at 3967 iteration is 2.8836476802825928 \n",
            "Train loss at 3968 iteration is 2.951988697052002 \n",
            "Train loss at 3969 iteration is 2.8718442916870117 \n",
            "Train loss at 3970 iteration is 2.8843958377838135 \n",
            "Train loss at 3971 iteration is 2.9976093769073486 \n",
            "Train loss at 3972 iteration is 2.8809258937835693 \n",
            "Train loss at 3973 iteration is 2.7001733779907227 \n",
            "Train loss at 3974 iteration is 2.9411659240722656 \n",
            "Train loss at 3975 iteration is 3.0434393882751465 \n",
            "Train loss at 3976 iteration is 2.942858934402466 \n",
            "Train loss at 3977 iteration is 2.9125454425811768 \n",
            "Train loss at 3978 iteration is 2.9270858764648438 \n",
            "Train loss at 3979 iteration is 2.8039443492889404 \n",
            "Train loss at 3980 iteration is 2.949446678161621 \n",
            "Train loss at 3981 iteration is 2.9256491661071777 \n",
            "Train loss at 3982 iteration is 2.894713878631592 \n",
            "Train loss at 3983 iteration is 2.837615489959717 \n",
            "Train loss at 3984 iteration is 2.914741039276123 \n",
            "Train loss at 3985 iteration is 2.7562592029571533 \n",
            "Train loss at 3986 iteration is 2.8142807483673096 \n",
            "Train loss at 3987 iteration is 2.887845516204834 \n",
            "Train loss at 3988 iteration is 2.755800247192383 \n",
            "Train loss at 3989 iteration is 2.8683784008026123 \n",
            "Train loss at 3990 iteration is 2.9036262035369873 \n",
            "Train loss at 3991 iteration is 2.7771239280700684 \n",
            "Train loss at 3992 iteration is 2.87636399269104 \n",
            "Train loss at 3993 iteration is 2.838691473007202 \n",
            "Train loss at 3994 iteration is 2.7090039253234863 \n",
            "Train loss at 3995 iteration is 2.7333641052246094 \n",
            "Train loss at 3996 iteration is 2.871358871459961 \n",
            "Train loss at 3997 iteration is 2.8116090297698975 \n",
            "Train loss at 3998 iteration is 2.8121323585510254 \n",
            "Train loss at 3999 iteration is 2.888731002807617 \n",
            "Train loss at 4000 iteration is 2.6476082801818848 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}